[
["index.html", "Modelización en R Presentación", " Modelización en R Aula Innova. Innova-tsn Sabadell. Enero-Febrero, 2018 Presentación Modelización con R es un manual práctico para la creación y utilización de modelos analíticos con el lenguaje R (R Core Team 2017). En particular, esta versión del manual ha sido desarrollada para el equipo de modelling del Banc Sabadell en Barcelona. El objetivo de este manual es presentar de manera resumida, los principales algoritmos del analytics, destacando cuándo deben ser utilizados y cómo evaluar su performance. Cada capítulo corresponde a un tópico. Se pueden leer de manera individual. Todos los ejemplo están desarrollados con datos incluidos en las librerias de R y/o se encuentran disponibles en la web. Para realizar las prácticas sugeridas en este manual, el lector requiere un portátil donde tenga instaladas las últimas versiones de R y RStudio. Además debe contar con una conexión a internet y la posibilidad de instalar las librerías que se citan a lo largo del documento. References "],
["modelizacion.html", "Capítulo 1 Modelizar", " Capítulo 1 Modelizar Los sistemas analíticos están presentes en todas las áreas de negocio del sector bancario. A muy alto nivel, se puede contar con modelos predictivos en la gestión de clientes, gestión del riesgo y en el soporte a las operaciones. Así mismo, dichos sistemas pueden estar desagregados por segmento, producto, región geográfica, etc. Algunas de las aplicaciones de la modelización son: Clientes Con modelos predictivos se puede mejorar la relación con los clientes, a través de: Anticipación de la Fuga (Retención), Incentivo del Uso de Productos (Fidelización), Adquisición de Nuevos Productos (Venta Cruzada), Anticipación de la Reclamación (Satisfacción), Promociones que le interesen (Gestión de Campañas), etc. Riesgo Con modelos analíticos se puede optimizar todo el ciclo de cobranza: Concesión de créditos, Anticipar impagos, Detectar fraude, Optimización de la Cobranza, etc. Operaciones Con modelos predictivos se puede hacer más eficientes algunos procesos como: Gestión de sucursales, Optimización de personal, Gestión de cajeros automáticos, Inversión en marketing, Gestión del call center, etc. Las técnicas/modelos analíticos utilizadas dependen del output o target. En general, se trabaja con outputs binarios (1-0), outputs continuos o, más recientemente, datos no estructurados. "],
["modelizar.html", "1.1 ¿Qué es Modelizar?", " 1.1 ¿Qué es Modelizar? Modelizar es el proceso de crear, desarrollar y validar modelos que sirvan para convertir los datos en información de negocio significativa que ayude a ejecutar las estrategias y mejorar el rendimiento. Data science es la disciplina que permite convertir los datos en conocimiento (Garrett Grolemund 2017). Modelizar es una de las fases del Data Science. Un esquema aceptado sobre las fases de un proyecto de Data Science es1: Data y Analytics van de la mano. Más generalmente, como lo expone Marr (2017), en el context de Big Data, apply analytics (A), se encuentra en el corazón de la estrategia para crear SMART Business y aprovechar al máximo el valor de los datos. En resumen, Modelizar es el proceso de crear, desarrollar y validar modelos que sirvan para convertir los datos en información de negocio significativa que ayude a ejecutar las estrategias y mejorar el rendimiento. Los modelos más comunes son: modelos de regresión, modelos de series temporales, técnicas de machine learning, etc. References "],
["que-es-un-modelo-analitico.html", "1.2 ¿Qué es un modelo analítico?", " 1.2 ¿Qué es un modelo analítico? Un modelo es resumen simple, de baja dimensión, de un conjunto de datos (Garrett Grolemund 2017). Algunas de las afirmaciones tradicionalmente aceptadas sobre un modelo analítico son: Un modelo es una representación simplificada de la realidad. Un modelo es una forma matemática de describir la relación entre una variable de respuesta y un conjunto de variables independientes. Un modelo se puede ver como: (a) Una teoría sobre cómo se generaron los datos y (b) Una forma útil de resumir los datos. A un modelo no se le exige que sea verdadero, sino que sea útil, de acuerdo a los objetivos para los cuales fue creado. Todos los modelos son errados, pero algunos son útiles. De manera general, un modelo es una representación del mecanismo generador de los datos. Por ello, un modelo puede verse como un resumen de la información disponible y en consecuencia permite compactar los datos existentes. Los modelos se utilizan principalmente para entender dinámicas del mercado, prever el futuro, simular consecuencias ante cambios, evaluar acciones pasadas, etc. Los modelos son el elemento central de la creación de inteligencia corporativa. Condesan y operacionalizan la información existente. Son almacenes y fábricas de conocimiento. Cuando se quiere hacer uso de un modelo, se suele identificar: output : variable dependiente, variable respuesta, variable objetivo. input(s) : variable(s) independiente(s), predictor(es), o simplemente feature(s). References "],
["tipos-de-problemas.html", "Capítulo 2 Tipos de Problemas", " Capítulo 2 Tipos de Problemas En bastante común que los algoritmos de Machine Learning en aprendizaje supervisado y aprendizaje no supervisado. Esta misma clasificación se menciona en la sección 2.1, las herramientas de statistical learning. Este tipo de clasificación responde al tipo de problema e información que disponemos del output, por ello, en este Manual generalizamos esta clasificación y la denominamos Tipo de Problema Analítico que debemos afrontar. Problema / Aprendizaje Supervisado En el aprendizaje supervisado, cada dato, unidad analizada u observación está etiquetada o asociada con una categoría o valor de interés. Ejemplos: Una imagen es etiquetada como un ‘gato’ o ‘perro’. Un cliente es etiquetado como ‘propenso’ o ‘no propenso’ al uso del canal digital. El precio de venta asociado a un coche usado, es una etiqueta de valor. El objetivo del aprendizaje supervisado es estudiar muchos ejemplos etiquetados y, luego, poder realizar predicciones sobre los datos futuros. Por ejemplo, identificar nuevas fotografías con el animal correcto, identificar clientes a clientes facilitar el uso de la banca online o asignar precios de venta precisos a otros coches usados. El aprendizaje supervisado usa técnicas de clasificación y regresión para desarrollar modelos predictivos. Las técnicas de clasificación predicen respuestas discretas —por ejemplo, saber si un correo es genuino o spam, o si un tumor es benigno o maligno. Los modelos de clasificación categorizan los datos de entrada. Entre las aplicaciones típicas se incluyen imágenes médicas, reconocimiento de voz o puntaje crediticio. Cuando hay sólo dos opciones, se denomina clasificación de dos clases o binaria. Cundo hay más categorías, se denomina clasificación multiclase o multinomial. En algunos casos la detección de anomalías se considera una técnica adicional de clasificación. En la detección de fraude, por ejemplo, los patrones de gasto de tarjeta de crédito muy poco habituales son sospechosos. Las posibles variaciones son tan numerosas y los ejemplos de formación son tan pocos, que no es posible saber de qué actividad fraudulenta se trata. El enfoque que toma la detección de anomalías es simplemente aprender qué puede considerarse como actividad normal (haciendo uso de las transacciones no fraudulentas del historial) e identificar todo lo que sea significativamente diferente2. Las técnicas de reducción de dimensionalidad ayudan a disminuir la complejidad de los problemas debida al gran volumen de datos. Cuando mayor es el conjunto de datos, mayor la necesidad de reducir el número de variables (features) que se quieren analizar. Las técnicas de regresión predicen respuestas continuas —por ejemplo, cambios en la temperatura o fluctuaciones en la demanda de energía. Las aplicaciones típicas pueden ser previsión del recurso eléctrico o trading algorítmico. Problema / Aprendizaje No Supervisado En el aprendizaje no supervisado, los datos no tienen etiquetas asociadas a ellos. En este caso, el objetivo es organizar los datos de alguna manera o describir su estructura. Esto puede significar agrupar clientes en segmentos, o buscar diferentes maneras de examinar datos complejos para que parezcan más simples. El aprendizaje no supervisado se utiliza en análisis exploratorio de datos para encontrar características ocultas y agrupar. Las aplicaciones del clustering incluyen análisis de secuencias genéticas, investigación de mercado y reconocimiento de objetos. Fuente:https://docs.microsoft.com/es-es/azure/machine-learning/studio/algorithm-choice↩ "],
["clasemodelos.html", "2.1 Enfoques de Modelización", " 2.1 Enfoques de Modelización Statistical Learning se refiere a un conjunto de herramientas para modelar y comprender conjuntos de datos complejos. Statistical Learning es un término presentado en Gareth James (2014). Hace referencia a un área de reciente desarrollo en estadística, que se combina con desarrollos paralelos de ciencias de la computación (específicamente, Machine Learning). Se refiere a un ámplio conjunto de herramientas para entender datos. Estas herramientas pueden ser: supervisadas o no supervisadas. De manera muy genérica, en los problemas supervisados se busca estimar o prever un output basado en uno o más inputs. En los problemas no supervisados, se cuenta con los inputs pero con un output, por lo que se busca entender la estructura de los datos. Otra forma de clasificar los métodos para modelizar se basa en su objetivo y forma de construcción. Cuando se prioriza la interpretación del modelo, buscando que expliquen las relaciones entre output e inputs, se habla de modelos estadísticos. Cuando se prioriza la precisión de la previsión se habla de algoritmos de machine learning. Tipos de modelos analíticos: Modelos Estadísticos y Machine Learning3. Los primeros hacen uso de la probabilidad (inferencia), son explicativos y predictivos. Los segundos suelen ser ‘cajas negras’, se centran en la previsión y el trabajo con grandes volúmenes de datos4. El objetivo de los modelos o algoritmos de Machine Learning es enseñar a las computadoras a hacer lo que es natural para humanos y animales: aprender de la experiencia. Estos algoritmos utilizan métodos computacionales para “aprender” información directamente de los datos, sin depender de una ecuación predeterminada como modelo. Los algoritmos mejoran su rendimientode forma adaptativa conforme aumenta la cantidad de muestras (datos) disponibles para el aprendizaje. Machine Learning El Machine Learning no requiere hipótesis previas sobre las relaciones subyacentes entre las variables (o inputs). Sólo se deben ingresar todos los datos que se diponga, y el algoritmo procesa los datos y descubre patrones, con los cuales puede hacer predicciones sobre el nuevo conjunto de datos. El aprendizaje automático trata un algoritmo como una black box (caja negra), siempre que funcione. En otras palabras, su principal objetivo es la previsión. Modelos Estadísticos Por el contrario, los estadísticos deben comprender cómo se recopilaron los datos, las propiedades estadísticas de los estimadores, la distribución subyacente de la población que están estudiando y los tipos de propiedades que esperaría si hiciera el experimento muchas veces. Necesita saber exactamente lo que está haciendo y proponer parámetros que le proporcionen el poder predictivo. References "],
["catalogo-de-tecnicas.html", "Capítulo 3 Catálogo de Técnicas", " Capítulo 3 Catálogo de Técnicas ¿Tus datos pueden ser etiquetados o categorizados? Si tus datos pueden ser separados en clases o grupos específicos, usa algoritmos de clasificación. ¿Estás trabajando con datos de un rango? Si la naturaleza de tu respuesta es un número real - como la temperatura o el tiempo hasta que un cajero automático falle -, usa modelos o algoritmos de regresión. ¿Aún no sabes como agrupar tus datos: Usa clúster jerárquico para encontrar posibles estructuras en los datos. Usa la evaluación de clústers para encontrar el ‘mejor’ número de grupos. "],
["tecnicas-de-clustering.html", "3.1 Técnicas de Clustering", " 3.1 Técnicas de Clustering La mayoría de las técnicas de aprendizaje no supervisado son una forma de análisis por cluster. En análisis por cluster, los datos son divididos en grupos de acuerdo con alguna métrica de similaridad o característica compartida. De esta forma los objetos o instancias en el mismo clúster son muy similares y los de distintos muy diferentes. Los algoritmos de clustering se dividen en dos grandes grupos5: Clustering rígido, donde cada dato pertenece únicamente a un clúster. Clustering suave, donde cada dato puede pertenecer a más de un clúster. k-means ¿Cómo trabaja? Particiona datos en k número de clusters mutuamente excluyentes. El como de bien un punto se ajuste a un clúster determinado viene dado por su distancia al centro de dicho clúster. ¿Cuándo se usa? Cuando el número de clusters es conocido y cuando se requiere un clustering rápido de grandes conjuntos de datos. ¿Cuál es el resultado? Centroide de cada cluster. k-medoids ¿Cómo trabaja? Algoritmo similar a k-medias pero requiere de que los centroides sean puntos u observaciones de la muestra. ¿Cuándo se usa? Cuando el número de clusters es conocido. Para clustering rápido de datos categóricos. Para escalar a grandes conjuntos de datos. ¿Cuál es el resultado? Observación o individuo de la muestra que actúa de centroide o medoide de cada cluster. Hierarchical Clustering ¿Cómo trabaja? Produce conjuntos anidados de datos analizando similaridades entre pares de puntos y agrupando objetos en un arbol binario jerárquico. ¿Cuándo se usa? Cuando se desconoce el número de clusters a los que darán lugar los datos. Cuando se requiere de visualización para guiar la elección. ¿Cuál es el resultado? Dendograma mostrando la relación jerárquica entre los clusters. Self-Organizing Map ¿Cómo trabaja? Red neuronal basada en clustering que transforma un conjunto de datos en un mapa 2D con preservación de topología. ¿Cuándo se usa? Para observar datos de alta dimensionalidad en mapas 2D o 3D. Para deducir la dimensionalidad de los datos preservando su topología (forma). ¿Cuál es el resultado? Representación en dimensión más baja (típicamente en 2D) Fuzzy c-Means ¿Cómo trabaja? Agrupamiento difuso. Agrupamiento basado en particiones en el que los datos pueden estar en más de un cluster. ¿Cuándo se usa? Cuando el número de clusters es conocido. Para reconocimento de patrones. Cuando los clusters se sobreponen o se solopan. ¿Cuál es el resultado? Centro de los clústers (similar a k-means) pero con difusión (fuzziness) de forma que las observaciones o individuos pueden pertenecer a más de 1 cluster. Gaussian Mixture Model ¿Cómo trabaja? Modelo gaussiando mixto. Agrupación basada en particiones en la que los datos provienen de diferentes distribuciones normales multivariantes con ciertas probabilidades. ¿Cuándo se usa? Cuando un punto puede pertenecer a más de un clúster. Cuando los clusters diferentes tamaños y correlaciones entre ellos. ¿Cuál es el resultado? Modelo de distribuciones gausianas que proporciona la probabilidad de que una observación o individuo pertenezca a un clúster. Fuente: https://es.mathworks.com/discovery/machine-learning.html↩ "],
["tecnicas-de-clasificacion.html", "3.2 Técnicas de Clasificación", " 3.2 Técnicas de Clasificación Regresión Logística ¿Cómo trabaja? Ajusta un modelo que puede predecir la probabilidad de que una respuesta binaria pertenezca a una clase u otra. Debido a su simplicidad, la regresión logística se utiliza comúnmente como punto de partida para los problemas de clasificación binaria. ¿Cuándo se usa? Cuando los datos se pueden separar claramente por un solo límite lineal. Como una línea de base (baseline) para evaluar más complejos métodos de clasificación. k Vecinos Cercanos (kNN) ¿Cómo trabaja? kNN categoriza los objetos en función de las clases de su vecinos más cercanos en el conjunto de datos. Las predicciones de kNN suponen que los objetos cercanos entre sí son similares. Algunas de las métricas de distancia utilizadas para encontrar el vecino más cercano son: Euclides, bloque de la ciudad_city block, coseno y Chebychev. ¿Cuándo se usa? Cuando se requiere un algoritmo simple para establecer reglas de aprendizaje de referencia o base. Cuando el uso de memoria del modelo entrenado no es una preocupación. Cuando la velocidad de predicción del modelo entrenado tampoco constituye una limitación. Support Vector Machines (SVM) ¿Cómo trabaja? Clasifica datos encontrando el límite de decisión lineal (hiperplano) que separa todos los puntos de datos de una clase de los de la otra clase. El mejor hiperplano para una SVM es aquel con el mayor margen entre las dos clases, cuando los datos son linealmente separables. Si los datos no son linealmente separables, se utiliza una función de pérdida para penalizar los puntos en el lado equivocado del hiperplano Los SVM a veces usan una transformación de núcleo para transformar los datos no separables linealmente en dimensiones más altas donde un límite de decisión lineal puede ser encontrado. ¿Cuándo se usa? Para datos que tienen exactamente dos clases.Para datos de alta dimensión, no linealmente separables.Cuando se necesita un clasificador que sea simple, fácil de interpretar y preciso. Redes Neuronales ¿Cómo trabaja? Inspirada en el cerebro humano, una red neuronal consiste enredes de neuronas altamente conectadas que relacionan las entradas a las salidas deseadas La red se entrena de forma iterativa, modificando las fortalezas de las conexiones para que las entradas se asignen a la respuesta correcta. ¿Cuándo se usa? Para modelar sistemas altamente no lineales. Cuando los datos están disponibles de forma incremental y se desea actualiza constantemente el modelo. Cuando podría haber cambios inesperados en su datos de entrada. Cuando la interpretabilidad del modelo no es una preocupación importante. Árboles de Decisión ¿Cómo trabaja? Un árbol de decisión permite predecir respuestas a datos siguiendo las decisiones organizadas en un árbol, desde la raíz (inicio) hasta un nodo u hoja. Un árbol consiste en condiciones organizadas en forma de ramificaciones, donde el valor de un predictor se compara con un peso entrenado. Los número de ramas y los valores de los pesos se determinan en el proceso de entrenamiento. Algunas acciones adicionales, como la poda, se pueden usar para simplificar el modelo. ¿Cuándo se usa? Cuando se necesita un algoritmo fácil de interpretar y rápido de ejecutar. Para minimizar el uso de memoria. Cuando la precisión predictiva alta no es un requisito. Bagging, Boosting ¿Cómo trabaja? Varios árboles de decisión “más débiles” son combinados en un conjuto “más fuerte”. Un árbol de decisión en bolsas (bagging) consta de árboles entrenados de forma independiente en los datos que se remuestrean (boostrapping) a partir de los datos de entrada. Boosting implica crear un modelo fuerte mediante la adición iterativa de modelos “débiles” y ajustando el peso de cada modelo débil para centrarse en ejemplos mal clasificados. ¿Cuándo se usa? Cuando los predictores son categóricos (discretos) o se comportan no lineal. Análisis Discriminante ¿Cómo trabaja? Clasifica los datos a partir de combinaciones lineales de los inputs. El análisis discriminante asume que las diferentes clases de datos se pueden generar a partir de distribuciones gaussianas. Entrenar o ajustar un modelo de análisis discriminante implica encontrar los parámetros para la distribución gaussiana de cada clase. ¿Cuándo se usa? Cuando necesitas un modelo simple que sea fácil de interpretar. Cuando el uso de la memoria durante el entrenamiento es una preocupación. Cuando necesitas un modelo que sea rápido para predecir. "],
["tecnicas-de-regresion.html", "3.3 Técnicas de Regresión", " 3.3 Técnicas de Regresión Regresión Lineal ¿Cómo trabaja? La regresión lineal es una clase de modelo estadístico utilizado para describir una variable de respuesta continua como una función lineal de una o más variables predictoras. Dado que los modelos de regresión lineal son simples de interpretar y fáciles de entrenar, a menudo constituyen el primer modelo que se ajusta a un nuevo conjunto de datos. ¿Cuándo se usa? Cuando se necesita un algoritmo fácil de interpretar y rápido de ejecutar. Como línea de base para evaluar otros modelos de regresión más complejos. SVM Regression ¿Cómo trabaja? Los algoritmos de regresión SVM funcionan como los algoritmos de clasificación SVM, pero están modificados para poder predecir una respuesta continua. En lugar de encontrar un hiperplano que separa los datos, los algoritmos de regresión SVM encuentran un modelo que se desvía (aleja) de los datos observados por un valor no mayor que una pequeña cantidad, con valores que son tan pequeños como posible (para minimizar la sensibilidad al error). ¿Cuándo se usa? Para datos de alta dimensión (donde habrá una gran cantidad de variables predictoras) Generalized Linear Models ¿Cómo trabaja? Un modelo lineal generalizado es un caso especial de modelo no lineal. Implica ajustar un combinación lineal de los inputs a una función no lineal (la función de enlace) de los outputs. ¿Cuándo se usa? Cuando las variables de respuesta tienen un comportamiento de distribución no normal, como una variable de respuesta que se espera que sea siempre positiva. Regression Tree ¿Cómo trabaja? Los árboles de decisión para la regresión son similares a los árboles de decisión para clasificación, pero se modifican para poder predecir respuestas continuas. ¿Cuándo se usa? Cuando los predictores son categóricos (discretos) o se comportan no lineal. Gaussian Process Regression Model ¿Cómo trabaja? Los modelos de regresión de procesos gaussianos (GPR) son modelos no paramétricos que se utilizan para predecir el valor de una variable de respuesta continua. Son ampliamente utilizados en el campo del análisis espacial para la interpolación en presencia de incertidumbre. GPR también se conoce como Kriging. ¿Cuándo se usa? Para la interpolación de datos espaciales. "],
["tecnicas-de-reduccion-de-dimension.html", "3.4 Técnicas de Reducción de Dimensión", " 3.4 Técnicas de Reducción de Dimensión Análisis de Componentes Principales (PCA) ¿Cómo trabaja? Realiza una transformación lineal en los datos de forma que la mayor varianza o información en el conjunto de datos de alta dimensión es capturada por las primeras (pocas) componentes principales. La primera componente capturará la mayor varianza, seguida por la segunda componente principal, y así sucesivamente. Análisis Factorial ¿Cómo trabaja? Identifia las correlaciones subyacentes entre las variables del conjunto de datos para proporcionar una representación en términos de un número pequeño de factores comunes latentes o no observables. "],
["otras-tecnicas.html", "3.5 Otras ‘Técnicas’", " 3.5 Otras ‘Técnicas’ Minería de Textos Video/Image Analytics Speech Analytics Stream Analytics "],
["que-tecnica-utilizar.html", "3.6 ¿Qué técnica utilizar?", " 3.6 ¿Qué técnica utilizar? Elegir el algoritmo adecuado puede parecer abrumador—hay docenas de algoritmos de statistical learning, y cada uno tiene una aproximación diferente. No existe un único mejor método o uno que sirva para todos los casos. Buscar el adecuado es a veces una tarea de prueba y error—incluso los científicos de datos con más experiencia no pueden saber si un algoritmo funcionará sin haberlo probado. La selección del algoritmo también depende del tamaño y del tipo de los datos con el que se está trabajando, los resultados que se quieren obtener y como dichos resultados serán usados. El primer paso, y uno de los más importantes, es definir el objetivo del análisis que se va a realizar. Volviendo al esquema propuesto por Marr (2017) (presentado en 1.1), Start with Strategy implica que, antes de empezar con los datos, se empiece con la definición de los objetivos de negocio que se quieren alcanzar. Inmediatamente después se definen los datos y las métricas que estarán involucradas. En este momento se conoce la naturaleza del problema y de la variable objetivo, por lo tanto se conoce si estamos delante de una variable continua o binaria, si se requiere de un modelo explicativo, si sólo se requiere una segmentación, etc. En consecuencia, una vez conocida la decisión que se requiere tomar y la variable objetivo que se analizará, se puede elegir el enfoque y modelo especíco que se va a utilizar. Considera utilizar un modelo estadístico si se debe priorizar el poder explicativo, se dispone de tiempo computacional y memoria para ajustar modelos relativamente complejos. Algunas situaciones donde este enfoque es útil son: Proceso de concesión de créditos, con modelos supervisados por la entidad reguladora. Asignación de presupuesto anual de marketing Determinación de metas de venta por distribuidor, centro, etc. Considera usar el machine learning cuando se tenga una tarea compleja o un problema que involucre una gran cantidad de datos o variables, pero no exista fórmula o ecuación. Por ejemplo, machine learning es una buena opción si se requieren manejar situaciones como: Las reglas y ecuaciones de escritura a mano son muy complejas—como reconocimiento facial o de voz. Las reglas de las tareas están cambiando constantemente—como en detección de fraude desde los registros de transacciones. La naturaleza de los datos es cambiante y el programa necesita adaptarse—como en el trading automático, previsión de demanda de energía y predicción de tendencias en compras. Algunas consideraciones al elegir un algoritmo son6: Precisión No siempre es necesario obtener la respuesta más precisa posible. A veces, una aproximación ya es útil, según para qué se la desee usar. Si es así, puede reducir el tiempo de procesamiento de forma considerable al usar métodos más aproximados. Otra ventaja de los métodos más aproximados es que tienden naturalmente a evitar el sobreajuste. Tiempo (de entrenamiento) La cantidad de minutos u horas necesarios para modelizar varía mucho según el algoritmo. A menudo, el tiempo depende de la precisión (generalmente, uno determina al otro). Además, algunos algoritmos son más sensibles a la cantidad de datos que otros. Si el tiempo es limitado, esto puede determinar la elección del algoritmo, especialmente cuando el conjunto de datos es grande. Cantidad de parámetros Los parámetros son los botones que el analista activa al configurar un algoritmo. Son números que afectan al comportamiento del algoritmo, como la tolerancia a errores o la cantidad de iteraciones, o bien opciones de variantes de comportamiento del algoritmo. El tiempo de entrenamiento y la precisión del algoritmo a veces pueden ser muy sensibles y requerir solo la configuración correcta. Normalmente, los algoritmos con muchos parámetrosla mayor cantidad de pruebas para encontrar una buena combinación. La ventaja es que tener muchos parámetros normalmente indica que un algoritmo tiene mayor flexibilidad. Se puede lograr una precisión muy alta, siempre y cuando se encuentre la combinación correcta de configuraciones de parámetros. Cantidad de variables Para ciertos tipos de datos, la cantidad de variables o características puede ser muy grande en comparación con la cantidad de datos. Este suele ser el caso de la genética o los datos textuales. Una gran cantidad de características puede trabar algunos algoritmos y provocar que el tiempo de procesamiento sea demasiado largo. Linealidad Muchos algoritmos hacen uso de la linealidad. Los algoritmos de clasificación lineal suponen que las clases pueden estar separadas mediante una línea recta (o su análogo de mayores dimensiones). Entre ellos, se encuentran la regresión logística y las máquinas de vectores de soporte (svm). Los algoritmos de regresión lineal suponen que las tendencias de datos siguen una línea recta. Estas suposiciones no son incorrectas para algunos problemas, pero en otros disminuyen la precisión. Casos especiales Algunos algoritmos hacen determinadas suposiciones sobre la estructura de los datos o los resultados deseados. Si encuentra uno que se ajuste a sus necesidades, este puede ofrecerle resultados más útiles, predicciones más precisas o tiempos de procesamiento más cortos. References "],
["evaluacion-de-modelos.html", "Capítulo 4 Evaluación de modelos", " Capítulo 4 Evaluación de modelos El ciclo de vida de un modelo empieza con su propia definición, pasando por la extracción y tratamiento de los datos y la evaluación, tanto antes de ponerlo en producción, como en la monitorización de su calidad predictiva. La diagnosis o evaluación es la clave para lograr un ecosistema de modelos que impacte en la organización. Hay muchas métricas para evaluar como de bien o de mal funciona un modelo o algoritmo. Para determinar cuáles usar en un problema particular, necesitamos formas sistemáticas de evaluar cómo funcionan los diferentes métodos y comparar uno con otro. La evaluación no es tan simple como podría parecer a primera vista. La diagnosis de los modelos puede realizarse desde dos perspectivas: Negocio y Estadística. Ambas pueden ser utilizadas para monitorizar la calidad de los modelos en producción. La frecuencia de análisis depende del tipo de modelo. Diagnosis de Negocio: Se refiere a la utilización de métricas que indican si se cumplen las hipótesis sobre las cuales se ha construido el modelo, además de evaluar su calidad predictiva. Ejemplo de estas métricas son: R2, MAPE, AUC, LIFT, etc Diagnosis Estadística: Se refiere a la discusión del significado de los resultados, teniendo en cuenta el sentido del negocio. Elementos susceptibles de esta interpretación son: parámetros, análisis decom, due-to, etc. "],
["diagnosis-de-negocio.html", "4.1 Diagnosis de Negocio", " 4.1 Diagnosis de Negocio Los parámetros de los modelos estadisticos sirven para cuantificar el efecto de las palancas. Su interpretación depende de la propia especificación del modelo. Los principales tipos de parámetros son: elasticidad, semi-elasticidad, piecewise, yes/no. Si el output es 0-1, la interpretación de los parámetros depende de la función enlace utilizada (logit o probit). Análisis de Descomposición. Mide el efecto de cada input o driver sobre el output de un periodo Análisis de due-to. Compara el efecto de los inputs o drivers en el output entre dos periodos "],
["evaluacion-en-respuesta-binaria.html", "4.2 Evaluación en Respuesta Binaria", " 4.2 Evaluación en Respuesta Binaria No todos los problemas son iguales, con lo que no todos los problemas pueden usar las mismas métricas de evaluación. En esta sección veremos las métricas más usuales para los tipos de problemas que nos podemos encontrar. Si nos centramos en modelos supervisados, nos encontramos básicamente dos problemas distintos: clasificación y regresión. 4.2.1 Clasificación En los problemas de clasificación tenemos la variable objetivo que son las clases o etiquetas que debemos predecir y una serie de variables que son los predictores. Es decir, usando los predictores obtenemos una etiqueta. Nos podemos encontrar con problemas de clasificación binaria (dos clases) o múltiple (más de dos clases). Para simplificar nos centraremos en la clasificación binaria, pero lo podemos trasladar a los problemas de clasificación múltiple. 4.2.1.1 Confusion matrix La confusion matrix o matriz de confusión muestra el número de predicciones correctas e incorrectas hechas por el modelo de clasificación en comparación con los resultados reales en los datos. La matriz de confusión es una matriz \\(n \\times n\\), dónde \\(n\\) es el número de clases. La siguiente tabla muestra una matriz de confusión de \\(2x2\\) para dos clases (positiva y negativa). Accuracy: la proporción del número total de predicciones correctas. \\[ACC = \\frac{TP+TN}{TP+TN+FP+FN}\\] Positive Predictive Value or Precision: la proporción de casos positivos que fueron identificados correctamente. \\[PPV = \\frac{TP}{TP+FP}\\] Negative Predictive Value: la proporción de casos negativos que fueron identificados correctamente. \\[ NPV = \\frac{TN}{TN+FN} \\] Sensitivity or Recall: la proporción de casos positivos reales que están correctamente identificados. \\[TPR = \\frac{TP}{TP+FN}\\] Specificity: la proporción de casos negativos reales que están correctamente identificados. \\[TNR = \\frac{TN}{TN+FP}\\] 4.2.1.2 Log-Loss La log-loss o pérdida logarítmica entra en los detalles más finos de un clasificador. En particular, si la salida bruta del clasificador es una probabilidad numérica en lugar de una etiqueta de clase de \\(0\\) o \\(1\\), se puede usar la log-loss. La probabilidad se puede entender como un indicador de confianza. Si la etiqueta es \\(0\\) pero el clasificador cree que pertenece a la clase \\(1\\) con probabilidad de \\(0,51\\). Aunque el clasificador estaría cometiendo un error de clasificación, el error se comente por poco, ya que la probabilidad está muy cerca del punto de corte de \\(0.5\\). La log-loss es una medición de precisión que incorpora esta idea de confianza probabilística. La log-loss para un clasificador binario es \\[LogLoss = - \\frac{1}{n} \\sum_{i=1}^{n} y_i \\log p_i + (1-y_i) \\log (1-p_i)\\] donde \\(n\\) es el número de registros, \\(y_i\\) es la etiqueta de la muestra \\(i\\), y \\(p_i\\) es la probabilidad del obtenida en el modelo. 4.2.1.3 Curvas ROC Para los modelos de clasificación obtenidos a partir de una probabilidad se suelen usar las curvas ROC. Una curva ROC (acrónimo de Receiver Operating Characteristic, o Característica Operativa del Receptor) es una representación gráfica de la sensitivity (TPR) frente a la specificity (TNR) para un sistema clasificador binario según se varía el umbral de discriminación. La curva ROC se puede usar para generar estadísticos que resumen el rendimiento (o la efectividad, en su más amplio sentido) del clasificador. A continuación se proporcionan algunos: El punto de inserción de la curva ROC con la línea convexa a la línea de discriminación. El área entre la curva ROC y la línea de convexo-paralela discriminación. El área bajo la curva ROC, llamada comúnmente AUC (area under curve). El indicador más utilizado en muchos contextos es el área bajo la curva ROC o AUC. Este índice se puede interpretar como la probabilidad de que un clasificador ordenará o puntuará una instancia positiva elegida aleatoriamente más alta que una negativa. En la figura abajo se muestran tres ejemplos de curvas ROC. La gráfica de la izquierda es la curva de un modelo perfecto, la del medio es la de un caso real con una \\(AUC = 0.8\\) y la de la derecha es la gráfico de un modelo no informativo. 4.2.1.4 Gráficos de ganancia y elevación (Gain and Lift Charts) La ganancia o la elevación es una medida de la efectividad de un modelo de clasificación calculado como la relación entre los resultados obtenidos con y sin el modelo. Los gráficos de ganancia y elevación son ayudas visuales para evaluar el rendimiento de los modelos de clasificación. Sin embargo, en contraste con la matriz de confusión que evalúa los modelos en toda la población, los gráficos de ganancia o elevación evalúan el modelo en una porción de la población. Para crear estos gráficos es necesario crear un ranking basado en la creabilidad de la predicción hecha por el modelo. En la figura tenemos un ejemplo de como obtener los puntos de las curvas de ganancia y elevación, y sus correspondientes gráficos. Igual que las curvas ROC, se busca el mayor AUC en las curvas de ganancia. Mientras que para los gráficos de elevación el modelo perfecto es el que la diferencia entre la línea azul y roja es nula. En otras palabras queremos una AUC mínima del gráfico de elevación. 4.2.2 Medidas de desigualdad 4.2.2.1 El coeficiente de Gini El coeficiente de Gini es una medida de la desigualdad ideada por el estadístico italiano Corrado Gini. El coeficiente de Gini es un número entre \\(0\\) y \\(1\\), en donde \\(0\\) se corresponde con la perfecta igualdad y donde el valor \\(1\\) se corresponde con la perfecta desigualdad. El coeficiente de Gini se calcula como una proporción de las áreas en el diagrama de la curva de Lorenz. De forma resumida, la Curva de Lorenz es una gráfica de concentración acumulada de la distribución superpuesta a la curva de la distribución de frecuencias de los individuos, y su expresión en porcentajes es el índice de Gini. El coeficiente de Gini puede obtener mediante la siguiente fórmula: \\[G = \\left| 1-\\sum_{k=1}^{n-1} (X_{k+1}-X_k)(Y_{k+1}+Y_k) \\right|\\] donde \\(X\\) es la proporción acumulada de la variable población, \\(Y\\) es la proporción acumulada de la variable a estudiar la desigualdad y \\(n\\) es el número de la población. 4.2.2.2 Índice de entropía El índice de entropía generalizado se ha propuesto como una medida de la desigualdad en una población. Se deriva de la teoría de la información como una medida de redundancia en los datos. En la teoría de la información, una medida de redundancia puede interpretarse como no aleatoriedad o compresión de datos; por lo tanto, esta interpretación también se aplica a este índice. La fórmula de la entropía general para un valor real \\(\\alpha\\) es: \\[GE(\\alpha) = \\begin{cases} \\frac{1}{n\\alpha (\\alpha -1)} \\sum_{i=1}^{n} \\left(\\left( \\frac{y_i}{\\bar{y}} \\right) ^{\\alpha} -1\\right), &amp;\\quad \\alpha\\neq0,1 ,\\\\ \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i}{\\bar{y}} \\ln \\frac{y_i}{\\bar{y}} &amp;\\quad \\alpha = 1 ,\\\\ -\\frac{1}{n} \\sum_{i=1}^{n} \\ln \\frac{y_i}{\\bar{y}} &amp;\\quad \\alpha = 0 .\\\\ \\end{cases}\\] donde \\(n\\) el número de muestras y \\(y\\) es la medida de desigualdad. "],
["evaluacion-en-respuesta-continua.html", "4.3 Evaluación en Respuesta Continúa", " 4.3 Evaluación en Respuesta Continúa 4.3.1 Modelos de Regresión En los problemas de regresión siempre tenemos una variable numérica dependiente que es la que queremos predecir y el resto son los predictores. Para evaluar los modelos de regresión tenemos varias métricas para evaluar el error cometido en al predicción: RMSE (root mean squared error) o error cuadrado medio: RMSE es la métrica más popular para medir la tasa de error de un modelo de regresión. \\[RMSE = \\sqrt {\\frac{\\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2}{n}}\\] donde \\(n\\) es el número de muestras, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. MAE (mean abosulte error) o error absoluto medio: \\[MAE = \\frac{\\sum_{i=1}^{n} | \\hat{y}_i - y_i |}{n}\\] donde \\(n\\) es el número de muestras, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. RSE (relative squared error) o error relativo cuadrado: \\[RSE = \\sqrt \\frac{\\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2}{\\sum_{i=1}^{n} (\\bar{y} - y_i)^2}\\] donde \\(n\\) es el número de muestras, \\(\\bar{y}\\) es la media de la variable objetivo, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. RAE (relative absolute error) o error relativo absoluto: \\[RAE = \\frac{\\sum_{i=1}^{n} |\\hat{y}_i - y_i|}{\\sum_{i=1}^{n} |\\bar{y} - y_i|}\\] donde \\(n\\) es el número de muestras, \\(\\bar{y}\\) es la media de la variable objetivo, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. Coeficiente \\(R^2\\): \\(R^2\\) resume el poder explicativo del modelo de regresión y se calcula a partir de los términos de las sumas de cuadrados. El coeficiente \\(R^2\\) toma valores entre \\(0\\) y \\(1\\), si \\(R^2=1\\) la regresión es perfecta. \\[R^2 = \\frac {SSR}{SST} = 1 - \\frac{SSE}{SST}, \\] donde \\[SST = \\sum_{i=1}^{n} (y - \\bar{y})^2 ,\\] \\[SSR = \\sum_{i=1}^{n} (\\hat{y} - \\bar{\\hat{y}})^2 ,\\] \\[SSE = \\sum_{i=1}^{n} (y-\\hat{y})^2 .\\] 4.3.2 Modelos de Series temporales Las series temporales son básicamente un problema de regresión. La diferencia es que hay una variable temporal y el objetivo es predecir el futuro dado un histórico. Por lo tanto, las métricas utilizadas son las mismas que las usadas para los problemas de regresión vistas en la sección anterior. Otras métricas usadas frecuentemente para la evaluación de series temporales son: MAPE MAPE viene de Mean Absolute Percentage Error. Los errores porcentuales tienen la ventaja de ser independientes de la escala y, por lo tanto, se utilizan con frecuencia para comparar el rendimiento del pronóstico entre diferentes conjuntos de datos. MAPE es el más usual. \\[MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{100·|\\hat{y_i}-y_i|}{y_i}\\] AIC AIC viene de Akaike information criterion. Se define como \\[AIC = 2k-2\\ln (\\hat{L})\\] Dado un conjunto de modelos candidatos para los datos, el modelo preferido es el que tiene el valor mínimo en el AIC. Por lo tanto AIC no sólo recompensa la bondad de ajuste, sino también incluye una penalidad, que es una función creciente del número de parámetros estimados. BIC BIC**_ viene de Bayesian Information Criterion)_. Se define como \\[BIC = \\ln (n) k - 2 \\ln (\\hat{L})\\] donde \\(\\hat{L}\\) es máximo de la función de verosimilitud, \\(n\\) es el número de muestras, \\(k\\) es el número de parámetros estimados por el modelo. La fórmula del BIC es similar a la fórmula del AIC, pero con una penalización distinta que varia según el número de muestras de los datos. "],
["evaluacion-en-clustering.html", "4.4 Evaluación en Clustering", " 4.4 Evaluación en Clustering El Clustering es una forma de tratar los datos para los que no se conocen o no están definidos los grupos. Por tanto, tenemos que conceptualizar los grupos. Este hecho dificultad evaluar la calidad de los clasificación obtenida. 4.4.1 Silueta El coeficiente silueta proporciona una representación gráfica del grado de integración de un objeto en su cluster. El coeficiente silueta de un objeto \\(i\\) se define como: \\[s_i=\\dfrac{b_i -a_i}{max(b_i -a_i)}\\] donde \\(a_i\\) denota la distancia media entre el objeto \\(i\\) y todos los otros objetos de su cluster y \\(b_i\\) denota la distancia media mínima entre \\(i\\) y los objetos de otros clusters. Los objetos con un coeficiente de silueta \\(s_i\\) alto están bien integrados en su cluster; aquéllos con un si bajo tienden a estar entre clusters. "],
["metodos-de-re-muestreo.html", "4.5 Métodos de re-muestreo", " 4.5 Métodos de re-muestreo 4.5.1 Training &amp; testing Lo primero que debemos hacer para conseguir una buena evaluación es dividir los datos en dos subconjuntos. Uno para entrenar el modelo (training) y otro para evaluar el modelo (testing). El partición entre estos dos subconjuntos suele hacerse de forma aleatoria, aunque según el problema podemos usar otros criterios. Por ejemplo, si los datos que tenemos son una serie temporal, entonces podemos dividirlos a partir de un cierto tiempo. Es decir, coger como test los datos más recientes. La razón de hacer esta división es usar los datos del subconjunto training para entrenar el modelo y luego evaluar los datos del testing. De esta manera simulamos correctamente una evaluación, ya que no podemos evaluar unos datos si hemos entrenado con ellos. Por lo tanto, los datos de testing no deben ser observados por el algoritmo. 4.5.2 Cross validation El procedimiento que se suele usar para evaluar un modelo es cross validation o validación cruzada. La idea básica de cross validation consiste en dividir los datos en \\(k\\) subconjuntos. Cada subconjunto se predice mediante un modelo entrenado con el resto. De esta manera podemos hacer una evaluación sobre todos los datos y evitamos el problema de obtener una muestra sesgada si sólo lo hiciéramos una vez. "],
["practica-en-r.html", "4.6 Práctica en R", " 4.6 Práctica en R Evaluaremos la calidad predictiva de dos modelos: Cuando la variable respuesta es binaria. Cuando la variable respuesta es contínua. 4.6.1 Preparación de los datos Definimos el Entorno de Trabajo El primer paso es crear una carpeta con nuestros modelos y resultados dentro de nuestro espacio de trabajo (proyecto). Obtenemos la ruta completa del directorio de trabajo7. myWD &lt;- getwd() Elegimos un nombre para nuestra carpeta con resultados myWorkingFolderName &lt;- &#39;ModelResults&#39; Creamos la carpeta donde guardaremos nuestros resultados y ficheros dir.create( paste0(getwd(),&quot;/&quot;,myWorkingFolderName)) Accedemos a los datos originales Cargamos la librería insuranceData que contiene los datos que utilizaremos8 if (!require(insuranceData)) install.packages(&#39;insuranceData&#39;) library(insuranceData) Para ver los contenidos de la librería insuranceData ejecutamos: data(package=&#39;insuranceData&#39;) Vemos que hay 10 datasets. Trabajaremos con el primero: AutoBi (Automobile Bodily Injury Claims9). Cargamos el conjunto de datos seleccionado: pérdidas en accidentes de coches data(&quot;AutoBi&quot;) Descripción de las 8 variables del conjunto de datos (tabla) ‘AutoBi’: Casenum. Identificador de la reclamación (esta variable no se utiliza en los modelos) Attorney. Indica si el reclamante está representado por un abogado (1= Sí, 2 = No) Clmsex. Sexo del reclamante (1 = Hombre, 2 = Mujer) Marital. Estado Civil del reclamante (1 = Casado, 2 = Soltero, 3 = Viudo, 4 = divorciado/separado) Clminsur. Indica si el conductor del vehículo del reclamante estaba o no asegurado (1 = Si, 2 = No, 3 = No aplica) Seatbelt. Si el reclamante llevaba o no un cinturón de seguridad en el asiento infantil (1 = Si, 2 = No, 3 = No Aplica) Clmage. Edad del reclamante. Loss (*). La pérdida económica total del reclamante (en miles). Esta es la variable objetivo o dependiente del conjunto de datos. Revisamos el contenido de la tabla y el tipo de datos que contiene str(AutoBi) FALSE &#39;data.frame&#39;: 1340 obs. of 8 variables: FALSE $ CASENUM : int 5 13 66 71 96 97 120 136 152 155 ... FALSE $ ATTORNEY: int 1 2 2 1 2 1 1 1 2 2 ... FALSE $ CLMSEX : int 1 2 1 1 1 2 1 2 2 1 ... FALSE $ MARITAL : int NA 2 2 1 4 1 2 2 2 2 ... FALSE $ CLMINSUR: int 2 1 2 2 2 2 2 2 2 2 ... FALSE $ SEATBELT: int 1 1 1 2 1 1 1 1 1 1 ... FALSE $ CLMAGE : int 50 28 5 32 30 35 19 34 61 NA ... FALSE $ LOSS : num 34.94 10.892 0.33 11.037 0.138 ... Exploramos el contenido con estadísticos descriptivos básicos summary(AutoBi) FALSE CASENUM ATTORNEY CLMSEX MARITAL FALSE Min. : 5 Min. :1.000 Min. :1.000 Min. :1.000 FALSE 1st Qu.: 8579 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 FALSE Median :17453 Median :1.000 Median :2.000 Median :2.000 FALSE Mean :17213 Mean :1.489 Mean :1.559 Mean :1.593 FALSE 3rd Qu.:25703 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:2.000 FALSE Max. :34253 Max. :2.000 Max. :2.000 Max. :4.000 FALSE NA&#39;s :12 NA&#39;s :16 FALSE CLMINSUR SEATBELT CLMAGE LOSS FALSE Min. :1.000 Min. :1.000 Min. : 0.00 Min. : 0.005 FALSE 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:19.00 1st Qu.: 0.640 FALSE Median :2.000 Median :1.000 Median :31.00 Median : 2.331 FALSE Mean :1.908 Mean :1.017 Mean :32.53 Mean : 5.954 FALSE 3rd Qu.:2.000 3rd Qu.:1.000 3rd Qu.:43.00 3rd Qu.: 3.995 FALSE Max. :2.000 Max. :2.000 Max. :95.00 Max. :1067.697 FALSE NA&#39;s :41 NA&#39;s :48 NA&#39;s :189 Para llamar directamente a las variables por sus nombres en la tabla AutoBi utilizamos el comando attach attach(AutoBi) Exploramos la variable objetivo LOSS es la variable objetivo una variable altamente asimétrica (con posibles outliers a la derecha o pérdida muy severa)10. Analizamos la variable target summary(LOSS) FALSE Min. 1st Qu. Median Mean 3rd Qu. Max. FALSE 0.005 0.640 2.331 5.954 3.995 1067.697 Analizamos la distribución de la variable target hist(LOSS, breaks=300 , probability = T) lines(density(LOSS), col=&quot;red&quot;,main=&quot;Loss distribution&quot;) Utilizamos una medida robusta (depende de la mediana y del IQR11) para segmentar los datos en dos clases: 1 si las pérdidas son atípicamente altas o 0 si no lo son. lsup &lt;- median(LOSS) + 1.5*IQR(LOSS) # Criterio basado en estadisticos robustos sum(LOSS&gt;=lsup) # 153 datos de perdidas atipicamente altas FALSE [1] 153 (Opcional) Guardamos el gráfico del histograma de las pérdidas no severas Path_to_graphics &lt;- paste0(getwd(),&quot;/&quot;,&quot;Graphics&quot;) dir.create(Path_to_graphics) png(paste0(Path_to_graphics,&quot;/histograma.png&quot;)) hist(LOSS[LOSS&lt;lsup], breaks = 100, probability = T, xlab=&quot;loss (pérdida en miles US $)&quot;, main=&quot;Pérdida no severa&quot;) lines(density(LOSS[LOSS&lt;lsup]),col=&quot;red&quot;) dev.off() FALSE png FALSE 2 Creamos el dataset de trabajo. Creamos un dataset o tabla de trabajo eliminando la variable CASENUM (id) y filtrando por la variable LOSS y el valor lsup= 72.22587 (miles). df_autobi &lt;- AutoBi[ , -match(&quot;CASENUM&quot;, colnames(AutoBi)) ] Fijamos los predictores categóricos como factores: Representado por un abogado: ‘1’ = representado por letrado y ‘2’ = no representado df_autobi$ATTORNEY &lt;- ordered(df_autobi$ATTORNEY, levels = 1:2) Sexo: ‘1’ = hombre y ‘2’ = mujer df_autobi$CLMSEX &lt;- ordered(df_autobi$CLMSEX , levels = 1:2) Estado civil: ‘1’ = casado, ‘2’ = soltero, ‘3’ = viudo y ‘4’ = divorciado / separado df_autobi$MARITAL &lt;- ordered(df_autobi$MARITAL , levels = 1:4) Vehículo asegurado: ‘1’ = vehículo estaba asegurado y ‘2’= no lo estaba df_autobi$CLMINSUR &lt;- ordered(df_autobi$CLMINSUR, levels = 1:2) Cinturón de seguridad: ‘1’ = llevaba cinturón abrochado y ‘2’ = no lo llevaba df_autobi$SEATBELT &lt;- ordered(df_autobi$SEATBELT, levels = 1:2) Pérdida: ‘1’= pérdida severa y ‘2’= pérdida no severa df_autobi$Y &lt;- ifelse(df_autobi$LOSS&gt;= lsup,1,0) Exploramos el dataset que acabamos de crear y verificamos la proporción de casos con pérdida severa (11.42%) summary(df_autobi) FALSE ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE FALSE 1:685 1 :586 1 :624 1 : 120 1 :1270 Min. : 0.00 FALSE 2:655 2 :742 2 :650 2 :1179 2 : 22 1st Qu.:19.00 FALSE NA&#39;s: 12 3 : 15 NA&#39;s: 41 NA&#39;s: 48 Median :31.00 FALSE 4 : 35 Mean :32.53 FALSE NA&#39;s: 16 3rd Qu.:43.00 FALSE Max. :95.00 FALSE NA&#39;s :189 FALSE LOSS Y FALSE Min. : 0.005 Min. :0.0000 FALSE 1st Qu.: 0.640 1st Qu.:0.0000 FALSE Median : 2.331 Median :0.0000 FALSE Mean : 5.954 Mean :0.1142 FALSE 3rd Qu.: 3.995 3rd Qu.:0.0000 FALSE Max. :1067.697 Max. :1.0000 FALSE Exploramos la relación de la pérdida con los factores. agg_loss_attorney &lt;- aggregate(LOSS, by = list(ATTORNEY) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_attorney)[[1]] &lt;- c(&quot;REPRESENTED&quot;,&quot;NOT REPRESENTED&quot;) ; dimnames(agg_loss_attorney)[[2]] &lt;- c(&quot;ATTORNEY&quot;,&quot;LOSS&quot;) agg_loss_clmsex &lt;- aggregate(LOSS, by = list(CLMSEX) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_clmsex)[[1]] &lt;- c(&quot;MALE&quot;,&quot;FEMALE&quot;) ; dimnames(agg_loss_clmsex)[[2]] &lt;- c(&quot;CLMSEX&quot;,&quot;LOSS&quot;) agg_loss_marital &lt;- aggregate(LOSS, by = list(MARITAL) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_marital)[[1]] &lt;- c(&quot;MARRIED&quot;,&quot;SINGLE&quot;,&quot;WIDOW&quot;,&quot;DIVORCED&quot;) ; dimnames(agg_loss_marital)[[2]] &lt;- c(&quot;MARITAL&quot;,&quot;LOSS&quot;) agg_loss_clminsur &lt;- aggregate(LOSS, by = list(CLMINSUR) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_clminsur)[[1]] &lt;- c(&quot;INSURED&quot;,&quot;NOT INSURED&quot;) ; dimnames(agg_loss_clminsur)[[2]] &lt;- c(&quot;CLMINSUR&quot;,&quot;LOSS&quot;) agg_loss_seatbelt &lt;- aggregate(LOSS, by = list(SEATBELT) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_seatbelt)[[1]] &lt;- c(&quot;SEATBELT&quot;,&quot;NOT SEATBELT&quot;) ; dimnames(agg_loss_seatbelt)[[2]] &lt;- c(&quot;SEATBELT&quot;,&quot;LOSS&quot;) Creamos los sets train y test Aleatorizamos los datos y separamos el set de datos en train y test: N=nrow(df_autobi) Es recomendable fijar una semilla (seed) para los algoritmos de aleatorización internos de R if (!require(caret)) install.packages(&#39;caret&#39;) library(caret) set.seed(123456) inTrain &lt;- createDataPartition(df_autobi$Y, times = 1, p = 0.7, list = TRUE) dt_train &lt;- df_autobi[inTrain[[1]],] # 938 casos dt_test &lt;- df_autobi[-inTrain[[1]],] # 402 casos nrow(dt_train) FALSE [1] 938 summary(dt_train) FALSE ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE FALSE 1:471 1 :406 1 :439 1 : 77 1 :885 Min. : 0.00 FALSE 2:467 2 :523 2 :455 2 :833 2 : 17 1st Qu.:20.00 FALSE NA&#39;s: 9 3 : 10 NA&#39;s: 28 NA&#39;s: 36 Median :32.00 FALSE 4 : 25 Mean :33.06 FALSE NA&#39;s: 9 3rd Qu.:43.00 FALSE Max. :95.00 FALSE NA&#39;s :134 FALSE LOSS Y FALSE Min. : 0.0050 Min. :0.0000 FALSE 1st Qu.: 0.7123 1st Qu.:0.0000 FALSE Median : 2.3645 Median :0.0000 FALSE Mean : 5.4656 Mean :0.1141 FALSE 3rd Qu.: 4.0263 3rd Qu.:0.0000 FALSE Max. :273.6040 Max. :1.0000 FALSE nrow(dt_test) FALSE [1] 402 summary(dt_test) FALSE ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE FALSE 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 FALSE 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 FALSE NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 FALSE 4 : 10 Mean :31.31 FALSE NA&#39;s: 7 3rd Qu.:42.00 FALSE Max. :78.00 FALSE NA&#39;s :55 FALSE LOSS Y FALSE Min. : 0.0050 Min. :0.0000 FALSE 1st Qu.: 0.5175 1st Qu.:0.0000 FALSE Median : 2.1645 Median :0.0000 FALSE Mean : 7.0917 Mean :0.1144 FALSE 3rd Qu.: 3.7782 3rd Qu.:0.0000 FALSE Max. :1067.6970 Max. :1.0000 FALSE Comprobamos si se que los conjuntos train y test se han formado correctamente length(intersect(inTrain, setdiff(1:N,inTrain))) FALSE [1] 0 4.6.2 Clasificación Vamos a construir un modelo para identificar los casos con pérdidas severas. El primer ejemplo lo hacemos con Random Forest if (!require(randomForest)) install.packages(&#39;randomForest&#39;) library(randomForest) Creamos un objeto de clase ‘formula’ y se lo pasamos como argumento a la función randomForest12 set.seed(123456) fmla.rf1 &lt;- as.formula(paste0(&quot;Y&quot;,&quot; ~&quot;,paste0(colnames(df_autobi[,-c(7,8)]),collapse = &quot;+&quot;),collapse = &quot;&quot;)) rf1 &lt;- randomForest( fmla.rf1, data =dt_train, ntree = 5000, # se ejecuta muy rapido, podemos utilizar ntree &gt; = 2500 replace =TRUE, mtry=4, maxnodes =50, importance = TRUE, proximity = TRUE, keep.forest = TRUE, na.action=na.omit) Exploramos el objeto con los resutados rf1 FALSE FALSE Call: FALSE randomForest(formula = fmla.rf1, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, importance = TRUE, proximity = TRUE, keep.forest = TRUE, na.action = na.omit) FALSE Type of random forest: regression FALSE Number of trees: 5000 FALSE No. of variables tried at each split: 4 FALSE FALSE Mean of squared residuals: 0.1009875 FALSE % Var explained: 4.3 summary(rf1) FALSE Length Class Mode FALSE call 11 -none- call FALSE type 1 -none- character FALSE predicted 759 -none- numeric FALSE mse 5000 -none- numeric FALSE rsq 5000 -none- numeric FALSE oob.times 759 -none- numeric FALSE importance 12 -none- numeric FALSE importanceSD 6 -none- numeric FALSE localImportance 0 -none- NULL FALSE proximity 576081 -none- numeric FALSE ntree 1 -none- numeric FALSE mtry 1 -none- numeric FALSE forest 11 -none- list FALSE coefs 0 -none- NULL FALSE y 759 -none- numeric FALSE test 0 -none- NULL FALSE inbag 0 -none- NULL FALSE terms 3 terms call FALSE na.action 179 omit numeric str(rf1) FALSE List of 19 FALSE $ call : language randomForest(formula = fmla.rf1, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, imp| __truncated__ ... FALSE $ type : chr &quot;regression&quot; FALSE $ predicted : Named num [1:759] 0.00767 0.000161 0.629748 0.008208 0.022047 ... FALSE ..- attr(*, &quot;names&quot;)= chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... FALSE ..- attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... FALSE .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... FALSE $ mse : num [1:5000] 0.102 0.129 0.121 0.115 0.113 ... FALSE $ rsq : num [1:5000] 0.0302 -0.2272 -0.1473 -0.0907 -0.071 ... FALSE $ oob.times : int [1:759] 1804 1942 1844 1864 1855 1780 1837 1782 1847 1807 ... FALSE $ importance : num [1:6, 1:2] 0.017697 -0.001602 0.004106 0.000933 0.0009 ... FALSE ..- attr(*, &quot;dimnames&quot;)=List of 2 FALSE .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE .. ..$ : chr [1:2] &quot;%IncMSE&quot; &quot;IncNodePurity&quot; FALSE $ importanceSD : Named num [1:6] 1.50e-04 8.42e-05 1.54e-04 8.18e-05 5.65e-05 ... FALSE ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE $ localImportance: NULL FALSE $ proximity : num [1:759, 1:759] 1 0.179 0 0.318 0 ... FALSE ..- attr(*, &quot;dimnames&quot;)=List of 2 FALSE .. ..$ : chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... FALSE .. ..$ : chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... FALSE $ ntree : num 5000 FALSE $ mtry : num 4 FALSE $ forest :List of 11 FALSE ..$ ndbigtree : int [1:5000] 99 99 99 99 99 99 99 99 99 99 ... FALSE ..$ nodestatus : int [1:99, 1:5000] -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ... FALSE ..$ leftDaughter : int [1:99, 1:5000] 2 4 6 8 10 12 14 16 18 20 ... FALSE ..$ rightDaughter: int [1:99, 1:5000] 3 5 7 9 11 13 15 17 19 21 ... FALSE ..$ nodepred : num [1:99, 1:5000] 0.1265 0.2198 0.0363 0.0115 0.2832 ... FALSE ..$ bestvar : int [1:99, 1:5000] 1 6 4 6 5 6 6 6 6 3 ... FALSE ..$ xbestsplit : num [1:99, 1:5000] 1.5 20.5 1.5 15.5 1.5 27.5 34.5 0 16.5 3.5 ... FALSE ..$ ncat : Named int [1:6] 1 1 1 1 1 1 FALSE .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE ..$ nrnodes : int 99 FALSE ..$ ntree : num 5000 FALSE ..$ xlevels :List of 6 FALSE .. ..$ ATTORNEY: num 0 FALSE .. ..$ CLMSEX : num 0 FALSE .. ..$ MARITAL : num 0 FALSE .. ..$ CLMINSUR: num 0 FALSE .. ..$ SEATBELT: num 0 FALSE .. ..$ CLMAGE : num 0 FALSE $ coefs : NULL FALSE $ y : Named num [1:759] 1 0 1 0 0 0 0 0 0 1 ... FALSE ..- attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... FALSE .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... FALSE ..- attr(*, &quot;names&quot;)= chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... FALSE $ test : NULL FALSE $ inbag : NULL FALSE $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language Y ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + SEATBELT + CLMAGE FALSE .. ..- attr(*, &quot;variables&quot;)= language list(Y, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) FALSE .. ..- attr(*, &quot;factors&quot;)= int [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ... FALSE .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 FALSE .. .. .. ..$ : chr [1:7] &quot;Y&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... FALSE .. .. .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE .. ..- attr(*, &quot;term.labels&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE .. ..- attr(*, &quot;order&quot;)= int [1:6] 1 1 1 1 1 1 FALSE .. ..- attr(*, &quot;intercept&quot;)= num 0 FALSE .. ..- attr(*, &quot;response&quot;)= int 1 FALSE .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; FALSE .. ..- attr(*, &quot;predvars&quot;)= language list(Y, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) FALSE .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:7] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... FALSE .. .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Y&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... FALSE $ na.action : &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... FALSE ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... FALSE - attr(*, &quot;class&quot;)= chr [1:2] &quot;randomForest.formula&quot; &quot;randomForest&quot; Gráfico de la importancia relativa de los predictores varImpPlot(rf1,sort = T,main = &quot;Variable Importance&quot;) Gráfico del Error vs número de árboles plot(rf1, main=&quot;Error de clasificación vs núero de árboles&quot;) Gráfico de la probabilidad condicional: \\(P(Y=1|X_1 = ATTORNEY,\\ldots,X_6=SEATBELT)\\) rf1.prediction &lt;- as.data.frame(predict(rf1, newdata = dt_train)) summary(rf1.prediction) ## predict(rf1, newdata = dt_train) ## Min. :0.00005 ## 1st Qu.:0.00599 ## Median :0.03651 ## Mean :0.11984 ## 3rd Qu.:0.21024 ## Max. :0.77138 ## NA&#39;s :179 dt_train$pred_rf1 &lt;- rf1.prediction$`predict(rf1, newdata = dt_train)` head(dt_train,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1 1 1 &lt;NA&gt; 2 1 50 34.940 1 NA ## 2 2 2 2 1 1 28 10.892 1 0.3807199932 ## 3 2 1 2 2 1 5 0.330 0 0.0001324938 tail(dt_train,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1335 2 2 2 2 1 26 0.161 0 0.001142849 ## 1338 2 2 1 2 1 39 0.099 0 0.012354460 ## 1340 2 2 2 2 1 30 0.688 0 0.002329733 summary(dt_train) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:471 1 :406 1 :439 1 : 77 1 :885 Min. : 0.00 ## 2:467 2 :523 2 :455 2 :833 2 : 17 1st Qu.:20.00 ## NA&#39;s: 9 3 : 10 NA&#39;s: 28 NA&#39;s: 36 Median :32.00 ## 4 : 25 Mean :33.06 ## NA&#39;s: 9 3rd Qu.:43.00 ## Max. :95.00 ## NA&#39;s :134 ## LOSS Y pred_rf1 ## Min. : 0.0050 Min. :0.0000 Min. :0.00005 ## 1st Qu.: 0.7123 1st Qu.:0.0000 1st Qu.:0.00599 ## Median : 2.3645 Median :0.0000 Median :0.03651 ## Mean : 5.4656 Mean :0.1141 Mean :0.11984 ## 3rd Qu.: 4.0263 3rd Qu.:0.0000 3rd Qu.:0.21024 ## Max. :273.6040 Max. :1.0000 Max. :0.77138 ## NA&#39;s :179 plot(density(dt_train$pred_rf1[!is.na(dt_train$pred_rf1)]), col=&quot;red&quot; , xlab=&quot;Probabilidad&quot; , main=&quot;Función de densidad estimada&quot;) Vemos que hay (claramente) dos concentraciones (clases) de probabilidades de pérdida, una concentración en torno a la probabilidad de pérdida no severa (\\(Y=0\\)) y otra para la pérdida severa (\\(Y=1\\)). Esto no lleva a la elección del punto de corte óptimo para obtener una regla de clasificación, es decir, un criterio para \\(Y_{predicted}=1\\) (pérdida severa), o bien, para \\(Y_{predicted}=0\\) (pérdida no severa). Una alternativa es el criterio de la Distancia de Kolmogorov-Smirnov (KS). Métricas de evaluación del poder de clasificación if (!require(ModelMetrics)) install.packages(&#39;ModelMetrics&#39;) library(ModelMetrics) if (!require(ROCR)) install.packages(&#39;ROCR&#39;) library(ROCR) if (!require(binaryLogic)) install.packages(&#39;binaryLogic&#39;) library(binaryLogic) Con el train creamos un objeto de tipo ‘prediction’13 rf1.pred &lt;- prediction(as.numeric(rf1$predicted),as.numeric(rf1$y)) Calculamos la Curva de ROC con la función ‘performance’ sobre el objeto ‘rf1’ rf1.perf &lt;- performance(rf1.pred,&quot;tpr&quot;,&quot;fpr&quot;) ## &quot;fpr&quot; = False positive rate. P(Yhat = + | Y = -). Estimated as: FP/N. ## &quot;tpr&quot; = True positive rate. P(Yhat = + | Y = +). Estimated as: TP/P. plot(rf1.perf) Elección del punto de corte: Criterio de la distancia de KS La distancia KS se calcula como: KS = abs(rf1.perf@y.values[[1]]-rf1.perf@x.values[[1]]) rf1.perf@alpha.values[[1]][rf1.perf@alpha.values[[1]]==Inf] &lt;- round(max(rf1.perf@alpha.values[[1]][rf1.perf@alpha.values[[1]]!=Inf]),2) KS.matrix= cbind(abs(rf1.perf@y.values[[1]]-rf1.perf@x.values[[1]]), rf1.perf@alpha.values[[1]]) Resumiendo colnames(KS.matrix) &lt;- c(&quot;KS-distance&quot;,&quot;cut-point&quot;) head(KS.matrix) ## KS-distance cut-point ## [1,] 0.000000000 0.7800000 ## [2,] 0.001497006 0.7809184 ## [3,] 0.002994012 0.7353170 ## [4,] 0.004491018 0.6577091 ## [5,] 0.005988024 0.6481896 ## [6,] 0.005000987 0.6297476 ind.ks &lt;- sort( KS.matrix[,1] , index.return=TRUE )$ix[nrow(KS.matrix)] El punto de corte óptimo de KS: rf1.KScutoff &lt;- KS.matrix[ind.ks,2] # := f(rf1.KS1) rf1.KScutoff ## cut-point ## 0.06415734 # 0.04 - 0.05 Gráfico de la Curva ROC y su métrica: Área bajo la curva ROC (AUC) Cálculo de AUC mediante la función ‘performance’ rf1.auc1 &lt;- performance(rf1.pred,&quot;auc&quot;)@y.values[[1]] rf1.auc1 FALSE [1] 0.7424327 -Cálculo de la curva ROC junto con la métrica AUC #win.graph() plot( rf1.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot;, xlab=&quot;Tasa de falsos positivos&quot; , ylab=&quot;Tasa de verdaderos positivos&quot;, main=&quot;Curva ROC con Random Forest&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4, 0.15 , c(paste0(&quot;AUC (Random Forest)=&quot;,round(rf1.auc1,4)),&quot;AUC (clasificacion al azar)=0.50&quot;),lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) Se realizar el mismo gráfico de la curva ROC utilizando la librería ggplot2. Para ello guardamos los datos en un data.frame library(&quot;ggplot2&quot;) df.perf &lt;- data.frame(x=rf1.perf@x.values[[1]],y=rf1.perf@y.values[[1]]) Construcción del objeto gráfico con ggplot2 #win.graph() p &lt;- ggplot(df.perf,aes(x=x,y=y)) + geom_path(size=1, colour=&quot;red&quot;) p &lt;- p + ggtitle(&quot;Curva ROC modelo Random Forest&quot;) p &lt;- p + theme_update(plot.title = element_text(hjust = 0.5)) p &lt;- p + geom_segment(aes(x=0,y=0,xend=1,yend=1),colour=&quot;blue&quot;,linetype= 2) p &lt;- p + geom_text(aes(x=0.75 , y=0.3 , label=paste(sep =&quot;&quot;,&quot;AUC (Random Forest) ) = &quot;,round(rf1.auc1,4) )),colour=&quot;black&quot;,size=4) p &lt;- p + geom_text(aes(x=0.75 , y=0.25 , label=paste(sep =&quot;&quot;,&quot;AUC (Coin toss) = &quot;,round(0.50,4) )),colour=&quot;black&quot;,size=4) p &lt;- p + scale_x_continuous(name= &quot;Tasa de falsos positivos&quot;) p &lt;- p + scale_y_continuous(name= &quot;Tasa de verdaderos positivos&quot;) p &lt;- p + theme( plot.title = element_text(size = 2), axis.text.x = element_text(size = 10), axis.text.y = element_text(size = 10), axis.title.x = element_text(size = 12,face = &quot;italic&quot;), axis.title.y = element_text(size = 12,face = &quot;italic&quot;,angle=90), legend.title = element_blank(), panel.background = element_rect(fill = &quot;grey&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(colour=&#39;white&#39;), plot.background = element_blank() ) p Métricas de evaluación del poder predictivo Calculamos la predicción en el test y evaluamos el poder de clasificación del modelo rf1.pred_test &lt;- as.data.frame(predict( rf1, newdata = dt_test)) dt_test$pred_rf1 &lt;- rf1.pred_test$`predict(rf1, newdata = dt_test)` head(dt_test,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.2279703 ## 12 1 1 1 2 1 42 29.620 1 0.2159590 ## 18 1 1 1 2 1 58 0.758 0 0.2047155 tail(dt_test,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.349066396 ## 1339 1 2 2 1 1 18 3.277 0 0.004032191 summary(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## 4 : 10 Mean :31.31 ## NA&#39;s: 7 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 ## Min. : 0.0050 Min. :0.0000 Min. :0.00005 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00797 ## Median : 2.1645 Median :0.0000 Median :0.03794 ## Mean : 7.0917 Mean :0.1144 Mean :0.12531 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.21666 ## Max. :1067.6970 Max. :1.0000 Max. :0.75036 ## NA&#39;s :70 Con el test creamos un objeto de tipo ‘prediction’ y calculamos la curva ROC dt_test.pred &lt;- prediction(as.numeric(rf1.pred_test$`predict(rf1, newdata = dt_test)`),dt_test$Y) dt_test.perf &lt;- performance(dt_test.pred,&quot;tpr&quot;,&quot;fpr&quot;) Evaluación del poder de clasificación del modelo RF1 vía curva ROC rf1.test.auc &lt;- performance(dt_test.pred ,&quot;auc&quot;)@y.values[[1]] Gráfico de la curva ROC para el test #win.graph() plot( dt_test.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot; , main=&quot;Curva ROC modelo RF - test&quot;,xlab=&quot;Tasa de falsos positivos&quot;, ylab=&quot;Tasa de verdaderos positivos&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4, 0.2 , c(paste0(&quot;AUC (Random Forest)=&quot;,round(rf1.test.auc,4)),&quot;AUC (Coin toss)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) Métrica de error del clasificador RF: Error tipo I (\\(\\alpha\\)): 22.50%, indica el error que se comete clasificando una pérdida ‘severa’ como ‘no severa’ Error tipo II (\\(\\beta\\)): 43.15%, indica el error que se comete clasificando una pérdida ‘no severa’ como ‘severa’ % mala clasificación (\\(%mc\\)) : 40.66%, indica el % de veces que el modelo clasifica incorrectamente las pérdidas Accuracy = \\(100 - %\\): 59.34%, indica el % de veces que el modelo acierta clasificando las pérdidas Area bajo la curva ROC \\(AUC\\): 0.6988, medida global del poder de clasificación del modelo Finalmente calculamos la curva ROC junto con la métrica AUC Resumiendo: Una función útil para obtener rápidamente el análisis de un clasificador binario es la siguiente: metricBinaryClass = function( fitted.model , dataset , cutpoint=NULL , roc.graph=TRUE){ # fitted.model : The Binary Classification model that is under evaluation. If provided, dataset contains all variables in the fitted model (target and predictors). # dataset : If fitted.model is not provided, dataset should has only two columns, predictions and labels. # cuttpoint : potimal cutoff or cutpoint to be used to split continuous predictions into two response categories of target variable # roc.graph : If true, ROC curve graph for the model is shown #install.packages(&quot;binaryLogic&quot;) library(binaryLogic) if( missing(fitted.model) | is.null(fitted.model) ){ tabl &lt;- as.data.frame(dataset) } else { if( class(fitted.model)[1] %in% c(&#39;glm&#39;,&#39;lm&#39;,&#39;randomForest.formula&#39;,&#39;randomForest&#39;) ){ tabl.pred &lt;- as.data.frame(predict( fitted.model, newdata = dataset )) tabl &lt;- as.data.frame(cbind(tabl.pred[[1]], dataset[,&#39;Y&#39;] )) tabl &lt;- tabl[!is.na(tabl[[1]]),] } if( class(fitted.model)[1] %in% c(&quot;gbm&quot;) ){ tabl.pred &lt;- as.data.frame(predict.gbm( fitted.model , newdata = dataset , n.trees = 5000 , type=&quot;response&quot; )) tabl &lt;- as.data.frame(cbind(tabl.pred[[1]], dataset[,&#39;Y&#39;] )) tabl &lt;- tabl[!is.na(tabl[[1]]),] } if( class(fitted.model)[1] %in% c(&#39;svm.formula&#39;,&#39;svm&#39;) ){ tabl.pred &lt;- as.data.frame(predict( fitted.model, newdata = dataset )) ids_NAs &lt;- na.index(dataset) tabl &lt;- as.data.frame( cbind(tabl.pred[[1]], dataset[-ids_NAs,&#39;Y&#39;]) ) tabl &lt;- tabl[!is.na(tabl[[1]]),] } } colnames(tabl) &lt;- c(&#39;predicted&#39;,&#39;actual&#39;) # ROCR objects require(ROCR) obj.pred &lt;- prediction(tabl$predicted,tabl$actual) obj.perf &lt;- performance(obj.pred,&quot;tpr&quot;,&quot;fpr&quot;) obj.auc &lt;- performance(obj.pred,&quot;auc&quot;)@y.values[[1]] # For ROC curve: obj.perf@alpha.values[[1]][obj.perf@alpha.values[[1]]==Inf] &lt;- max(obj.perf@alpha.values[[1]][obj.perf@alpha.values[[1]]!=Inf]) # KS criteria KS.matrix= cbind(abs(obj.perf@y.values[[1]]-obj.perf@x.values[[1]]), obj.perf@alpha.values[[1]]) # KS cutoff # colnames(KS.matrix) &lt;- c(&quot;KS-distance&quot;,&quot;cut-point&quot;) ind.ks &lt;- sort( KS.matrix[,1] , index.return=TRUE )$ix[nrow(KS.matrix)] if( missing(cutpoint) | is.null(cutpoint) ) cutpoint &lt;- KS.matrix[ind.ks,2] if( !(is.binary(tabl)) ){ # Make predictions objs. # Binary metrics tp = sum( tabl$predicted &gt; cutpoint &amp; tabl$actual &gt; cutpoint) fp = sum( tabl$predicted &gt; cutpoint &amp; tabl$actual &lt;= cutpoint) tn = sum( tabl$predicted &lt;= cutpoint &amp; tabl$actual &lt;= cutpoint) fn = sum( tabl$predicted &lt;= cutpoint &amp; tabl$actual &gt; cutpoint) pos = tp+fn neg = tn+fp acc= 100*(tp+tn)/(pos+neg) prec= 100*tp/(tp+fp) sens= 100*tp/(tp+fn) # = tpr = recall = 1 - error alpha spec= 100*tn/(tn+fp) # 1- error beta fpr = 100*fp/neg # error beta (tipo II) = 1 - spec fnr = 100*fn/pos # error alpha (tipo I) = 1- recall = 1- sens } if( is.binary(tabl) ){ tp = sum( tabl$predicted == 1 &amp; tabl$actual == 1) fp = sum( tabl$predicted == 1 &amp; tabl$actual == 0) tn = sum( tabl$predicted == 0 &amp; tabl$actual == 0) fn = sum( tabl$predicted == 0 &amp; tabl$actual == 1) pos = tp+fn neg = tn+fp acc= 100*(tp+tn)/(pos+neg) prec= 100*tp/(tp+fp) sens= 100*tp/(tp+fn) # = tpr = recall = 1 - error alpha spec= 100*tn/(tn+fp) # 1- error beta fpr = 100*fp/neg # error beta (tipo II) = 1 - spec fnr = 100*fn/pos # error alpha (tipo I) = 1- recall = 1- sens } if(roc.graph==TRUE){ win.graph() plot( obj.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot;,xlab=&quot;Tasa de falsos positivos&quot; , ylab=&quot;Tasa de verdaderos positivos&quot;, main=&quot;Curva ROC modelo clasificación&quot;) abline( 0.0 , 1.0 , col=&quot;blue&quot;, lwd=2, lty=2) abline( 0.0 , 0.0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.45, 0.2 , c(paste0(&quot;AUC (Model)=&quot;,round(obj.auc,4)),&quot;AUC (Rolling dice)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) } list(ClassError.tI=round(fnr,2), ClassError.tII=round(fpr,2), Accuracy=round(acc,2),Sensitivity = round(sens,2) , Specificity= round(spec,2), auc= obj.auc , Fisher.F1=round(2*prec*sens/(prec+sens),4) ) } metricBinaryClass( fitted.model = rf1 , dataset= dt_test , cutpoint=rf1.KScutoff , roc.graph=TRUE) ## $ClassError.tI ## [1] 22.5 ## ## $ClassError.tII ## [1] 43.49 ## ## $Accuracy ## [1] 59.04 ## ## $Sensitivity ## [1] 77.5 ## ## $Specificity ## [1] 56.51 ## ## $auc ## [1] 0.7056507 ## ## $Fisher.F1 ## [1] 31.3131 4.6.3 Regresión Vamos a construir un modelo para prever las pérdidas. Modelo con Random Forest en train fmla.rf2 &lt;- as.formula(paste0(&#39;LOSS&#39;,&#39;~&#39;,paste0(colnames(df_autobi[,-c(7,8)]),collapse = &quot;+&quot;),collapse = &#39;&#39;)) set.seed(112233) #recomendado rf2 &lt;- randomForest( fmla.rf2, data =dt_train, ntree = 5000, replace =TRUE, mtry=4, maxnodes =50, importance = TRUE, na.action=na.omit) summary(rf2) ## Length Class Mode ## call 9 -none- call ## type 1 -none- character ## predicted 759 -none- numeric ## mse 5000 -none- numeric ## rsq 5000 -none- numeric ## oob.times 759 -none- numeric ## importance 12 -none- numeric ## importanceSD 6 -none- numeric ## localImportance 0 -none- NULL ## proximity 0 -none- NULL ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## forest 11 -none- list ## coefs 0 -none- NULL ## y 759 -none- numeric ## test 0 -none- NULL ## inbag 0 -none- NULL ## terms 3 terms call ## na.action 179 omit numeric str(rf2) ## List of 19 ## $ call : language randomForest(formula = fmla.rf2, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, imp| __truncated__ ## $ type : chr &quot;regression&quot; ## $ predicted : Named num [1:759] 2.407 0.676 37.029 1.73 4.229 ... ## ..- attr(*, &quot;names&quot;)= chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... ## ..- attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ mse : num [1:5000] 566 483 441 401 427 ... ## $ rsq : num [1:5000] -0.707 -0.457 -0.328 -0.208 -0.286 ... ## $ oob.times : int [1:759] 1820 1870 1853 1846 1856 1840 1820 1899 1880 1876 ... ## $ importance : num [1:6, 1:2] 17.313 0.136 -3.726 3.199 4.752 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..$ : chr [1:2] &quot;%IncMSE&quot; &quot;IncNodePurity&quot; ## $ importanceSD : Named num [1:6] 1.215 1.018 1.116 0.38 0.743 ... ## ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## $ localImportance: NULL ## $ proximity : NULL ## $ ntree : num 5000 ## $ mtry : num 4 ## $ forest :List of 11 ## ..$ ndbigtree : int [1:5000] 99 99 99 99 99 99 99 99 99 99 ... ## ..$ nodestatus : int [1:99, 1:5000] -3 -3 -3 -3 -3 -3 -1 -3 -3 -3 ... ## ..$ leftDaughter : int [1:99, 1:5000] 2 4 6 8 10 12 0 14 16 18 ... ## ..$ rightDaughter: int [1:99, 1:5000] 3 5 7 9 11 13 0 15 17 19 ... ## ..$ nodepred : num [1:99, 1:5000] 4.96 4.6 23.76 7.19 1.9 ... ## ..$ bestvar : int [1:99, 1:5000] 5 1 6 3 6 3 0 6 2 3 ... ## ..$ xbestsplit : num [1:99, 1:5000] 1.5 1.5 37.5 3.5 20.5 1.5 0 25.5 1.5 1.5 ... ## ..$ ncat : Named int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## ..$ nrnodes : int 99 ## ..$ ntree : num 5000 ## ..$ xlevels :List of 6 ## .. ..$ ATTORNEY: num 0 ## .. ..$ CLMSEX : num 0 ## .. ..$ MARITAL : num 0 ## .. ..$ CLMINSUR: num 0 ## .. ..$ SEATBELT: num 0 ## .. ..$ CLMAGE : num 0 ## $ coefs : NULL ## $ y : Named num [1:759] 10.892 0.33 11.037 0.138 3.538 ... ## ..- attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## ..- attr(*, &quot;names&quot;)= chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... ## $ test : NULL ## $ inbag : NULL ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language LOSS ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + SEATBELT + CLMAGE ## .. ..- attr(*, &quot;variables&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;factors&quot;)= int [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ... ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:7] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## .. .. .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;term.labels&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;order&quot;)= int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;intercept&quot;)= num 0 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:7] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## $ na.action : &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;randomForest.formula&quot; &quot;randomForest&quot; Importancia Relativa de las Variables Input varImpPlot(rf2,sort = T,main=&quot;Variable Importance&quot;) Previsión en test rf2.prediction &lt;- as.data.frame(predict(rf2, newdata = dt_test)) dt_test$pred_rf2 &lt;- rf2.prediction[[1]] head(dt_test, 3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.2279703 ## 12 1 1 1 2 1 42 29.620 1 0.2159590 ## 18 1 1 1 2 1 58 0.758 0 0.2047155 ## pred_rf2 ## 6 7.914295 ## 12 8.539666 ## 18 9.864992 tail(dt_test, 3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.349066396 ## 1339 1 2 2 1 1 18 3.277 0 0.004032191 ## pred_rf2 ## 1336 NA ## 1337 36.877666 ## 1339 3.963606 summary(dt_test, 3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 2 :195 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 (Other):200 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 NA&#39;s : 7 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## Mean :31.31 ## 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 pred_rf2 ## Min. : 0.0050 Min. :0.0000 Min. :0.00005 Min. : 0.377 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00797 1st Qu.: 2.048 ## Median : 2.1645 Median :0.0000 Median :0.03794 Median : 3.293 ## Mean : 7.0917 Mean :0.1144 Mean :0.12531 Mean : 6.375 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.21666 3rd Qu.: 7.881 ## Max. :1067.6970 Max. :1.0000 Max. :0.75036 Max. :56.904 ## NA&#39;s :70 NA&#39;s :70 Graficamos la distribución de los valores estimados en el train plot(density(dt_test$pred_rf2[!is.na(dt_test$pred_rf2) &amp; dt_test$pred_rf2 &lt; 30]), ylim= c(0,.25) , col=&quot;red&quot; , main=&quot;&quot;) lines(density(dt_test$LOSS[dt_test$LOSS&lt;30]),col=&quot;blue&quot;,lty=1) modelchecktest1 &lt;- as.data.frame( cbind(real=dt_test$LOSS , predicted=dt_test$pred_rf2) ) modelchecktest1[is.na(modelchecktest1)] &lt;- 0 summary(modelchecktest1) ## real predicted ## Min. : 0.0050 Min. : 0.000 ## 1st Qu.: 0.5175 1st Qu.: 1.310 ## Median : 2.1645 Median : 2.422 ## Mean : 7.0917 Mean : 5.265 ## 3rd Qu.: 3.7782 3rd Qu.: 7.469 ## Max. :1067.6970 Max. :56.904 Error de ajuste del modelo plot(modelchecktest1, xlim=c(0,100) , ylim=c(0,100) , pch=&quot;.&quot; , cex=1.5) segments( 0, 0 , 100, 100 , col=&quot;red&quot;) Resumiendo Una función útil para medir el error: modelMetrics(real=modelchecktest1$real, pred=modelchecktest1$predicted ) ## Accuracy metrics (global): ## MAE(ref) = 8.9208 ## MAE = 7.765 ## RMSE = 54.5686 ## MAPE = 127.01 ## MAPE(sim) = 68.65 ## WMAPE = 109.49 Commentario: El error de ajuste del modelo de regresión es demasiado alto: \\(RMSE= 54.57\\) y el \\(MAPE=127.19%\\) Con estos errores de predicción, es preferible utilizar a un modelo de clasificación en lugar de un modelo de regresión. Ejercicio sugerido Ajustar un Modelo de Regresión Logística para \\(Y\\) y comparar los resultados con los proporcionados por el Random Forest Ajustar un Modelo de Regresión Lineal para \\(LOSS\\) y comparar los resultados con los proporcionados por el Random Forest Si queremos cambiar la ruta, podemos hacer ‘myWd &lt;- setwd(“Ruta y Nombre de la carpeta”)’.↩ https://CRAN.R-project.org/package=insuranceData↩ https://www.rdocumentation.org/packages/insuranceData/versions/1.0/topics/AutoBi↩ A loss is the injury or damage sustained by the insured in consequence of the happening of one or more of the accidents or misfortunes against which the insurer, in consideration of the premium, has undertaken to indemnify the insured.↩ The interquartile range of an observation variable is the difference of its upper and lower quartiles. It is a measure of how far apart the middle portion of data spreads in value↩ https://www.rdocumentation.org/packages/randomForest/versions/4.6-12/topics/randomForest↩ https://www.r-bloggers.com/a-small-introduction-to-the-rocr-package/↩ "],
["regresion-lineal.html", "Capítulo 5 Regresión Lineal", " Capítulo 5 Regresión Lineal Nota sobre Modelo Estadístico Los datos varian según las condiciones de su contexto experimental. La variabilidad en los datos, puede ser expresada de manera simplificada a través de un modelo, conformado por una ecuación y una serie de hipótesis sobre las componentes de azar que subyacen el estudio. La ecuación del modelo incluye siempre dos partes, una determinísta asociada con variaciones sistemáticas y que se reconoce que van a existir incluso antes de realizar el experimento y otra que depende de componentes aleatorias que son imposible de controlar y usualmente inherentes a la variabilidad propia del fenómeno aleatorio en estudio. \\[ \\text{Y} = \\text{Funcion Deterministica} + \\text{Perturbacion Aleatoria} \\] También se puede decir que en un modelo estadístico hay siempre dos estructuras íntimamente relacionadas: La estructura de media (que provee el valor esperado para la respuesta bajo las condiciones experimentales) La estructura de varianzas y covarianzas (asociada a la o las componentes aleatorias del modelo). "],
["que-es-un-modelo-de-regresion.html", "5.1 ¿Qué es un Modelo de Regresión?", " 5.1 ¿Qué es un Modelo de Regresión? El modelo de regresión se utiliza para representar la relación entre \\(Y\\) y \\(X\\): \\[Y = f(x)\\] \\(Y\\) es una variable respuesta, explicada o dependiente: que depende de otras y que tratamos de explicar/predecir. \\(X\\), o mas bien \\(X_1, X_2, \\ldots, X_K\\) son variables explicativas o independientes que permiten explicar/predecir \\(Y\\). Una regresión es lineal, cuando la función \\(f(x)\\) que relaciona \\(X\\) e \\(Y\\) es una función lineal. Teniendo \\(K\\) variables explicativas, la regresión lineal es: \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_K X_K + \\epsilon; \\epsilon \\sim N(0,\\sigma^2) \\] De manera que el valor de la predicción de la variable \\(Y\\) será: \\[ \\hat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta X_2 + ... + \\beta X_K \\] O lo que es lo mismo: \\[ \\epsilon = Y - \\hat{Y} \\] Así, \\(\\epsilon\\) será el error cometido en la previsión de \\(Y\\) usando el mode. En función del número \\(K\\) de variables explicativas que tengamos, la regresión lineal puede ser Simple o Múltiple. Simple si hay una única variable independiente (\\(K = 1\\)). Múltiple si hay varias variables independendientes (\\(K &gt; 1\\)). Para obtener la \\(\\hat{Y}\\) es necesario conocer \\(\\beta_0, \\ldots, \\beta_K\\), es decir, falta el proceso de inferencia estadística. La Inferencia Estadística es el procedimiento que permiten elaborar conclusiones sobre parámetros poblacionales desconocidos. \\[ \\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_1 + \\hat{\\beta} X_2 + ... + \\hat{\\beta} X_K \\] Conocer o estimar a un parámetro de la distribución de una variable es posible a través de un estadístico (estadístico muestral). Dado que el estadístico es obtenido a partir de una muestra y hay más de una muestra posible de ser elegida, el valor del estadístico dependerá de la muestra seleccionada. Como los valores de los estadísticos cambian de una muestra a otra. Interesa contar con una medida de estos cambios para cuantificar la medida del error en el que podría incurrirse al hacer una inferencia. Los parámetros de un modelo de regresión se pueden estimar con: Mínimos Cuadrados Ordinarios (OLS) Máxima Verosimilitud (ML) Inferencia Bayesiana 5.1.1 Ver también: Simple Linear Regression Analysis ¿Cómo Validar Tu Modelo De Regresión? ¿Qué modelo de regresión debería elegir? ¿Cómo seleccionar las variables adecuadas para tu modelo? -Multiple Linear Regression Analysis "],
["practica-en-r-1.html", "5.2 Práctica en R", " 5.2 Práctica en R 5.2.1 Regresión lineal simple Para realizarla usaremos la base de datos Boston de la librería MASS. library(MASS) Veamos la descripción de Boston en la ayuda de R: ?Boston ## starting httpd help server ... done Observamos que es un data.frame con 506 observaciones y 14 variables. Podemos explorar un poco más los datos usando las funciones head, tail y summary. head(Boston,5) ## crim zn indus chas nox rm age dis rad tax ptratio black ## 1 0.00632 18 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 ## 2 0.02731 0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 ## 3 0.02729 0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 ## 4 0.03237 0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 ## 5 0.06905 0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 ## lstat medv ## 1 4.98 24.0 ## 2 9.14 21.6 ## 3 4.03 34.7 ## 4 2.94 33.4 ## 5 5.33 36.2 tail(Boston,5) ## crim zn indus chas nox rm age dis rad tax ptratio black ## 502 0.06263 0 11.93 0 0.573 6.593 69.1 2.4786 1 273 21 391.99 ## 503 0.04527 0 11.93 0 0.573 6.120 76.7 2.2875 1 273 21 396.90 ## 504 0.06076 0 11.93 0 0.573 6.976 91.0 2.1675 1 273 21 396.90 ## 505 0.10959 0 11.93 0 0.573 6.794 89.3 2.3889 1 273 21 393.45 ## 506 0.04741 0 11.93 0 0.573 6.030 80.8 2.5050 1 273 21 396.90 ## lstat medv ## 502 9.67 22.4 ## 503 9.08 20.6 ## 504 5.64 23.9 ## 505 6.48 22.0 ## 506 7.88 11.9 summary(Boston) ## crim zn indus chas ## Min. : 0.00632 Min. : 0.00 Min. : 0.46 Min. :0.00000 ## 1st Qu.: 0.08204 1st Qu.: 0.00 1st Qu.: 5.19 1st Qu.:0.00000 ## Median : 0.25651 Median : 0.00 Median : 9.69 Median :0.00000 ## Mean : 3.61352 Mean : 11.36 Mean :11.14 Mean :0.06917 ## 3rd Qu.: 3.67708 3rd Qu.: 12.50 3rd Qu.:18.10 3rd Qu.:0.00000 ## Max. :88.97620 Max. :100.00 Max. :27.74 Max. :1.00000 ## nox rm age dis ## Min. :0.3850 Min. :3.561 Min. : 2.90 Min. : 1.130 ## 1st Qu.:0.4490 1st Qu.:5.886 1st Qu.: 45.02 1st Qu.: 2.100 ## Median :0.5380 Median :6.208 Median : 77.50 Median : 3.207 ## Mean :0.5547 Mean :6.285 Mean : 68.57 Mean : 3.795 ## 3rd Qu.:0.6240 3rd Qu.:6.623 3rd Qu.: 94.08 3rd Qu.: 5.188 ## Max. :0.8710 Max. :8.780 Max. :100.00 Max. :12.127 ## rad tax ptratio black ## Min. : 1.000 Min. :187.0 Min. :12.60 Min. : 0.32 ## 1st Qu.: 4.000 1st Qu.:279.0 1st Qu.:17.40 1st Qu.:375.38 ## Median : 5.000 Median :330.0 Median :19.05 Median :391.44 ## Mean : 9.549 Mean :408.2 Mean :18.46 Mean :356.67 ## 3rd Qu.:24.000 3rd Qu.:666.0 3rd Qu.:20.20 3rd Qu.:396.23 ## Max. :24.000 Max. :711.0 Max. :22.00 Max. :396.90 ## lstat medv ## Min. : 1.73 Min. : 5.00 ## 1st Qu.: 6.95 1st Qu.:17.02 ## Median :11.36 Median :21.20 ## Mean :12.65 Mean :22.53 ## 3rd Qu.:16.95 3rd Qu.:25.00 ## Max. :37.97 Max. :50.00 Antes de continuar, hacemos la división de Boston en trainy test. id_train &lt;- sample(1:nrow(Boston), size = 0.8*nrow(Boston)) train &lt;- Boston[id_train, ] test &lt;- Boston[-id_train, ] Ajustamos el modelo de regresión lineal simple para predecir la variable medv utilizando la variable lstat de nuestro conjunto de datos Boston. Para ello usaremos la función lm. reg_ls &lt;- lm(medv~lstat, data = train) reg_ls ## ## Call: ## lm(formula = medv ~ lstat, data = train) ## ## Coefficients: ## (Intercept) lstat ## 34.4975 -0.9504 Veamos los coeficientes de la regresión reg_ls$coefficients ## (Intercept) lstat ## 34.4975175 -0.9504457 Donde el término independiente es: reg_ls$coefficients[1] ## (Intercept) ## 34.49752 y el coeficiente de la variable lstates: reg_ls$coefficients[2] ## lstat ## -0.9504457 De manera que la recta de regresión lineal, siendo \\(y\\) la variable medv y \\(x\\) la variable lstat, es: ## y = 34.49752 + -0.9504457 x Si queremos obtener los errores residuales de las observaciones correspondientes: residuales &lt;- reg_ls$residuals # Veamos los residuales de las 10 primeras observaciones residuales[1:10] ## 363 379 89 345 76 64 ## -4.0124757 1.1185414 -5.6700661 1.0840372 -4.6005328 -0.4682832 ## 51 501 316 437 ## -2.0140227 -4.0776304 -7.3673918 -7.7419724 Una vez obtenido el modelo de regresión lineal, para realizar la predicción sobre un nuevo conjunto de datos, utilizamos la función predict, de la siguiente manera: predic &lt;- predict(reg_ls, newdata = test) #Veamos la predicción de las 10 primeras observaciones predic[1:10] ## 2 6 8 11 14 25 34 ## 25.810444 29.545695 16.296482 15.060903 26.646836 19.005252 17.056839 ## 49 54 66 ## 5.214285 26.485260 30.058936 Algunas representaciones gráficas de un modelo de regresión son: Dispersión de los puntos y la recta de regresión lineal simple obtenida: regresion &lt;- lm(medv~lstat, data = Boston) plot(Boston$lstat, Boston$medv, xlab = &quot;lstat&quot;, ylab = &quot;medv&quot;) abline(regresion, col=&#39;red&#39;, lwd=2) a &lt;- regresion$coefficients[[1]] b &lt;- regresion$coefficients[[2]] text(30,40,labels = paste(&#39;Y = &#39;, round(b,2),&#39;x +&#39;, round(a,2)), col=&#39;red&#39;) Análisis de residuos: par(mfrow=c(2,2)) plot(regresion) 5.2.2 Regresión lineal múltiple Utilizamos lo mismo que hemos hecho para la regresión lineal simple, con la diferencia de que ahora hay más de una variable independiente. Usamos la misma función, lm, y la sucesión de variables independientes estarán separadas con un +, es decir: reg_lm &lt;- lm(medv~lstat + age, data = train) reg_lm ## ## Call: ## lm(formula = medv ~ lstat + age, data = train) ## ## Coefficients: ## (Intercept) lstat age ## 33.63205 -1.00541 0.02289 Veamos los coeficientes de la regresión reg_lm$coefficients ## (Intercept) lstat age ## 33.6320457 -1.0054079 0.0228852 Donde el término independiente es: reg_lm$coefficients[1] ## (Intercept) ## 33.63205 el coeficiente de la variable lstat es: reg_lm$coefficients[2] ## lstat ## -1.005408 y el coeficiente de la variable age es: reg_lm$coefficients[3] ## age ## 0.0228852 De manera que la recta de regresión lineal, siendo \\(y\\) la variable medv, \\(x1\\) la variable lstat y \\(x2\\) la variable age, será: ## y = 33.63205 + -1.005408 x1 + 0.0228852 x2 Veamos los gráficos de dispersión 2 a 2: pairs(Boston[,c(&#39;medv&#39;,&#39;lstat&#39;, &#39;age&#39;)],panel = panel.smooth) Análogamente a como hemos hecho con la regresión lineal, podemos obtener los residuos y utilizar la función predict en un nuevo conjunto de datos. Hay otras opciones de poner la variables independientes. Por ejemplo, si quisieramos usar todas las variables, como conjunto de variables independientes, bastaría con escribir: reg_lm2 &lt;- lm(medv~., data = train) reg_lm2 ## ## Call: ## lm(formula = medv ~ ., data = train) ## ## Coefficients: ## (Intercept) crim zn indus chas ## 34.493133 -0.102681 0.051960 0.011247 3.618118 ## nox rm age dis rad ## -19.229433 4.029826 -0.005499 -1.530193 0.308246 ## tax ptratio black lstat ## -0.012192 -0.910011 0.010621 -0.475281 Por otro lado, si quisieramos usarlas todas excepto alguna, podemos escribir: reg_lm3 &lt;- lm(medv~.-age, data = train) reg_lm3 ## ## Call: ## lm(formula = medv ~ . - age, data = train) ## ## Coefficients: ## (Intercept) crim zn indus chas ## 34.75321 -0.10258 0.05256 0.01144 3.59839 ## nox rm dis rad tax ## -19.70045 3.99336 -1.50772 0.31033 -0.01225 ## ptratio black lstat ## -0.91672 0.01056 -0.48229 "],
["regresion-logistica.html", "Capítulo 6 Regresión Logística", " Capítulo 6 Regresión Logística Una aplicación muy conocida son los modelos de churn. Un modelo de churn es una herramienta que permite evaluar la probabilidad de baja o fuga de un cliente en función de sus características propias y del tipo de relación que tiene con la empresa. La variable que se analiza toma valor 1 ó 0. Para representar la relación entre esa variable binaria (output) y las variables explicativas (inputs), se utilizan modelos de tipo &lt;font logit o probit. "],
["modelos-lineales-generalizados.html", "6.1 Modelos Lineales Generalizados", " 6.1 Modelos Lineales Generalizados Los Modelos Lineales Generalizados son una extensión de los modelos lineales clásicos. Un modelo lineal se basa en un vector de observaciones \\(\\mathbf{Y}\\) con \\(n\\) componentes, que son una realización de una variable aleatoria \\(\\mathbf{Y}\\) cuyas componentes están independientemente distribuidas con media \\(\\mu\\). Un modelo lineal puede ser descrito como: \\[\\mathbf{Y} = \\mathbf{\\mu} + \\mathbf{\\epsilon}\\] La parte sistemática de un modelo es una especificación para \\(\\mu\\) en función de un número pequeño de parámetros, \\(\\beta_1, \\ldots, \\beta_p.\\) Esa especificación se hace de la siguiente manera: \\[ \\mu_i = \\sum_{j=1}^p X_{ij}\\beta_j; i=1,\\ldots,n. \\] O en forma matricial, \\[ E(\\mathbf{Y}) = \\mathbf{\\mu} = \\mathbf{x} \\mathbf{\\beta} \\] donde \\(\\mathbf{X}\\) es una matriz \\(n \\times p\\), con las covariables o regresoras del modelo. Para la parte aleatoria se supone independencia y varianza constante de los errores. En un modelo lineal clásico, se tiene que: \\[ \\mathbf{\\epsilon} \\sim N(0, \\sigma^2 \\mathbf{I}) \\] Por tanto un modelo lineal clásico puede ser resumido de la forma: \\[ \\begin{align} \\mathbf{Y} &amp; \\sim N(\\mathbf{\\mu}, \\sigma^2 \\mathbf{I}) \\\\ E(\\mathbf{Y}) &amp; = \\mathbf{X}\\mathbf{\\beta} \\\\ Var(\\mathbf{Y}) &amp; = \\sigma^2\\mathbf{I} \\end{align} \\] La generalización de los modelos lineales incluye una especificación de tres aspectos principales: Las componentes de \\(\\mathbf{Y}\\) tienen distribución normal con varianza constante y son independientes. En la parte sistemática, las covariables, \\(x_1, x_2, ..., x_p\\), producen un predictor lineal \\(\\eta\\), dado por: \\[ \\eta= \\sum_{j=1}^p X_{ij}\\beta_j \\] La relación entre los componentes sistemáticos y aleatorios se hace a través de una función de manera que: \\[\\mathbf{\\mu}=\\mathbf{\\eta}\\] Los Modelos Lineales Generalizados o MLGs permiten dos extensiones. La primera extensión está en la función de enlace, que es la parte del modelo que determina la relación entre la media de la variable respuesta y las covariables. Esta función de enlace, ahora, podrá ser cualquier función monótona diferenciable y generalmente denotada por \\(g(\\mu)\\). La segunda extensión reside en la distribución especificada para la componente aleatoria. En los MLGs esta puede ser de la familia exponencial, de la cual la distribución normal forma parte. Se supone que si \\(\\mathbf{Y}\\) tiene una distribución de la familia exponencial para unos específicos \\(a(\\cdot), b(\\cdot)\\) y \\(c(\\cdot)\\) se asume la siguiente forma: \\[ f_Y ( \\mathbf{Y} | \\eta,\\phi) = \\exp \\left\\{ \\dfrac{\\mathbf{\\eta} - b(\\eta)}{a(\\phi)} + c(\\mathbf{Y},\\phi) \\right\\} \\] El parámetro \\(\\phi\\) es llamado parámetro de dispersión y, si es conocido, llamamos a su familia ``de familia exponencial lineal de parámetro canónico \\(\\theta\\)’’. Utilizando la ecuación anterior y algunas relaciones, se puede obtener expresiones para la media y la varianza de \\(\\mathbf{Y}\\) de la siguiente manera: \\[ \\begin{align} E(\\mathbf{Y}) &amp; = b&#39;(\\eta) \\\\ Var(\\mathbf{Y}) &amp; = a(\\phi)b&#39;&#39;(\\eta) \\end{align} \\] "],
["modelo-logit.html", "6.2 Modelo Logit", " 6.2 Modelo Logit Cuando la variable respuesta es continua, se utilizan métodos de regresión lineal o de otro tipo; en cambio, cuando la variable respuesta es cualitativa se utilizan los llamados Modelos de Regresión Logística. El objetivo de los modelos de regresión logística es encontrar el mejor ajuste para describir las relaciones entre las variables respuesta (dicotómica o cualitativa) y un grupo de variables explicativas. Esta diferencia (respecto a los modelos con variable respuesta cuantitativa) da lugar a distintos modelos paramétricos y a distintas hipótesis para estos modelos, pero, una vez salvada esta diferencia, los métodos empleados en Regresión Logística siguen los principios generales de los métodos de Regresión Lineal. La primera razón por la cual un Modelo de Regresión Lineal no es adecuado para este tipo de datos es que la variable respuesta sólo puede tomar 2 valores (0 y 1), de modo que si pretendiésemos elaborar una relación entre una variable explicativa y esta, tendríamos que condicionar la probabilidad de alguno de los valores de la variable respuesta a cada valor de la variable explicativa, es decir \\(E(Y= 1 | X = x_1)\\) y obtendríamos la curva logística: La relación existente no es lineal, sino que puede asociarse con la función de distribución de cierta variable aleatoria. Al utilizar la distribución Logística, representaremos la media de \\(Y\\), dado un valor \\(x\\) de la variable \\(X\\), por \\(\\pi(X)=E(Y/x)\\). El modelo de Regresión Logística es: \\[ \\pi(x) = \\frac{e^{\\beta_0+\\beta_1x}}{1+e^{\\beta_0+\\beta_1x}} \\] o de forma equivalente: \\[ \\pi(x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}} \\] Aplicando la transformación Logit: \\[ g(x)=\\ln\\Big[\\frac{\\pi(x)}{1-\\pi(x)}\\Big]= \\beta_0+\\beta_1x \\] Hemos llegado a \\(g(x)\\), que tiene las propiedades que se desea que tenga un Modelo de Regresión Lineal; es lineal en sus parámetros; puede ser continua y su rango está entre \\(-\\infty\\) y \\(\\infty\\) dependiendo del rango de X. Como hemos dicho antes, también tenemos que tener clara la distribución de la parte aleatoria de nuestro modelo. En el Modelo Lineal Generalizado suponemos que un valor de la variable dependiente puede expresarse como \\(y=E(Y/x)+\\epsilon.\\) Donde \\(\\epsilon\\sim N(0,\\sigma^2)\\), con varianza constante para los distintos niveles de la variable independiente. Pero esto no ocurre así en el caso de una variable dicotómica. Si expresamos nuestro modelo como \\(Y = \\pi(x) + \\epsilon,\\) \\(\\epsilon\\) toma dos posibles valores: Si \\(Y=1,\\) con probabilidad \\(\\pi(x)\\), \\(\\epsilon= 1-\\pi(x)\\), con probabilidad \\(\\pi(x)\\). Si \\(Y=0, \\epsilon = -\\pi(x)\\), con probabilidad \\(1-\\pi(x)\\). Por tanto: \\[ E(\\epsilon)= (1-\\pi(x))\\pi(x)-\\pi(x)(1-\\pi(x))=0 \\] \\[ V(\\epsilon) = (1-\\pi(x))^2\\pi(x)-\\pi(x))^2(1-\\pi(x))=\\pi(x)(1-\\pi(x)) \\] La distribución de la variable dependiente \\(Y\\), dado un valor de \\(x\\) de la variable \\(X\\), sigue una distribución Binomial con probabilidad \\(\\pi(x)\\). Al no ser una relación lineal, no es posible interpretar directamente el valor de los parámetros estimados. Para ello se utilizan los ‘ODDS Ratios’. A través de un ratio de ODDS se puede calcular qué influencia genera en el target el incremento de una unidad en el valor de la variable explicativa. Si \\(\\beta_i &gt; 0\\) el efecto de la variable explicativa \\(X_i\\) sobre la respuesta \\(Y\\) es de incremento: aumenta la probabilidad del target. Si \\(\\beta_i &lt; 0\\) el efecto que produce la variable explicativa \\(X_i\\) sobre la respuesta \\(Y\\) es decremento: disminuye la probabilidad del target. "],
["modelo-probit.html", "6.3 Modelo Probit", " 6.3 Modelo Probit La relación existente entre \\(E(Y= 1/X=x_1)\\) y \\(X\\), que como dicho anteriormente no es linea, se asocia también con la curva de distribución normal.Este enfoque utiliza la inversa de la función de distribución normal para obtener una relación lineal entre \\(E(Y= 1/X=x_1)\\) y \\(X\\). Y una vez hayamos tenido los valores en forma de relación lineal del tipo \\(g(x) = B_0+B_1x_1\\) volveremos a transformarlo en una curva que se asemeje a una distribución aleatoria de la siguiente manera: \\[ E(Y=1/X) = \\int_{-\\infty}^{B_0+B_1 x_1}\\frac{1}{\\sqrt{2\\pi}}e^{\\frac{-z^2}{2}} \\] Así estimando los valores de \\(B_0\\) y \\(B_1\\), siguiendo el proceso anteriormente mencionado, obtendremos estimaciones de las probabilidades de un determinado valor de la variable respuesta \\((Y)\\) condicionada a unos determinados valores de las variables explicativas \\((X_1,X_2,...X_n)\\). "],
["practica-en-r-2.html", "6.4 Práctica en R", " 6.4 Práctica en R Para este ejemplo cargamos la librería ISLR y utilizamos el conjunto de datos de Smarket. Veamos información sobre los datos Smarket ?Smarket ## starting httpd help server ... done head(Smarket) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down ## 4 2001 -0.623 1.032 0.959 0.381 -0.192 1.2760 0.614 Up ## 5 2001 0.614 -0.623 1.032 0.959 0.381 1.2057 0.213 Up ## 6 2001 0.213 0.614 -0.623 1.032 0.959 1.3491 1.392 Up summary(Smarket) ## Year Lag1 Lag2 ## Min. :2001 Min. :-4.922000 Min. :-4.922000 ## 1st Qu.:2002 1st Qu.:-0.639500 1st Qu.:-0.639500 ## Median :2003 Median : 0.039000 Median : 0.039000 ## Mean :2003 Mean : 0.003834 Mean : 0.003919 ## 3rd Qu.:2004 3rd Qu.: 0.596750 3rd Qu.: 0.596750 ## Max. :2005 Max. : 5.733000 Max. : 5.733000 ## Lag3 Lag4 Lag5 ## Min. :-4.922000 Min. :-4.922000 Min. :-4.92200 ## 1st Qu.:-0.640000 1st Qu.:-0.640000 1st Qu.:-0.64000 ## Median : 0.038500 Median : 0.038500 Median : 0.03850 ## Mean : 0.001716 Mean : 0.001636 Mean : 0.00561 ## 3rd Qu.: 0.596750 3rd Qu.: 0.596750 3rd Qu.: 0.59700 ## Max. : 5.733000 Max. : 5.733000 Max. : 5.73300 ## Volume Today Direction ## Min. :0.3561 Min. :-4.922000 Down:602 ## 1st Qu.:1.2574 1st Qu.:-0.639500 Up :648 ## Median :1.4229 Median : 0.038500 ## Mean :1.4783 Mean : 0.003138 ## 3rd Qu.:1.6417 3rd Qu.: 0.596750 ## Max. :3.1525 Max. : 5.733000 En este caso la variable Y que queremos predecir/explicar es la variable Direction, y las variables independientes son Lag1, Lag2, Lag3, Lag4, Lag5 y Volume. Veamos que valores toma la variable Direction levels(Smarket$Direction) ## [1] &quot;Down&quot; &quot;Up&quot; Vemos que es una variable binaria que toma valores Downo Up. Antes de continuar pasamos esos valores a 0 o 1, respectivamente. Smarket$Direction &lt;- ifelse(Smarket$Direction == &#39;Up&#39;, 1, 0) Para realizar la regresión logística en R utilizaremos la función glm. Se puede observar en el código siguiente, que como nuestro Target es binario, el parámetro family lo debemos fijar a binomial. reg_logis &lt;- glm(Direction~Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial) Veamos que hemos obtenido summary(reg_logis) ## ## Call: ## glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + ## Volume, family = binomial, data = Smarket) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.446 -1.203 1.065 1.145 1.326 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.126000 0.240736 -0.523 0.601 ## Lag1 -0.073074 0.050167 -1.457 0.145 ## Lag2 -0.042301 0.050086 -0.845 0.398 ## Lag3 0.011085 0.049939 0.222 0.824 ## Lag4 0.009359 0.049974 0.187 0.851 ## Lag5 0.010313 0.049511 0.208 0.835 ## Volume 0.135441 0.158360 0.855 0.392 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1731.2 on 1249 degrees of freedom ## Residual deviance: 1727.6 on 1243 degrees of freedom ## AIC: 1741.6 ## ## Number of Fisher Scoring iterations: 3 Los coeficientes de la regresión logística obtenida serán: coef(reg_logis) ## (Intercept) Lag1 Lag2 Lag3 Lag4 ## -0.126000257 -0.073073746 -0.042301344 0.011085108 0.009358938 ## Lag5 Volume ## 0.010313068 0.135440659 Como se hace en los otros modelos, la función predict la utilizaremos para predecir un nuevo conjunto de datos a partir de nuestro modelo de regresión logística ajustado. Para un modelo binomial predeterminado, las predicciones serán de log-odds (probabilidades en la escala logit). Como vemos en el código a continuación, utilizamos el argumento type = response para guardar la predicción de las probabilidades. glm.probs &lt;- predict(reg_logis, type = &quot;response&quot;) Lo que hacemos a continuación es dar a una observación el valor del target \\(1\\) o \\(0\\) en función a la probabilidad obtenida. El corte en la probabilidad en este caso lo ponemos en \\(0.5\\), es decir, si la predicción que se ha obtenido de la probabilidad es menor que 0.5, le damos el valor \\(0\\), y sino el valor \\(1\\). El código que hace esto es de la siguiente manera: glm.pred &lt;- rep(1, nrow(Smarket)) glm.pred[glm.probs &lt; .5] &lt;- 0 Ahora, obtenemos la matriz de confusión, en el que podemos comparar el valor de la predicción obtenida (filas) con el verdadero valor (columnas). De esta manera, lo que está en la diagonal principal será lo que se ha predecido correctamente. table(glm.pred, Smarket$Direction) ## ## glm.pred 0 1 ## 0 145 141 ## 1 457 507 observamos la media de los valores que se ha predecido bien: mean(glm.pred == Smarket$Direction) ## [1] 0.5216 y la media de los que se han predecido mal: mean(glm.pred != Smarket$Direction) ## [1] 0.4784 Podemos ver de manera gráfica como han sido clasificados por nuestro modelo (en función de la probabilidad obtenida) frente a su valor real. nuevo &lt;- data.frame(glm.probs, glm.pred, Smarket$Direction) names(nuevo)[1] &lt;- &quot;probs&quot; names(nuevo)[2] &lt;- &quot;pred&quot; names(nuevo)[3] &lt;- &quot;direction&quot; nuevo$direction &lt;- ifelse(nuevo$direction == 1, &#39;Up&#39;, &#39;Down&#39;) nuevo$pred &lt;- ifelse(nuevo$pred == 1, &#39;Up&#39;, &#39;Down&#39;) library(ggplot2) ggplot(data = nuevo, aes(x = pred, y = probs, col = direction)) + geom_point() + labs(x = &#39;Prediccion&#39;, y = &#39;Probabilidades&#39;) + ggtitle(&#39;Prediccion vs Valor Real&#39;) + theme(legend.title=element_blank()) + scale_colour_manual(values=c(&quot;blue&quot;, &quot;red&quot;)) 6.4.1 Otros ejemplos How to perform a Logistic Regression in R Logit Regression | R Data Analysis Examples Practical Guide to Logistic Regression Analysis in R Customer Churn – Logistic Regression with R "],
["series-temporales.html", "Capítulo 7 Series Temporales", " Capítulo 7 Series Temporales Ejemplo A: Ejemplo B: Una serie temporal es una secuencia de datos, medidos a intervalos de tiempo sucesivos regularmente espaciados. Ejemplos de series temporales son: tasa de cambio diario, tasa de desempleo mensual, PIB trimestral, volumen de lluvia diario, etc. Una de las características más importantes de una serie temporal es que las observaciones vecinas son generalmente dependientes. Así, mientras que en los modelos de regresión, por ejemplo, el orden de las observaciones es irrelevante para el análisis, en las series temporales el orden de los datos es crucial. "],
["que-es-una-serie-temporal.html", "7.1 ¿Qué es una Serie Temporal?", " 7.1 ¿Qué es una Serie Temporal? Una serie temporal (o simplemente una serie) es una secuencia de \\(N\\) observaciones ordenadas y equidistantes cronológicamente sobre una característica o varias características de una unidad observable en diferentes momentos. Si la serie es sobre una característica se dice que es univariante o escalar. Si la serie es sobre dos o más características se dice que es multivariante o vectorial. El estudio de las series temporales permite: entender mejor el mecanismo de generación de los datos, que puede no ser claro inicialmente en una investigación y/o hacer pronósticos sobre el futuro, es decir: previsiones. Las previsiones se utilizan en forma constante en diversos campos: economía, finanzas, marketing, medio ambiente, ingeniería, etc. En general, las previsiones proporcionan una guía para las decisiones que deben tomarse. Algunos ejemplos de uso de las previsiones son: En Planeamiento y Control de Operaciones. Las decisiones de producción de un artículo con base en los pronósticos de ventas. Es posible por ejemplo, detectar una disminución en la tendencia de ventas que conlleve a reducir la producción, o al contrario. En Marketing. La decisión de invertir en publicidad puede depender de prever las ventas. En Economía. Las decisiones del Banco de España, por ejemplo para el control de la inflación, requieren la previsión y el examen del comportamiento de ciertas variables macroeconómicas, como el PIB, la tasa de desempleo, el IPC, las tasas de inter?s a distintos plazos, activas y pasivas. En Turismo. La previsión del de número de turistas mensuales para determinar la demanda hotelera. En Epidemiología y Medio Ambiente. La vigilancia de los niveles de contaminantes en el aire tiene como herramienta fundamental las series de tiempo. Pero adicionalmente el efecto de estos niveles sobre la salud. Todas las series temporales tienen características particulares. Asi por ejemplo, las series pueden: evolucionar alrededor de un nivel constante o tienen tendencias crecientes o decrecientes, evolucionar alrededor de un nivel que cambia sin seguir aparentemente un patrón concreto - tienen tendencia estocástica - presentar reducciones (en invierno) y aumentos (en verano) sistemáticos en su nivel cada 12 meses - son estacionales - presentar variabilidad constante alrededor de su nivel presentar variabilidad condicional o alta volatilidad, moverse conjuntamente con otras series - tendencia común - etc. Ejemplo: Caudal Anual del Río Nilo. 1871–1970. Anual. Ejemplo: España: Viviendas Iniciadas. Ene-1989/Jun-2012. Mensual. Miles de Viviendas Ejemplo: Madrid: Temperatura Media en el Parque del Retiro. Ene-1989/Dic-2011. Mensual. En las secciones siguiente se describen brevemente algunos conceptos necesarios para la modelación básica de series temporales. "],
["herramientas-de-analisis.html", "7.2 Herramientas de Análisis", " 7.2 Herramientas de Análisis 7.2.1 Autocorrelación (acf y pacf) Los correlogramas permiten representar las funciones de autocorrelación simple (fas) y parcial (fap). El coeficiente de correlación simple (y así la fas) refleja la correlación entre la variable \\(Y\\) y el valor retardado de la misma en \\(k\\) instantes anteriores (lags). El **coeficiente de correlación parcial (y así la fap) calcula la correlación directa eliminando posibles dependencias asociadas a retardos intermedios. Los correlogramas permiten representar las acf y pacf que solo tienen sentido dentro del ámbito de los procesos estacionarios porque asumen que la correlación entre dos valores de la serie sólo depende de su distancia, no del instante del tiempo al que van referidos. 7.2.2 Operadores (del Tiempo) Operador de Retardo Simple El operador de retardo simple se define como \\[Bz_t=z_{t-1}\\] Si aplicamos el operador de retardo dos veces: \\[BBz_t=Bz_{t-1}=z_{t-2}\\] Del mismo modo, si aplicamos \\(n\\) veces el operador de retardo, obtenemos: \\[ BB \\ldots Bz_t=z_{t-n} \\] Definimos, por tanto \\[ B^n z_t=z_{t-n} \\] Operador de Adelanto simple De modo análogo, definimos el operador de adelanto simple \\[ \\begin{align} Fz_t&amp;=z_{t+1}\\\\ F^n z_t&amp;=z_{t+n} \\end{align} \\] El operador \\(F\\) es el inverso del operador \\(B\\) ya que: \\[ FBz_t=BFz_t=z_t \\] Por tanto, \\(BF=FB=1,\\) lo que implica que \\(F=B^{-1}\\). Polinomios en \\(B\\) Sea el polinomio en el operador de retardo \\(B\\): \\[ \\phi_0 - \\phi_1 B - \\ldots - \\phi_pB^p \\] La operación de este polinomio se define como: \\[ (\\phi_0 - \\phi_1 B - \\ldots - \\phi_pB^p)z_t=\\phi_0z_t+\\phi_1z_{t-1}+\\ldots+\\phi_pz_{t-p} \\] Llamamos polinomio autorregresivo de orden \\(p\\) al polinomio de grado \\(p\\) \\[ 1-\\phi_1B-\\dots-\\phi_pB^p \\] La razón de esta nomenclatura es que si tenemos una serie cuyo comportamiento puede expresarse como \\[ (1-\\phi_1B-\\dots-\\phi_pB^p)z_t=e_t \\] donde \\(e_t\\) es un término de error, la anterior expresión puede escribirse como: \\[ z_t=\\phi_1 z_{t-1}+ \\ldots + \\phi_p z_{t-p} + e_t \\] Es decir, como una regresión donde la serie \\(z_t\\) es el output y los propios retardos \\(1,2,\\ldots,p\\) de la variable actúan como inputs o regresores construyendo una autorregresión. En muchas ocasiones emplearemos las formas \\(\\phi(B), \\psi(B), \\varphi(B)\\) u otras semejantes para denotar polinomios en \\(B\\). Notaremos más adelante que asociaremos ciertas formas de expresar polinomios en \\(B\\) como \\(\\phi(B)\\) a clases de polinomios en \\(B\\) que juegan cierto papel especial. Por ejemplo, reservaremos la expresi?n \\(\\phi(B)\\) a polinomios autorregresivos. Operador Diferencia El operador diferencia respecto al pasado, en lo sucesivo simplemente operador diferencia, se define como: \\[ \\bigtriangledown z_t = z_t - z_{t-1}, \\] que puede expresarse como: \\[ \\bigtriangledown z_t = z_t - z_{t-1}, \\] que puede expresarse como \\[ (1-B)z_t=\\bigtriangledown z_t. \\] Por lo tanto: \\(\\bigtriangledown =1-B\\). El operador de , usualmente diferencia estacional, se define como \\[ \\bigtriangledown_s z_t=z_t-z_{t-s}=(1-B^s)z_t. \\] Luego, \\(\\bigtriangledown_s=(1-B^s).\\) Debe observarse que cuando aplicamos el operador \\(B\\) a una serie \\(S\\) lo que hacemos en realidad es adelantar la serie un periodo. Análogamente, cuando aplicamos el operador \\(F\\) a una serie \\(S\\) retrasamos la serie un periodo. "],
["alisado-exponencial.html", "7.3 Alisado Exponencial", " 7.3 Alisado Exponencial El alisado exponencial es una técnica aplicada a series de tiempo, para suavizarlas u obtener previsiones. Mientras que, con la media móvil, las observaciones pasadas se ponderan por igual, en el alisado exponencial se asignan ponderaciones exponencialmente decrecientes en el tiempo. La fórmula utilizada es: \\[ y_1 = x_0 \\] \\[ y_t = (1-\\theta)x_{t-1}+\\theta y_{t-1}, t &gt; 1 \\] donde \\(\\{x_t\\}\\) son las observaciones reales, \\(\\{y_t\\}\\) son las estimaciones y \\(\\theta\\) es el factor de alisamiento, \\(0 &lt; \\theta &lt; 1\\). En otras palabras, con este método, la previsión para el periodo \\(t\\) (valor esperado) como la suma ponderada de todas la observaciones anteriores, dando mayor importancia a las observaciones más recientes que a las más antiguas. Como puede verse en: \\[ y_t = (1-\\theta) x_{t-1} +\\theta y_{t-1} \\] \\[ y_t = (1-\\theta)x_{t-1}+(1-\\theta)\\theta x_{t-2}+(1-\\theta) \\theta^2 y_{t-2} \\] \\[ y_t = (1-\\theta)[x_{t-1}+\\theta x_{t-2}+\\theta x_{t-3}+\\theta x_{t-4}+ ...] + \\theta^{t-1} x_0 \\] Así, los pesos asignados a las observaciones previas pertenecen a una proporción de la progresión geométrica: \\(\\{1, \\theta, \\theta^2, \\theta^3, ..\\}\\). Por otro lado, si la ecuación arriba se expresa como: \\[ y_t = x_{t-1} + \\theta(y_{t-1} - x_{t-1}) , \\] Se aprecia que \\(y_t\\) está formada por la suma de la observación en el periodo anterior (\\(x_{t-1}\\)) más una proporción (\\(\\theta\\)) del error cometido (\\(y_{t-1} - x_{t-1}\\)). Por lo tanto el valor de \\(\\theta\\) controla la rapidez con que la previsión se adapta a los cambios del nivel de la serie (estado). Si \\(\\theta\\) es grande (próximo a 1), la previsión se adapta rápidamente a los cambios, por lo tanto se debe utilizar en series poco estables. Si \\(\\theta\\) es pequeño (próximo a 0), se consigue eliminar el efecto de las fluctuaciones, por lo tanto se debe utilizar en series estables. El valor de \\(\\theta\\) se puede optimizar minimizando la suma de cuadrados del error de previsión, es decir, resolviendo: \\(min(x_{t-1} - y_{t-1})^2\\). El alisado exponencial, técnicamente, es equivalente a un modelo ARIMA (0,1,1) sin constante. En otras palabras, se puede representar por: \\[\\hat{y} = (1-\\theta)(1 + \\theta B + \\theta^2 B^2 + \\theta^3 B^3 + ...)x_{t-1}\\] donde \\(B\\) es el operador retardo y \\(\\theta\\) es el parámetro de amortiguamiento. Esta representación no implica recargar el último término con un peso mayor a los valores más recientes. Si existe un número finito de periodos observados, la ecuación anterior se reescribe como: \\[ \\hat{y} = \\alpha (1 + \\theta B + \\theta^2 B^2 + ... + \\theta^p B^p)x_{t-1}\\] donde \\(p\\) es el número de periodos disponibles y $&lt;1 $ es un término que asegura que los coeficientes de la ecuación sumen la unidad. Eso permite que el peso relativo de cada uno de los datos del pasado se mantenga constante y, al mismo tiempo, el resultado siga siendo una media. En la tabla abajo se muestran los pesos que toman los términos, en el caso de contar con 6. I II III IV V \\(\\theta\\) 0.70 0.65 0.60 0.55 0.50 \\((1- \\theta)\\) 0.30 0.35 0.40 0.45 0.50 \\((1- \\theta)\\theta\\) 0.21 0.23 0.24 0.25 0.25 \\((1- \\theta)\\theta^2\\) 0.15 0.15 0.14 0.14 0.13 \\((1- \\theta)\\theta^3\\) 0.10 0.10 0.09 0.07 0.06 \\((1- \\theta)\\theta^4\\) 0.07 0.06 0.05 0.04 0.03 \\((1- \\theta)\\theta^5\\) 0.05 0.04 0.03 0.02 0.02 "],
["arima.html", "7.4 ARIMA", " 7.4 ARIMA Un proceso estocástico es un mecanismo generador de un número aleatorio de series. Una serie temporal es una realización particular de un proceso estocástico. El objetivo que se plantea es inferir el proceso estocástico que ha generado el conjunto de observaciones que definen la serie temporal. Para caracterizar un proceso estocástico \\(F(y(t_1),\\ldots,y(t_N))\\), se requiere de la distribución conjunta de \\(F(y_t), \\forall t\\), las distribuciones marginales \\(F(y_t,y_{t+1}), \\forall t\\), etc. Problema. Como sólo se dispone de una observación por instante temporal, no es posible obtener dichas distribuciones. Solución. Asumir qe las distribuiones son estables (estacionarias) en el tiempo para que las distribuciones asociadas a diferentes instantes sean comparables. Un proceso es estacionario en sentido estricto si el comportamiento de una colección de variables aleatórias sólo depende de su posición relativa, no del instante \\(t\\). Dada una serie temporal, el objetivo es hacerla estacionaria para asumir esa estabilidad que permita hacer que todos los instantes sean comparables. Una vez que el proceso (serie) es estacionario, se busca algún tipo de modelo adecuado para su caracterización: los procesos ARMA son modelizables mediante modelos ARMA. \\[ARMA(p,q) = (1-\\phi_1 B - \\ldots - \\phi_p B^p)X_t = (1- \\theta_1 B - \\ldots - \\theta_q B^q)a_t\\] 7.4.1 Parte AR (Autorregresiva) La parte autogresica del modelos muestra la dependencia del dato real con su propio pasado. Se trata de una regresión de la variable en sí misma (autoregresión). \\[AR(p): X_t= \\mu_t + \\phi_1X_{t-1} + \\ldots + \\phi_1X_{t-p} + a_t\\] 7.4.2 Parte MA (Medias Móviles) La parte de medias moviles muestra la dependencia del dato real con el pasado del proceso de error (media móvil de la serie de los errores) Los procesos \\(MA\\) siempre son estacionarios. \\[MA(q): X_t= \\mu - \\theta_1 a_{t-1} - \\ldots - \\theta_q a_{t-q} + a_t\\] Se requiere identificar el proceso que buyace bajo los datos, lo cual consiste en identicar los órdenes \\(p\\) y \\(q\\) del modelo ARMA que generó la serie temporal. Las herramientas para identificar esos procesos son las funciones de autocorrelación simple y parcial. Ejemplo AR(2): \\(Y_t = 0.6Y_{t-1}+0.2Y_{t-2}+A_t\\) Ejemplo MA(2): \\(X_t=A_t-0.6A_{t-1}-0.2A_{t-2}\\) Ejemplo ARIMA(1,1):\\(Y_t = -0.8 Y_{t-1} + A_t -0.8A_{t-1}\\) "],
["funciones-de-transferencia.html", "7.5 Funciones de Transferencia", " 7.5 Funciones de Transferencia Algunos ejemplos14(https://www.xycoon.com/tf_identification.htm): Fuente de los gráficos↩ "],
["practica-en-r-3.html", "7.6 Práctica en R", " 7.6 Práctica en R Un ejemplo sencillo sobre el manejo de series temporales que puede realizarse con algunos paquetes de R. Datos Los datos utilizados corresponden a las ventas mensuales para una tienda de souvenirs en un balneario de Queensland, Australia, de enero de 1987 a diciembre de 1993 (Ver aquí. Datos originales de Wheelwright y Hyndman, 1998). Librerías A lo largo de esta práctica se utilizan las siguientes librerías: XTS: eXtensible Time Series y HIGHCHARTER: a R wrapper for Highcharts javascript libray and its modules. . Los manual de usuario de ambos paquetes esta disponibles en la siguientes enlaces: Manual de XTS y Manual de HIGHCHARTER Para instalar un paquete de R, se puede usar el comando: install.packages(\"nombre del paquete\"). Por ejemplo, install.packages(\"xts\"). De forma alternativa: # Get xts if (!require(&quot;xts&quot;)) {install.packages(&quot;xts&quot;); library(xts)} # Get highcharter if (!require(&quot;highcharter&quot;)) {install.packages(&quot;highcharter&quot;); library(highcharter)} # Get tseries if (!require(&quot;tseries&quot;)) {install.packages(&quot;tseries&quot;); library(tseries)} Lectura y Visualización Obtenemos los datos en el site de la Time Series Data Library (TSDL). (Los datos están aquí. datos = scan(&quot;http://robjhyndman.com/tsdldata/data/fancy.dat&quot;) datos = log(datos) #transformación opcional head(datos,5) #primeros 5 datos FALSE [1] 7.41747 7.78219 7.95181 8.17394 8.23030 tail(datos,5) #últimos 5 datos FALSE [1] 10.2607 10.3257 10.3360 10.7501 11.5585 Objeto XTS La forma más conocida para la creación de un objeto de la clase serie temporal, es el uso de la función ts. En este ejemplo, creamos la serie temporal sales.ts a partir de datos. Sin embargo, la manipulación de la serie es bastante más natural y amigable utilizando un objeto de la clase xts. En este ejemplo se crea el objeto sales a partir de datos y se hacen consultas básicas sobre su contenido (fechado, primer dato, últimas semanas, número de semanas en la muestra, etc.) sales = as.xts(sales.ts) #creación del objeto XTS is.xts(sales) #debe devolver TRUE FALSE [1] TRUE periodicity(sales) #fechado de los datos FALSE Monthly periodicity from ene. 1987 to dic. 1993 first(sales) #primer dato FALSE [,1] FALSE ene. 1987 7.41747 last(sales) #último dato FALSE [,1] FALSE dic. 1993 11.5585 first(sales, &#39;7 months&#39;) #primeros 7 dias FALSE [,1] FALSE ene. 1987 7.41747 FALSE feb. 1987 7.78219 FALSE mar. 1987 7.95181 FALSE abr. 1987 8.17394 FALSE may. 1987 8.23030 FALSE jun. 1987 8.22006 FALSE jul. 1987 8.37784 last(sales, &#39;2 quarters&#39;) #últimas dos semanas FALSE [,1] FALSE jul. 1993 10.1718 FALSE ago. 1993 10.2607 FALSE sep. 1993 10.3257 FALSE oct. 1993 10.3360 FALSE nov. 1993 10.7501 FALSE dic. 1993 11.5585 nmonths(sales) #número de meses en la muestra FALSE [1] 84 nquarters(sales) #número de trimestres en la muestra FALSE [1] 28 nyears(sales) #número de años en la muestra FALSE [1] 7 Selección de datos usando las fechas Una funcionalidad interesante es la obtención de sub-muestras, utilizando la(s) fecha(s) como criterio(s) de selección. sales[&#39;1990-01-01/1990-05-01&#39;] #todos los datos del 01 al 05 de Febrero de 1990 FALSE [,1] FALSE ene. 1990 8.68628 FALSE feb. 1990 8.66812 FALSE mar. 1990 9.42716 FALSE abr. 1990 8.75932 FALSE may. 1990 8.93710 first(sales[&#39;1991&#39;], &#39;5 month&#39;) #primeros 5 meses desde Febrero de 1989 FALSE [,1] FALSE ene. 1991 8.48191 FALSE feb. 1991 8.77497 FALSE mar. 1991 9.17355 FALSE abr. 1991 9.08491 FALSE may. 1991 9.07365 last(sales[&#39;1990&#39;], &#39;1 quarter&#39;) #datos último mes de 1990 FALSE [,1] FALSE oct. 1990 9.04508 FALSE nov. 1990 9.79337 FALSE dic. 1990 10.31276 rbind(sales[&#39;1987-10/1988-03&#39;],sales[&#39;1988-10/1989-03&#39;]) #todos los datos del 01 al 05 de Febrero de 2011 y 2012 FALSE [,1] FALSE oct. 1987 8.76772 FALSE nov. 1987 8.93598 FALSE dic. 1987 9.89122 FALSE ene. 1988 7.82397 FALSE feb. 1988 8.55608 FALSE mar. 1988 8.88532 FALSE oct. 1988 8.67165 FALSE nov. 1988 9.44146 FALSE dic. 1988 10.25912 FALSE ene. 1989 8.45893 FALSE feb. 1989 8.64868 FALSE mar. 1989 9.20609 Cambios de Fechado El cambio de fechado o periodicidad es una operación muy útil durante el trabajo con series temporales. En este ejemplo, como la variable analizada corresponde a las ventas mensuales, se utiliza la función sum para obtener las ventas trimestrales y anuales. sales.qua=apply.quarterly(sales, sum) # datos trimestrales first(sales.qua, &#39;3 quarters&#39;) FALSE [,1] FALSE mar. 1987 23.1515 FALSE jun. 1987 24.6243 FALSE sep. 1987 25.0787 sales.yea=apply.yearly(sales, sum) # datos anuales first(sales.yea, &#39;3 years&#39;) FALSE [,1] FALSE dic. 1987 100.449 FALSE dic. 1988 105.113 FALSE dic. 1989 108.676 Imputación de Datos Faltantes La falta de algunos datos y/o la presencia de datos errones suele tratarse con procedimientos de imputación - para no perder histórico de la muestra disponible. El paquete xts posee funciones que permiten extender hacia adelante o hacia atrás, valores observados en la misma serie temporal. aux=sales[&#39;1990-01-01/1990-03-01&#39;] sales[&#39;1990-01-01/1990-03-01&#39;]=NA sales[&#39;1990-01-01/1990-03-01&#39;] FALSE [,1] FALSE ene. 1990 NA FALSE feb. 1990 NA FALSE mar. 1990 NA (isna=which(is.na(sales))) #identifica las líneas con NA FALSE [1] 37 38 39 sales.na01=na.locf(sales) #repite el ultimo anterior a NA sales.na01[isna,] FALSE [,1] FALSE ene. 1990 10.4359 FALSE feb. 1990 10.4359 FALSE mar. 1990 10.4359 sales.na02=na.locf(sales, fromLast=TRUE) # repite el primero despues de NA sales.na02[isna,] FALSE [,1] FALSE ene. 1990 8.75932 FALSE feb. 1990 8.75932 FALSE mar. 1990 8.75932 sales.na03=na.locf(sales, na.rm=TRUE, fromLast=TRUE) sales.na03[isna,] FALSE [,1] FALSE ene. 1990 8.75932 FALSE feb. 1990 8.75932 FALSE mar. 1990 8.75932 sales[isna,]=aux Estadísticos en diferentes fechados El paquete xtspermite trabajar con series de estadísticos en fechado agregado. Por ejemplo, el máximo del mes, el mínimo del trimestre, etc. El ingrediente indispensable es el vector que indica los puntos de quiebre de la serie. Este vector se obtiene con la función endpoints. aux.qq=endpoints(sales,&quot;quarters&quot;) #indica los finales de trimestre par(mfrow=c(1,3), cex.lab=0.8,cex.axis=0.8,las=2) plot(period.sum(sales,aux.qq), main=&quot;Total&quot;) plot(period.min(sales,aux.qq), main=&quot;Mínimo&quot;) plot(period.max(sales,aux.qq), main=&quot;Máximo&quot;) aux.yy=endpoints(sales,&quot;years&quot;) #indica los finales de año par(mfrow=c(1,3),cex.lab=0.8,cex.axis=0.8,las=2) plot(period.sum(sales,aux.yy), main=&quot;Total&quot;) plot(period.min(sales,aux.yy), main=&quot;Mínimo&quot;) plot(period.max(sales,aux.yy), main=&quot;Máximo&quot;) División del conjunto de datos usando fechas Otra funcionalidad útil es split. Permite dividir el objeto original en sub-conjuntos, teniendo en cuenta un fechado y un horizonte. En este caso, se divide el objeto sales en sub-muestras de 4 meses cada una. sales.by.4months=split(sales, f=&quot;months&quot;,k=4) sales.by.4months ## [[1]] ## [,1] ## ene. 1987 7.41747 ## feb. 1987 7.78219 ## mar. 1987 7.95181 ## abr. 1987 8.17394 ## ## [[2]] ## [,1] ## may. 1987 8.23030 ## jun. 1987 8.22006 ## jul. 1987 8.37784 ## ago. 1987 8.17930 ## ## [[3]] ## [,1] ## sep. 1987 8.52155 ## oct. 1987 8.76772 ## nov. 1987 8.93598 ## dic. 1987 9.89122 ## ## [[4]] ## [,1] ## ene. 1988 7.82397 ## feb. 1988 8.55608 ## mar. 1988 8.88532 ## abr. 1988 8.47763 ## ## [[5]] ## [,1] ## may. 1988 8.68286 ## jun. 1988 8.50741 ## jul. 1988 8.72893 ## ago. 1988 8.46635 ## ## [[6]] ## [,1] ## sep. 1988 8.61185 ## oct. 1988 8.67165 ## nov. 1988 9.44146 ## dic. 1988 10.25912 ## ## [[7]] ## [,1] ## ene. 1989 8.45893 ## feb. 1989 8.64868 ## mar. 1989 9.20609 ## abr. 1989 8.57636 ## ## [[8]] ## [,1] ## may. 1989 8.77839 ## jun. 1989 8.79948 ## jul. 1989 8.90240 ## ago. 1989 9.00903 ## ## [[9]] ## [,1] ## sep. 1989 9.05639 ## oct. 1989 9.17890 ## nov. 1989 9.62588 ## dic. 1989 10.43591 ## ## [[10]] ## [,1] ## ene. 1990 8.68628 ## feb. 1990 8.66812 ## mar. 1990 9.42716 ## abr. 1990 8.75932 ## ## [[11]] ## [,1] ## may. 1990 8.93710 ## jun. 1990 8.88527 ## jul. 1990 9.00224 ## ago. 1990 8.98460 ## ## [[12]] ## [,1] ## sep. 1990 8.99876 ## oct. 1990 9.04508 ## nov. 1990 9.79337 ## dic. 1990 10.31276 ## ## [[13]] ## [,1] ## ene. 1991 8.48191 ## feb. 1991 8.77497 ## mar. 1991 9.17355 ## abr. 1991 9.08491 ## ## [[14]] ## [,1] ## may. 1991 9.07365 ## jun. 1991 9.23107 ## jul. 1991 9.33048 ## ago. 1991 9.43765 ## ## [[15]] ## [,1] ## sep. 1991 9.36198 ## oct. 1991 9.51833 ## nov. 1991 9.99068 ## dic. 1991 10.71577 ## ## [[16]] ## [,1] ## ene. 1992 8.93788 ## feb. 1992 9.19520 ## mar. 1992 9.58592 ## abr. 1992 9.35767 ## ## [[17]] ## [,1] ## may. 1992 9.14126 ## jun. 1992 9.47900 ## jul. 1992 9.72512 ## ago. 1992 9.89790 ## ## [[18]] ## [,1] ## sep. 1992 10.0830 ## oct. 1992 10.1422 ## nov. 1992 10.4920 ## dic. 1992 11.2988 ## ## [[19]] ## [,1] ## ene. 1993 9.23437 ## feb. 1993 9.32962 ## mar. 1993 9.99090 ## abr. 1993 9.76177 ## ## [[20]] ## [,1] ## may. 1993 9.68021 ## jun. 1993 9.83100 ## jul. 1993 10.17180 ## ago. 1993 10.26069 ## ## [[21]] ## [,1] ## sep. 1993 10.3257 ## oct. 1993 10.3360 ## nov. 1993 10.7501 ## dic. 1993 11.5585 #divide el conjunto de datos en partes de 4 meses cada una summary(sales.by.4months) #indica el número de elemento que hay en cada parte ## Length Class Mode ## [1,] 4 xts numeric ## [2,] 4 xts numeric ## [3,] 4 xts numeric ## [4,] 4 xts numeric ## [5,] 4 xts numeric ## [6,] 4 xts numeric ## [7,] 4 xts numeric ## [8,] 4 xts numeric ## [9,] 4 xts numeric ## [10,] 4 xts numeric ## [11,] 4 xts numeric ## [12,] 4 xts numeric ## [13,] 4 xts numeric ## [14,] 4 xts numeric ## [15,] 4 xts numeric ## [16,] 4 xts numeric ## [17,] 4 xts numeric ## [18,] 4 xts numeric ## [19,] 4 xts numeric ## [20,] 4 xts numeric ## [21,] 4 xts numeric Otras operaciones con los datos Finalmente, se presenta un ejemplo de una serie obtenida a partir del uso de operaciones básicas de R como diff y log. sales.inc &lt;- diff(log(sales), lag = 1) #Tasa de incremento mensual sales.inc &lt;- sales.inc[-1] #Eliminamos el primer dato por ser NA par(mfrow=c(1,1),cex.lab=0.8,cex.axis=0.8,las=2) plot(sales.inc, main = &quot;Nuevas Ventas&quot;, col = &quot;grey&quot;, xlab = &quot;Date&quot;, ylab = &quot;Variación&quot;, major.ticks=&#39;years&#39;, minor.ticks=FALSE) Gráficos con xts Los gráficos de objetos xts son bastante más visuales o legibles que los objetos ts. La principal diferencia está en el reconocimiento de las fechas y su visualización en el eje horizontal. par(mfrow=c(1,1),cex.lab=0.8,cex.axis=0.8,las=2) plot(sales, main = &quot;Ventas Mensuales&quot;, col = innCol[1],xlab = &quot;Date&quot;, ylab = &quot;Ventas&quot;, major.ticks=&#39;quarters&#39;, minor.ticks=FALSE) Gráficos con highcharter Los gráficos generados con highcharter utilizan la biblioteca Highcharts highchart() %&gt;% hc_chart(type=&quot;line&quot;,zoomType=&quot;x&quot;)%&gt;% hc_title(text = &quot;Ventas Mensuales&quot;) %&gt;% hc_subtitle(text = &quot;Gráfico Tipo Línea&quot;) %&gt;% hc_legend(enabled = T) %&gt;% hc_tooltip(valueDecimals= 2,shared=T, crosshairs=T) %&gt;% hc_xAxis(type = &#39;datetime&#39;, tickInterval=10, labels = list(format = &#39;{value:%m-%Y}&#39;,rotation=-90)) %&gt;% hc_add_series(data=sales.ts, name = &quot;Ventas&quot;, color = innCol[1], lineWidth= 1) %&gt;% hc_credits(enabled = TRUE, # add credits text = &quot;Elaborado por Innova-tsn&quot;, href = &quot;https://www.innova-tsn.com&quot;) %&gt;% hc_exporting(enabled = TRUE) hc &lt;- highchart(type=&quot;stock&quot;) %&gt;% hc_title(text = &quot;Ventas Mensuales&quot;) %&gt;% hc_subtitle(text = &quot;Gráfico tipo Stock&quot;) %&gt;% hc_legend(enabled = T) %&gt;% hc_tooltip(valueDecimals= 0) %&gt;% hc_add_series(data=sales.ts, name = &quot;Ventas&quot;, color = innCol[1]) %&gt;% hc_credits(enabled = TRUE, # add credits text = &quot;Elaborado por Innova-tsn&quot;, href = &quot;https://www.innova-tsn.com&quot;) hc Tendencia (anual) plot(sales.ts,main=&quot;Venta&quot;, type=&quot;l&quot;) abline(lm(sales.ts ~ time(sales.ts)),col=&quot;#9d9fa0&quot;,lty=3) Tendencia (anual) plot(aggregate(sales.ts,FUN=mean),main=&quot;Venta media por Año&quot;, type=&quot;h&quot;) Estacionalidad boxplot(sales.ts~cycle(sales.ts), main=&quot;Ventas por Mes&quot;) Variacion anual (diferencia) sales.ts.diff = diff(sales.ts, differences = 12) plot(sales.ts.diff) Test de Estacionariedad adf.test(diff(sales.ts,12), alternative=&quot;stationary&quot;, k=0) Augmented Dickey-Fuller Test data: diff(sales.ts, 12) Dickey-Fuller = -4.705, Lag order = 0, p-value = 0.01 alternative hypothesis: stationary ACF acf(sales.ts.diff) pacf(sales.ts.diff) Ajuste Modelo ARIMA (fit &lt;- arima(sales.ts, c(1, 1, 0),seasonal = list(order = c(0, 1, 1), period = 12))) Call: arima(x = sales.ts, order = c(1, 1, 0), seasonal = list(order = c(0, 1, 1), period = 12)) Coefficients: ar1 sma1 -0.502 -0.511 s.e. 0.101 0.154 sigma^2 estimated as 0.0311: log likelihood = 20.49, aic = -34.99 Previsión pred &lt;- predict(fit, n.ahead = 5*12) ts.plot(sales.ts,pred$pred, log = &quot;y&quot;, lty = c(1,3), main=&quot;Previsión 5 años&quot;) 7.6.1 Ver también Using R for Time Series Analysis TSA: Start to Finish Examples A Complete Tutorial on Time Series Modeling in R Business Science Demo Week TimeKit: Time Series Forecast Applications Using Data Mining Time Series Data Library "],
["a-manera-de-nota-final.html", "7.7 A manera de nota final", " 7.7 A manera de nota final Ver Fuente de la imagen "],
["aprendizaje-supervisado.html", "Capítulo 8 Aprendizaje Supervisado", " Capítulo 8 Aprendizaje Supervisado Los modelos de la estadística tradicional (regresiones lineales, por ejemplo) suelen ser poco flexibles por su naturaleza paramétrica, es decir, estos modelos se construyen partiendo de u nas hipótesis y que, si estas no se cumplen, el modelo falla estrepitosamente. Por ejemplo, una regresión lineal supone que la estructura de los datos sigue una tendencia lineal. Si la estructura de los datos no sigue la hipótesis de linealidad, el modelo lineal es inservible en este caso Los métodos propios del machine learning intentan ser métodos flexibles que permitan adaptarse a estructuras sin imponer hipótesis rígidas. Una de las ideas más potentes y que más éxito ha tenido es la de los modelos ensamblados Estos modelos consisten en utilizar algún tipo de modelo que a priori pueda ser débil (como un árbol de decisión) y ensamblar distintos modelos con algún tipo de modificación en el que cada uno enfatice alguna característica. Los modelos ensamblados (ensemble learning) que más uso tienen son: Bagging (bootstrap aggregating) Random Forest Boosting Estos tres modelos utilizan los árboles de decisión como algoritmo base, así que primero vamos a hablar sobre ellos. "],
["arboles-de-decision.html", "8.1 Árboles de decisión", " 8.1 Árboles de decisión Los árboles de decisión particionan el espacio en un conjunto de rectángulos y ajustan un modelo simple (como una constante) en cada uno de ellos. Formalmente, un árbol de decisión se puede expresar como \\[h(x; \\Theta) = \\sum_{j=1}^J \\gamma_J \\cdot I(x\\in R_j)\\] con parámetros \\(\\Theta = \\{ R_j, \\gamma_j \\}_1^J\\). Los parámetros se buscan de forma que \\[\\hat{\\Theta} = \\underset{\\Theta}{\\arg\\min} \\sum_{j=1}^J \\sum_{x_i \\in R_j} L(y_i, \\gamma_j)\\] 8.1.1 En R El siguiente ejemplo está sacado del libro Introduction to statistical learning library(tree) library(ISLR) datos &lt;- Carseats datos$High &lt;- as.factor(ifelse(datos$Sales &lt;= 8, &quot;No&quot;, &quot;Yes&quot;)) names(datos) ## [1] &quot;Sales&quot; &quot;CompPrice&quot; &quot;Income&quot; &quot;Advertising&quot; &quot;Population&quot; ## [6] &quot;Price&quot; &quot;ShelveLoc&quot; &quot;Age&quot; &quot;Education&quot; &quot;Urban&quot; ## [11] &quot;US&quot; &quot;High&quot; tree.carseats &lt;- tree(High ~ .-Sales, datos) summary(tree.carseats) ## ## Classification tree: ## tree(formula = High ~ . - Sales, data = datos) ## Variables actually used in tree construction: ## [1] &quot;ShelveLoc&quot; &quot;Price&quot; &quot;Income&quot; &quot;CompPrice&quot; &quot;Population&quot; ## [6] &quot;Advertising&quot; &quot;Age&quot; &quot;US&quot; ## Number of terminal nodes: 27 ## Residual mean deviance: 0.4575 = 170.7 / 373 ## Misclassification error rate: 0.09 = 36 / 400 plot(tree.carseats) text(tree.carseats) tree.carseats ## node), split, n, deviance, yval, (yprob) ## * denotes terminal node ## ## 1) root 400 541.500 No ( 0.59000 0.41000 ) ## 2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 ) ## 4) Price &lt; 92.5 46 56.530 Yes ( 0.30435 0.69565 ) ## 8) Income &lt; 57 10 12.220 No ( 0.70000 0.30000 ) ## 16) CompPrice &lt; 110.5 5 0.000 No ( 1.00000 0.00000 ) * ## 17) CompPrice &gt; 110.5 5 6.730 Yes ( 0.40000 0.60000 ) * ## 9) Income &gt; 57 36 35.470 Yes ( 0.19444 0.80556 ) ## 18) Population &lt; 207.5 16 21.170 Yes ( 0.37500 0.62500 ) * ## 19) Population &gt; 207.5 20 7.941 Yes ( 0.05000 0.95000 ) * ## 5) Price &gt; 92.5 269 299.800 No ( 0.75465 0.24535 ) ## 10) Advertising &lt; 13.5 224 213.200 No ( 0.81696 0.18304 ) ## 20) CompPrice &lt; 124.5 96 44.890 No ( 0.93750 0.06250 ) ## 40) Price &lt; 106.5 38 33.150 No ( 0.84211 0.15789 ) ## 80) Population &lt; 177 12 16.300 No ( 0.58333 0.41667 ) ## 160) Income &lt; 60.5 6 0.000 No ( 1.00000 0.00000 ) * ## 161) Income &gt; 60.5 6 5.407 Yes ( 0.16667 0.83333 ) * ## 81) Population &gt; 177 26 8.477 No ( 0.96154 0.03846 ) * ## 41) Price &gt; 106.5 58 0.000 No ( 1.00000 0.00000 ) * ## 21) CompPrice &gt; 124.5 128 150.200 No ( 0.72656 0.27344 ) ## 42) Price &lt; 122.5 51 70.680 Yes ( 0.49020 0.50980 ) ## 84) ShelveLoc: Bad 11 6.702 No ( 0.90909 0.09091 ) * ## 85) ShelveLoc: Medium 40 52.930 Yes ( 0.37500 0.62500 ) ## 170) Price &lt; 109.5 16 7.481 Yes ( 0.06250 0.93750 ) * ## 171) Price &gt; 109.5 24 32.600 No ( 0.58333 0.41667 ) ## 342) Age &lt; 49.5 13 16.050 Yes ( 0.30769 0.69231 ) * ## 343) Age &gt; 49.5 11 6.702 No ( 0.90909 0.09091 ) * ## 43) Price &gt; 122.5 77 55.540 No ( 0.88312 0.11688 ) ## 86) CompPrice &lt; 147.5 58 17.400 No ( 0.96552 0.03448 ) * ## 87) CompPrice &gt; 147.5 19 25.010 No ( 0.63158 0.36842 ) ## 174) Price &lt; 147 12 16.300 Yes ( 0.41667 0.58333 ) ## 348) CompPrice &lt; 152.5 7 5.742 Yes ( 0.14286 0.85714 ) * ## 349) CompPrice &gt; 152.5 5 5.004 No ( 0.80000 0.20000 ) * ## 175) Price &gt; 147 7 0.000 No ( 1.00000 0.00000 ) * ## 11) Advertising &gt; 13.5 45 61.830 Yes ( 0.44444 0.55556 ) ## 22) Age &lt; 54.5 25 25.020 Yes ( 0.20000 0.80000 ) ## 44) CompPrice &lt; 130.5 14 18.250 Yes ( 0.35714 0.64286 ) ## 88) Income &lt; 100 9 12.370 No ( 0.55556 0.44444 ) * ## 89) Income &gt; 100 5 0.000 Yes ( 0.00000 1.00000 ) * ## 45) CompPrice &gt; 130.5 11 0.000 Yes ( 0.00000 1.00000 ) * ## 23) Age &gt; 54.5 20 22.490 No ( 0.75000 0.25000 ) ## 46) CompPrice &lt; 122.5 10 0.000 No ( 1.00000 0.00000 ) * ## 47) CompPrice &gt; 122.5 10 13.860 No ( 0.50000 0.50000 ) ## 94) Price &lt; 125 5 0.000 Yes ( 0.00000 1.00000 ) * ## 95) Price &gt; 125 5 0.000 No ( 1.00000 0.00000 ) * ## 3) ShelveLoc: Good 85 90.330 Yes ( 0.22353 0.77647 ) ## 6) Price &lt; 135 68 49.260 Yes ( 0.11765 0.88235 ) ## 12) US: No 17 22.070 Yes ( 0.35294 0.64706 ) ## 24) Price &lt; 109 8 0.000 Yes ( 0.00000 1.00000 ) * ## 25) Price &gt; 109 9 11.460 No ( 0.66667 0.33333 ) * ## 13) US: Yes 51 16.880 Yes ( 0.03922 0.96078 ) * ## 7) Price &gt; 135 17 22.070 No ( 0.64706 0.35294 ) ## 14) Income &lt; 46 6 0.000 No ( 1.00000 0.00000 ) * ## 15) Income &gt; 46 11 15.160 Yes ( 0.45455 0.54545 ) * Para puntuar nuevas observaciones, simplemente utilizamos la función predict() cuyos parámetros más importantes son: object: el objeto resultante del ajuste del árbol. newdata: el data.frame que contiene la información a puntuar. type: el tipo de la predicción. Lo más recomendable es elegir vector que devuelve la probabilidad de cada clase. 8.1.2 Ventajas y desventajas Las ventajas son: Fáciles de entender su funcionamiento. Pueden ser interpretados gráficamente. Pueden manejar variables cualitativas sin necesidad de crear variables dummy. Las desventajas son: No tienen un buen poder predictivo. Poco robustos: un pequeño cambio en los datos suponen un gran cambio en el árbol estimado. "],
["bagging-y-random-forest.html", "8.2 Bagging y Random Forest", " 8.2 Bagging y Random Forest Uno de los problemas de los árboles de decisión es su alta varianza, es decir, un ligero cambio en los datos puede producir un gran cambio en la estructura del árbol. Para paliar este hecho, los modelos de bagging actúan de la siguiente forma: Se obtienen \\(n\\) muestras bootstrap. Se ajusta un modelo para cada una de las muestras. La predicción final será la media de las predicciones. Las muestras bootstrap consisten en seleccionar con reemplazamiento muestras de las observaciones originales. Esta idea se puede aplicar desde otro enfoque. Pueden existir variables que sean muy buenas predictoras y, aunque escojamos muestras bootstrap, puede que lso árboles siempre escojan estas variables haciendo que otras varaibles menos buenas no sean tenidas nunca en cuenta. Para ello, el modelo random forest actúa de la misma forma que el método de bagging pero **muestreando sobre las columnas en vez de las observaciones. Esto favorece que puedan intervenir variables que, a priori, no son tan buenas predictoras. 8.2.1 En R FALSE FALSE Call: FALSE randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE, subset = train) FALSE Type of random forest: regression FALSE Number of trees: 500 FALSE No. of variables tried at each split: 13 FALSE FALSE Mean of squared residuals: 10.80817 FALSE % Var explained: 86.91 FALSE %IncMSE IncNodePurity FALSE crim 12.042248 1083.56152 FALSE zn 2.144551 76.90258 FALSE indus 9.518353 1088.06694 FALSE chas 2.591068 77.14216 FALSE nox 12.346546 1002.78940 FALSE rm 32.409454 6134.55720 FALSE age 11.799314 530.13915 FALSE dis 15.362428 1309.52619 FALSE rad 3.468537 96.05578 FALSE tax 7.196484 361.87594 FALSE ptratio 10.103258 1018.55792 FALSE black 6.737108 384.53170 FALSE lstat 27.720132 7184.83340 "],
["boosting.html", "8.3 Boosting", " 8.3 Boosting Es una familia de algoritmos de machine learning cuya idea es la de utilizar métodos de aprendizaje débiles (weak learners) para crear un método de aprendizaje fuerte con alto poder predictivo. Es uno de los algoritmos de aprendizaje que mayor impacto han tenido en los últimos 20 años. Robert E. Schapire y Yoav Freund recibieron el premio Gödel en 2003 por su trabajo sobre boosting. La mayoría de los ganadores recientes en Kaggle, utilizan boosting. Buscadores como Yahoo utilizan versiones propias de algoritmos de boosting. El algoritmo sería Inicializar: \\(\\omega_1^{(i)}=\\frac{1}{n} \\text{ con } i = 1, \\ldots , n\\) -Repetir \\(t = 1, \\ldots, T\\): Seleccionar un clasificador \\(h_t(x_i)\\) para los datos de entrenamiento usando \\(\\omega_t^{(i)}\\) Calcular \\(\\alpha_t\\) Calcular \\(\\omega_{t+1}^{(i)} \\text{ para } i = 1, \\ldots, n\\) Modelo final: \\[H(x) = sign\\left(\\sum_{t=1}^T\\alpha_th_t(x)\\right)\\] Lo descrito anteriormente se denomina AdaBoost y se aplica solamente para problema de tipo binario. Para poder aplicarlo a cualquier tipo de problema, tenemos el gradient boosting, donde se utiliza el algoritmo del descenso del gradiente: El algoritmo gradient boosting queda de la siguiente forma Inicializar: \\(H_0 \\equiv 0\\) Repetir para \\(t = 1, \\ldots, T\\): Calcular para \\(i = 1, \\ldots, n\\) \\[r_{it}=-\\left[ \\frac{\\partial L(y_i, H(x_i))}{\\partial H(x_i)}\\right]_{H=H_{t-1}}\\] Ajustar \\(h_t\\) a \\(r_{it}\\) Elegir \\(\\alpha_t &gt;0\\) tal que \\[\\alpha_t = \\underset{\\alpha_t}{\\arg\\min} \\sum_{i= 1}^n L(x_i, H_{t-1}(x_i)+\\alpha_th_t(x_i))\\] 8.3.1 Optimización de parámetros Como con cualquier otro modelo, lleva asociados una serie de parámetros que necesitan ser ajustados para encontrar el mejor modelo. Dos formas básicas de hacerlo son Hacer un barrido con un número elevado de combinaciones. Hacer una búsqueda orientada de los metaparámetros óptimos. Paso 1. Modelo inicial. Hacer un primer lanzamiento dejando las opciones por defecto o elegir una combinación inicial. Por ejemplo, profundidad = 5. submuestra = 0.8. shrinkage = 0.1. Paso 2. Profundidad del árbol Una vez que tenemos un modelo base, realizamos pruebas con distintas profundidades de árbol. Una buena idea suele ser elegir profundidades entre 2 y 10. Paso 3. Submuestra (y muestra de columnas) El siguiente paso es elegir un porcentaje de observaciones que se utilizarán, aleatoriamente, en cada iteración. Se suelen elegir valores 0.6, 0.7, 0.8, 0.9. A veces, si el volumen de datos es muy grande, se pueden elegir submuestras por debajo de 0.5 sin que se vea afectado el poder predictivo. En caso de que el software lo permita, se puede probar a la vez el muestreo sobre columnas (idea de random forest) Paso 4. Shrinkage Por último, nos ocupamos del shrinkage, probablemente el valor que más puede ayudar a tener un mejor modelo. En función de la estructura de los datos, podemos hacer un barrido inicial de, por ejemplo, 0.1, 0.01 y 0.001. En este caso es importante cambiar el número de iteraciones a un valor alto y elegir el número óptimo de estas mediante parada temprana. 8.3.2 En R library(xgboost) dtrain &lt;- xgb.DMatrix(agaricus.train$data, label = agaricus.train$label) dtest &lt;- xgb.DMatrix(agaricus.test$data, label = agaricus.test$label) watchlist &lt;- list(eval = dtest, train = dtrain) xgb_grid = expand.grid( eta = c(0.1, 0.05, 0.01, 0.001), max_depth = c(3, 6, 8, 10), colsample_bytree = 1, subsample = c(0.6, 0.75, 1) ) modelos.xgb &lt;- data.frame() tiempo.ini &lt;- Sys.time() for (model in 1:nrow(xgb_grid)){ set.seed(1234) boosting &lt;- xgb.train(data = dtrain, nrounds = 10, objective = &quot;binary:logistic&quot;, booster = &quot;gbtree&quot;, eval_metric = &quot;auc&quot;, params = as.list(xgb_grid[model,]), watchlist = watchlist, early_stopping_rounds = 3 ) modelos.xgb &lt;- rbind(modelos.xgb, data.frame( xgb_grid[model,], iteracion = boosting$best_iteration, ntree = boosting$best_ntreelimit, error = boosting$best_score)) print(paste(&#39;modelo&#39;, model, &#39; de &#39;, nrow(xgb_grid))) print(max(modelos.xgb$error)) print(paste(&#39;Tiempo &#39;,Sys.time() - tiempo.ini)) } pred &lt;- predict(boosting, agaricus.test$data, ntreelimit = 8) "],
["explicacion-de-prediccion.html", "8.4 Explicación de predicción", " 8.4 Explicación de predicción Una crítica que se hace a los modelos de Machine Learning es que están muy orientados hacia la predicción lo que provoca que sean modelos muy complejos convirtiéndose en cajas negras y de los que perdemos la “explicatividad” del modelo. Esto conlleva que los usuarios finales para los que se desarrollan los modelos puedan perder el interés por el ya que no entienden la naturaleza de las predicciones. Esto es especialmente relevante en entornos médicos: si se construye un modelo para determinar si se debe hacer una intervención, para que el equipo médico pueda confiar en el modelo necesita entender qué soporta la decisión de intervenir al margen de indicadores formales. Para solventar estos problemas surge una iniciativa relativamente novedosa conocida como LIME. La referencia se puede consultar en el siguiente paper: [https://arxiv.org/pdf/1602.04938v1.pdf]. La idea intuitiva que hay detrás de esta técnica es que, aunque un modelo pueda ser altamente complejo y flexible, se supone que es localmente estable: Por ejemplo, si entrenasemos una red neuronal para intenar describir los elementos de una fotografía, nos interesaría saber qué es lo que soporta la decisión 8.4.1 Un ejemplo en R library(lime) library(MASS) data(biopsy) biopsy$ID &lt;- NULL biopsy &lt;- na.omit(biopsy) names(biopsy) &lt;- c(&#39;clump thickness&#39;, &#39;uniformity of cell size&#39;, &#39;uniformity of cell shape&#39;, &#39;marginal adhesion&#39;, &#39;single epithelial cell size&#39;, &#39;bare nuclei&#39;, &#39;bland chromatin&#39;, &#39;normal nucleoli&#39;, &#39;mitoses&#39;, &#39;class&#39;) set.seed(4) test_set &lt;- sample(seq_len(nrow(biopsy)), 100) prediction &lt;- biopsy$class biopsy$class &lt;- NULL model &lt;- lda(biopsy[-test_set, ], prediction[-test_set]) explainer &lt;- lime(biopsy[-test_set,], model) explanation &lt;- explain(biopsy[test_set[1:4], ], explainer, n_labels = 1, n_features = 4) plot_features(explanation, ncol = 1) "],
["sobre-in-training.html", "A Sobre in-training", " A Sobre in-training in-training es una iniciativa del Aula Innova. Es la respuesta de Innova-tsn a la necesidad actual de formación especializada y personalizada de nuestros clientes ante un entorno en continua evolución y unos cambios tecnológicos vertiginosos. El conocimiento y especialización que Innova-tsn ha adquirido a lo largo de los años, su continua apuesta por la innovación y la cualificación e inquietud académica de sus profesionales, permiten crear una oferta formativa flexible y totalmente personalizada que aúna conocimientos teóricos y experiencia práctica. De este modo, se pretende alcanzar eficientemente el principal objetivo de Aula Innova: Dotar a los clientes de Innova-tsn de los conocimientos y competencias necesarias para afrontar eficiente y autónomamente sus propios retos de negocio. "],
["colaboradores.html", "B Colaboradores", " B Colaboradores Alicia Morales alicia.morales@innova-tsn.com Alicia Muñoz alicia.munoz@innova-tsn.com Alvaro Díaz alvaro.munoz@innova-tsn.com Andrés Devia andres.devia@innova-tsn.com Daniel Vélez daniel.velez@innova-tsn.com Diego Fernández diego.fernandez@innova-tsn.com Jaume Puigbó jaume.puigbo@innova-tsn.com Juan Luis Rivero juan.rivero@innova-tsn.com Pablo Hidalgo pablo.hidalgo@innova-tsn.com Romy Rodríguez romy.rodríguez@innova-tsn.com "],
["references.html", "References", " References "]
]
