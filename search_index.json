[
["index.html", "Modelización en R Presentación", " Modelización en R Aula Innova. Innova-tsn Sabadell. Enero-Febrero, 2018 Presentación Modelización con R es un manual práctico para la creación y utilización de modelos analíticos con el lenguaje R (R Core Team 2017). En particular, esta versión del manual ha sido desarrollada para el equipo de modelling del Banc Sabadell en Barcelona. El objetivo de este manual es presentar de manera resumida, los principales algoritmos del analytics, destacando cuándo deben ser utilizados y cómo evaluar su performance. Cada capítulo corresponde a un tópico. Se pueden leer de manera individual. Todos los ejemplo están desarrollados con datos incluidos en las librerias de R y/o se encuentran disponibles en la web. Para realizar las prácticas sugeridas en este manual, el lector requiere un portátil donde tenga instaladas las últimas versiones de R y RStudio. Además debe contar con una conexión a internet y la posibilidad de instalar las librerías que se citan a lo largo del documento. References "],
["modelizacion.html", "Capítulo 1 Modelizar", " Capítulo 1 Modelizar Los sistemas analíticos están presentes en todas las áreas de negocio del sector bancario. A muy alto nivel, se puede contar con modelos predictivos en la gestión de clientes, gestión del riesgo y en el soporte a las operaciones. Así mismo, dichos sistemas pueden estar desagregados por segmento, producto, región geográfica, etc. Algunas de las aplicaciones de la modelización son: Clientes Con modelos predictivos se puede mejorar la relación con los clientes, a través de: Anticipación de la Fuga (Retención), Incentivo del Uso de Productos (Fidelización), Adquisición de Nuevos Productos (Venta Cruzada), Anticipación de la Reclamación (Satisfacción), Promociones que le interesen (Gestión de Campañas), etc. Riesgo Con modelos analíticos se puede optimizar todo el ciclo de cobranza: Concesión de créditos, Anticipar impagos, Detectar fraude, Optimización de la Cobranza, etc. Operaciones Con modelos predictivos se puede hacer más eficientes algunos procesos como: Gestión de sucursales, Optimización de personal, Gestión de cajeros automáticos, Inversión en marketing, Gestión del call center, etc. Las técnicas/modelos analíticos utilizadas dependen del output o target. En general, se trabaja con outputs binarios (1-0), outputs continuos o, más recientemente, datos no estructurados. "],
["modelizar.html", "1.1 ¿Qué es Modelizar?", " 1.1 ¿Qué es Modelizar? Modelizar es el proceso de crear, desarrollar y validar modelos que sirvan para convertir los datos en información de negocio significativa que ayude a ejecutar las estrategias y mejorar el rendimiento. Data science es la disciplina que permite convertir los datos en conocimiento (Garrett Grolemund 2017). Modelizar es una de las fases del Data Science. Un esquema aceptado sobre las fases de un proyecto de Data Science es1: Data y Analytics van de la mano. Más generalmente, como lo expone Marr (2017), en el context de Big Data, apply analytics (A), se encuentra en el corazón de la estrategia para crear SMART Business y aprovechar al máximo el valor de los datos. En resumen, Modelizar es el proceso de crear, desarrollar y validar modelos que sirvan para convertir los datos en información de negocio significativa que ayude a ejecutar las estrategias y mejorar el rendimiento. Los modelos más comunes son: modelos de regresión, modelos de series temporales, técnicas de machine learning, etc. References "],
["que-es-un-modelo-analitico.html", "1.2 ¿Qué es un modelo analítico?", " 1.2 ¿Qué es un modelo analítico? Un modelo es resumen simple, de baja dimensión, de un conjunto de datos (Garrett Grolemund 2017). Algunas de las afirmaciones tradicionalmente aceptadas sobre un modelo analítico son: Un modelo es una representación simplificada de la realidad. Un modelo es una forma matemática de describir la relación entre una variable de respuesta y un conjunto de variables independientes. Un modelo se puede ver como: (a) Una teoría sobre cómo se generaron los datos y (b) Una forma útil de resumir los datos. A un modelo no se le exige que sea verdadero, sino que sea útil, de acuerdo a los objetivos para los cuales fue creado. Todos los modelos son errados, pero algunos son útiles. De manera general, un modelo es una representación del mecanismo generador de los datos. Por ello, un modelo puede verse como un resumen de la información disponible y en consecuencia permite compactar los datos existentes. Los modelos se utilizan principalmente para entender dinámicas del mercado, prever el futuro, simular consecuencias ante cambios, evaluar acciones pasadas, etc. Los modelos son el elemento central de la creación de inteligencia corporativa. Condesan y operacionalizan la información existente. Son almacenes y fábricas de conocimiento. Cuando se quiere hacer uso de un modelo, se suele identificar: output : variable dependiente, variable respuesta, variable objetivo. input(s) : variable(s) independiente(s), predictor(es), o simplemente feature(s). References "],
["tipos-de-problemas.html", "Capítulo 2 Tipos de Problemas", " Capítulo 2 Tipos de Problemas En bastante común que los algoritmos de Machine Learning en aprendizaje supervisado y aprendizaje no supervisado. Esta misma clasificación se menciona en la sección 2.1, las herramientas de statistical learning. Este tipo de clasificación responde al tipo de problema e información que disponemos del output, por ello, en este Manual generalizamos esta clasificación y la denominamos Tipo de Problema Analítico que debemos afrontar. Problema / Aprendizaje Supervisado En el aprendizaje supervisado, cada dato, unidad analizada u observación está etiquetada o asociada con una categoría o valor de interés. Ejemplos: Una imagen es etiquetada como un ‘gato’ o ‘perro’. Un cliente es etiquetado como ‘propenso’ o ‘no propenso’ al uso del canal digital. El precio de venta asociado a un coche usado, es una etiqueta de valor. El objetivo del aprendizaje supervisado es estudiar muchos ejemplos etiquetados y, luego, poder realizar predicciones sobre los datos futuros. Por ejemplo, identificar nuevas fotografías con el animal correcto, identificar clientes a clientes facilitar el uso de la banca online o asignar precios de venta precisos a otros coches usados. El aprendizaje supervisado usa técnicas de clasificación y regresión para desarrollar modelos predictivos. Las técnicas de clasificación predicen respuestas discretas —por ejemplo, saber si un correo es genuino o spam, o si un tumor es benigno o maligno. Los modelos de clasificación categorizan los datos de entrada. Entre las aplicaciones típicas se incluyen imágenes médicas, reconocimiento de voz o puntaje crediticio. Cuando hay sólo dos opciones, se denomina clasificación de dos clases o binaria. Cundo hay más categorías, se denomina clasificación multiclase o multinomial. En algunos casos la detección de anomalías se considera una técnica adicional de clasificación. En la detección de fraude, por ejemplo, los patrones de gasto de tarjeta de crédito muy poco habituales son sospechosos. Las posibles variaciones son tan numerosas y los ejemplos de formación son tan pocos, que no es posible saber de qué actividad fraudulenta se trata. El enfoque que toma la detección de anomalías es simplemente aprender qué puede considerarse como actividad normal (haciendo uso de las transacciones no fraudulentas del historial) e identificar todo lo que sea significativamente diferente2. Las técnicas de reducción de dimensionalidad ayudan a disminuir la complejidad de los problemas debida al gran volumen de datos. Cuando mayor es el conjunto de datos, mayor la necesidad de reducir el número de variables (features) que se quieren analizar. Las técnicas de regresión predicen respuestas continuas —por ejemplo, cambios en la temperatura o fluctuaciones en la demanda de energía. Las aplicaciones típicas pueden ser previsión del recurso eléctrico o trading algorítmico. Problema / Aprendizaje No Supervisado En el aprendizaje no supervisado, los datos no tienen etiquetas asociadas a ellos. En este caso, el objetivo es organizar los datos de alguna manera o describir su estructura. Esto puede significar agrupar clientes en segmentos, o buscar diferentes maneras de examinar datos complejos para que parezcan más simples. El aprendizaje no supervisado se utiliza en análisis exploratorio de datos para encontrar características ocultas y agrupar. Las aplicaciones del clustering incluyen análisis de secuencias genéticas, investigación de mercado y reconocimiento de objetos. Fuente:https://docs.microsoft.com/es-es/azure/machine-learning/studio/algorithm-choice↩ "],
["clasemodelos.html", "2.1 Enfoques de Modelización", " 2.1 Enfoques de Modelización Statistical Learning se refiere a un conjunto de herramientas para modelar y comprender conjuntos de datos complejos. Statistical Learning es un término presentado en Gareth James (2014). Hace referencia a un área de reciente desarrollo en estadística, que se combina con desarrollos paralelos de ciencias de la computación (específicamente, Machine Learning). Se refiere a un ámplio conjunto de herramientas para entender datos. Estas herramientas pueden ser: supervisadas o no supervisadas. De manera muy genérica, en los problemas supervisados se busca estimar o prever un output basado en uno o más inputs. En los problemas no supervisados, se cuenta con los inputs pero con un output, por lo que se busca entender la estructura de los datos. Otra forma de clasificar los métodos para modelizar se basa en su objetivo y forma de construcción. Cuando se prioriza la interpretación del modelo, buscando que expliquen las relaciones entre output e inputs, se habla de modelos estadísticos. Cuando se prioriza la precisión de la previsión se habla de algoritmos de machine learning. Tipos de modelos analíticos: Modelos Estadísticos y Machine Learning3. Los primeros hacen uso de la probabilidad (inferencia), son explicativos y predictivos. Los segundos suelen ser ‘cajas negras’, se centran en la previsión. El objetivo de los modelos o algoritmos de Machine Learning es enseñar a las computadoras a hacer lo que es natural para humanos y animales: aprender de la experiencia. Estos algoritmos utilizan métodos computacionales para “aprender” información directamente de los datos, sin depender de una ecuación predeterminada como modelo. Los algoritmos mejoran su rendimientode forma adaptativa conforme aumenta la cantidad de muestras (datos) disponibles para el aprendizaje. Machine Learning El Machine Learning no requiere hipótesis previas sobre las relaciones subyacentes entre las variables (o inputs). Sólo se deben ingresar todos los datos que se diponga, y el algoritmo procesa los datos y descubre patrones, con los cuales puede hacer predicciones sobre el nuevo conjunto de datos. El aprendizaje automático trata un algoritmo como una black box (caja negra), siempre que funcione. En otras palabras, su principal objetivo es la previsión. Modelos Estadísticos Por el contrario, los estadísticos deben comprender cómo se recopilaron los datos, las propiedades estadísticas de los estimadores, la distribución subyacente de la población que están estudiando y los tipos de propiedades que esperaría si hiciera el experimento muchas veces. Necesita saber exactamente lo que está haciendo y proponer parámetros que le proporcionen el poder predictivo. References "],
["catalogo-de-tecnicas.html", "Capítulo 3 Catálogo de Técnicas", " Capítulo 3 Catálogo de Técnicas ¿Tus datos pueden ser etiquetados o categorizados? Si tus datos pueden ser separados en clases o grupos específicos, usa algoritmos de clasificación. ¿Estás trabajando con datos de un rango? Si la naturaleza de tu respuesta es un número real - como la temperatura o el tiempo hasta que un cajero automático falle -, usa modelos o algoritmos de regresión. ¿Aún no sabes como agrupar tus datos: Usa clúster jerárquico para encontrar posibles estructuras en los datos. Usa la evaluación de clústers para encontrar el ‘mejor’ número de grupos. "],
["tecnicas-de-clustering.html", "3.1 Técnicas de Clustering", " 3.1 Técnicas de Clustering La mayoría de las técnicas de aprendizaje no supervisado son una forma de análisis por cluster. En análisis por cluster, los datos son divididos en grupos de acuerdo con alguna métrica de similaridad o característica compartida. De esta forma los objetos o instancias en el mismo clúster son muy similares y los de distintos muy diferentes. Los algoritmos de clustering se dividen en dos grandes grupos4: Clustering rígido, donde cada dato pertenece únicamente a un clúster. Clustering suave, donde cada dato puede pertenecer a más de un clúster. k-means ¿Cómo trabaja? Particiona datos en k número de clusters mutuamente excluyentes. El como de bien un punto se ajuste a un clúster determinado viene dado por su distancia al centro de dicho clúster. ¿Cuándo se usa? Cuando el número de clusters es conocido y cuando se requiere un clustering rápido de grandes conjuntos de datos. ¿Cuál es el resultado? Centroide de cada cluster. k-medoids ¿Cómo trabaja? Algoritmo similar a k-medias pero requiere de que los centroides sean puntos u observaciones de la muestra. ¿Cuándo se usa? Cuando el número de clusters es conocido. Para clustering rápido de datos categóricos. Para escalar a grandes conjuntos de datos. ¿Cuál es el resultado? Observación o individuo de la muestra que actúa de centroide o medoide de cada cluster. Hierarchical Clustering ¿Cómo trabaja? Produce conjuntos anidados de datos analizando similaridades entre pares de puntos y agrupando objetos en un arbol binario jerárquico. ¿Cuándo se usa? Cuando se desconoce el número de clusters a los que darán lugar los datos. Cuando se requiere de visualización para guiar la elección. ¿Cuál es el resultado? Dendograma mostrando la relación jerárquica entre los clusters. Self-Organizing Map ¿Cómo trabaja? Red neuronal basada en clustering que transforma un conjunto de datos en un mapa 2D con preservación de topología. ¿Cuándo se usa? Para observar datos de alta dimensionalidad en mapas 2D o 3D. Para deducir la dimensionalidad de los datos preservando su topología (forma). ¿Cuál es el resultado? Representación en dimensión más baja (típicamente en 2D) Fuzzy c-Means ¿Cómo trabaja? Agrupamiento difuso. Agrupamiento basado en particiones en el que los datos pueden estar en más de un cluster. ¿Cuándo se usa? Cuando el número de clusters es conocido. Para reconocimento de patrones. Cuando los clusters se sobreponen o se solopan. ¿Cuál es el resultado? Centro de los clústers (similar a k-means) pero con difusión (fuzziness) de forma que las observaciones o individuos pueden pertenecer a más de 1 cluster. Gaussian Mixture Model ¿Cómo trabaja? Modelo gaussiando mixto. Agrupación basada en particiones en la que los datos provienen de diferentes distribuciones normales multivariantes con ciertas probabilidades. ¿Cuándo se usa? Cuando un punto puede pertenecer a más de un clúster. Cuando los clusters diferentes tamaños y correlaciones entre ellos. ¿Cuál es el resultado? Modelo de distribuciones gausianas que proporciona la probabilidad de que una observación o individuo pertenezca a un clúster. Fuente: https://es.mathworks.com/discovery/machine-learning.html↩ "],
["tecnicas-de-clasificacion.html", "3.2 Técnicas de Clasificación", " 3.2 Técnicas de Clasificación Regresión Logística ¿Cómo trabaja? Ajusta un modelo que puede predecir la probabilidad de que una respuesta binaria pertenezca a una clase u otra. Debido a su simplicidad, la regresión logística se utiliza comúnmente como punto de partida para los problemas de clasificación binaria. ¿Cuándo se usa? Cuando los datos se pueden separar claramente por un solo límite lineal. Como una línea de base (baseline) para evaluar más complejos métodos de clasificación. k Vecinos Cercanos (kNN) ¿Cómo trabaja? kNN categoriza los objetos en función de las clases de su vecinos más cercanos en el conjunto de datos. Las predicciones de kNN suponen que los objetos cercanos entre sí son similares. Algunas de las métricas de distancia utilizadas para encontrar el vecino más cercano son: Euclides, bloque de la ciudad_city block, coseno y Chebychev. ¿Cuándo se usa? Cuando se requiere un algoritmo simple para establecer reglas de aprendizaje de referencia o base. Cuando el uso de memoria del modelo entrenado no es una preocupación. Cuando la velocidad de predicción del modelo entrenado tampoco constituye una limitación. Support Vector Machines (SVM) ¿Cómo trabaja? Clasifica datos encontrando el límite de decisión lineal (hiperplano) que separa todos los puntos de datos de una clase de los de la otra clase. El mejor hiperplano para una SVM es aquel con el mayor margen entre las dos clases, cuando los datos son linealmente separables. Si los datos no son linealmente separables, se utiliza una función de pérdida para penalizar los puntos en el lado equivocado del hiperplano Los SVM a veces usan una transformación de núcleo para transformar los datos no separables linealmente en dimensiones más altas donde un límite de decisión lineal puede ser encontrado. ¿Cuándo se usa? Para datos que tienen exactamente dos clases.Para datos de alta dimensión, no linealmente separables.Cuando se necesita un clasificador que sea simple, fácil de interpretar y preciso. Redes Neuronales ¿Cómo trabaja? Inspirada en el cerebro humano, una red neuronal consiste enredes de neuronas altamente conectadas que relacionan las entradas a las salidas deseadas La red se entrena de forma iterativa, modificando las fortalezas de las conexiones para que las entradas se asignen a la respuesta correcta. ¿Cuándo se usa? Para modelar sistemas altamente no lineales. Cuando los datos están disponibles de forma incremental y se desea actualiza constantemente el modelo. Cuando podría haber cambios inesperados en su datos de entrada. Cuando la interpretabilidad del modelo no es una preocupación importante. Árboles de Decisión ¿Cómo trabaja? Un árbol de decisión permite predecir respuestas a datos siguiendo las decisiones organizadas en un árbol, desde la raíz (inicio) hasta un nodo u hoja. Un árbol consiste en condiciones organizadas en forma de ramificaciones, donde el valor de un predictor se compara con un peso entrenado. Los número de ramas y los valores de los pesos se determinan en el proceso de entrenamiento. Algunas acciones adicionales, como la poda, se pueden usar para simplificar el modelo. ¿Cuándo se usa? Cuando se necesita un algoritmo fácil de interpretar y rápido de ejecutar. Para minimizar el uso de memoria. Cuando la precisión predictiva alta no es un requisito. Bagging, Boosting ¿Cómo trabaja? Varios árboles de decisión “más débiles” son combinados en un conjuto “más fuerte”. Un árbol de decisión en bolsas (bagging) consta de árboles entrenados de forma independiente en los datos que se remuestrean (boostrapping) a partir de los datos de entrada. Boosting implica crear un modelo fuerte mediante la adición iterativa de modelos “débiles” y ajustando el peso de cada modelo débil para centrarse en ejemplos mal clasificados. ¿Cuándo se usa? Cuando los predictores son categóricos (discretos) o se comportan no lineal. Análisis Discriminante ¿Cómo trabaja? Clasifica los datos a partir de combinaciones lineales de los inputs. El análisis discriminante asume que las diferentes clases de datos se pueden generar a partir de distribuciones gaussianas. Entrenar o ajustar un modelo de análisis discriminante implica encontrar los parámetros para la distribución gaussiana de cada clase. ¿Cuándo se usa? Cuando necesitas un modelo simple que sea fácil de interpretar. Cuando el uso de la memoria durante el entrenamiento es una preocupación. Cuando necesitas un modelo que sea rápido para predecir. "],
["tecnicas-de-regresion.html", "3.3 Técnicas de Regresión", " 3.3 Técnicas de Regresión Regresión Lineal ¿Cómo trabaja? La regresión lineal es una clase de modelo estadístico utilizado para describir una variable de respuesta continua como una función lineal de una o más variables predictoras. Dado que los modelos de regresión lineal son simples de interpretar y fáciles de entrenar, a menudo constituyen el primer modelo que se ajusta a un nuevo conjunto de datos. ¿Cuándo se usa? Cuando se necesita un algoritmo fácil de interpretar y rápido de ejecutar. Como línea de base para evaluar otros modelos de regresión más complejos. SVM Regression ¿Cómo trabaja? Los algoritmos de regresión SVM funcionan como los algoritmos de clasificación SVM, pero están modificados para poder predecir una respuesta continua. En lugar de encontrar un hiperplano que separa los datos, los algoritmos de regresión SVM encuentran un modelo que se desvía (aleja) de los datos observados por un valor no mayor que una pequeña cantidad, con valores que son tan pequeños como posible (para minimizar la sensibilidad al error). ¿Cuándo se usa? Para datos de alta dimensión (donde habrá una gran cantidad de variables predictoras) Generalized Linear Models ¿Cómo trabaja? Un modelo lineal generalizado es un caso especial de modelo no lineal. Implica ajustar un combinación lineal de los inputs a una función no lineal (la función de enlace) de los outputs. ¿Cuándo se usa? Cuando las variables de respuesta tienen un comportamiento de distribución no normal, como una variable de respuesta que se espera que sea siempre positiva. Regression Tree ¿Cómo trabaja? Los árboles de decisión para la regresión son similares a los árboles de decisión para clasificación, pero se modifican para poder predecir respuestas continuas. ¿Cuándo se usa? Cuando los predictores son categóricos (discretos) o se comportan no lineal. Gaussian Process Regression Model ¿Cómo trabaja? Los modelos de regresión de procesos gaussianos (GPR) son modelos no paramétricos que se utilizan para predecir el valor de una variable de respuesta continua. Son ampliamente utilizados en el campo del análisis espacial para la interpolación en presencia de incertidumbre. GPR también se conoce como Kriging. ¿Cuándo se usa? Para la interpolación de datos espaciales. "],
["tecnicas-de-reduccion-de-dimension.html", "3.4 Técnicas de Reducción de Dimensión", " 3.4 Técnicas de Reducción de Dimensión Análisis de Componentes Principales (PCA) ¿Cómo trabaja? Realiza una transformación lineal en los datos de forma que la mayor varianza o información en el conjunto de datos de alta dimensión es capturada por las primeras (pocas) componentes principales. La primera componente capturará la mayor varianza, seguida por la segunda componente principal, y así sucesivamente. Análisis Factorial ¿Cómo trabaja? Identifia las correlaciones subyacentes entre las variables del conjunto de datos para proporcionar una representación en términos de un número pequeño de factores comunes latentes o no observables. "],
["otras-tecnicas.html", "3.5 Otras ‘Técnicas’", " 3.5 Otras ‘Técnicas’ Minería de Textos Video/Image Analytics Speech Analytics Stream Analytics "],
["que-tecnica-utilizar.html", "3.6 ¿Qué técnica utilizar?", " 3.6 ¿Qué técnica utilizar? Elegir el algoritmo adecuado puede parecer abrumador—hay docenas de algoritmos de statistical learning, y cada uno tiene una aproximación diferente. No existe un único mejor método o uno que sirva para todos los casos. Buscar el adecuado es a veces una tarea de prueba y error—incluso los científicos de datos con más experiencia no pueden saber si un algoritmo funcionará sin haberlo probado. La selección del algoritmo también depende del tamaño y del tipo de los datos con el que se está trabajando, los resultados que se quieren obtener y como dichos resultados serán usados. El primer paso, y uno de los más importantes, es definir el objetivo del análisis que se va a realizar. Volviendo al esquema propuesto por Marr (2017) (presentado en 1.1), Start with Strategy implica que, antes de empezar con los datos, se empiece con la definición de los objetivos de negocio que se quieren alcanzar. Inmediatamente después se definen los datos y las métricas que estarán involucradas. En este momento se conoce la naturaleza del problema y de la variable objetivo, por lo tanto se conoce si estamos delante de una variable continua o binaria, si se requiere de un modelo explicativo, si sólo se requiere una segmentación, etc. En consecuencia, una vez conocida la decisión que se requiere tomar y la variable objetivo que se analizará, se puede elegir el enfoque y modelo especíco que se va a utilizar. Considera utilizar un modelo estadístico si se debe priorizar el poder explicativo, se dispone de tiempo computacional y memoria para ajustar modelos relativamente complejos. Algunas situaciones donde este enfoque es útil son: Proceso de concesión de créditos, con modelos supervisados por la entidad reguladora. Asignación de presupuesto anual de marketing Determinación de metas de venta por distribuidor, centro, etc. Considera usar el machine learning cuando se tenga una tarea compleja o un problema que involucre una gran cantidad de datos o variables, pero no exista fórmula o ecuación. Por ejemplo, machine learning es una buena opción si se requieren manejar situaciones como: Las reglas y ecuaciones de escritura a mano son muy complejas—como reconocimiento facial o de voz. Las reglas de las tareas están cambiando constantemente—como en detección de fraude desde los registros de transacciones. La naturaleza de los datos es cambiante y el programa necesita adaptarse—como en el trading automático, previsión de demanda de energía y predicción de tendencias en compras. Algunas consideraciones al elegir un algoritmo son5: Precisión No siempre es necesario obtener la respuesta más precisa posible. A veces, una aproximación ya es útil, según para qué se la desee usar. Si es así, puede reducir el tiempo de procesamiento de forma considerable al usar métodos más aproximados. Otra ventaja de los métodos más aproximados es que tienden naturalmente a evitar el sobreajuste. Tiempo (de entrenamiento) La cantidad de minutos u horas necesarios para modelizar varía mucho según el algoritmo. A menudo, el tiempo depende de la precisión (generalmente, uno determina al otro). Además, algunos algoritmos son más sensibles a la cantidad de datos que otros. Si el tiempo es limitado, esto puede determinar la elección del algoritmo, especialmente cuando el conjunto de datos es grande. Cantidad de parámetros Los parámetros son los botones que el analista activa al configurar un algoritmo. Son números que afectan al comportamiento del algoritmo, como la tolerancia a errores o la cantidad de iteraciones, o bien opciones de variantes de comportamiento del algoritmo. El tiempo de entrenamiento y la precisión del algoritmo a veces pueden ser muy sensibles y requerir solo la configuración correcta. Normalmente, los algoritmos con muchos parámetrosla mayor cantidad de pruebas para encontrar una buena combinación. La ventaja es que tener muchos parámetros normalmente indica que un algoritmo tiene mayor flexibilidad. Se puede lograr una precisión muy alta, siempre y cuando se encuentre la combinación correcta de configuraciones de parámetros. Cantidad de variables Para ciertos tipos de datos, la cantidad de variables o características puede ser muy grande en comparación con la cantidad de datos. Este suele ser el caso de la genética o los datos textuales. Una gran cantidad de características puede trabar algunos algoritmos y provocar que el tiempo de procesamiento sea demasiado largo. Linealidad Muchos algoritmos hacen uso de la linealidad. Los algoritmos de clasificación lineal suponen que las clases pueden estar separadas mediante una línea recta (o su análogo de mayores dimensiones). Entre ellos, se encuentran la regresión logística y las máquinas de vectores de soporte (svm). Los algoritmos de regresión lineal suponen que las tendencias de datos siguen una línea recta. Estas suposiciones no son incorrectas para algunos problemas, pero en otros disminuyen la precisión. Casos especiales Algunos algoritmos hacen determinadas suposiciones sobre la estructura de los datos o los resultados deseados. Si encuentra uno que se ajuste a sus necesidades, este puede ofrecerle resultados más útiles, predicciones más precisas o tiempos de procesamiento más cortos. References "],
["evaluacion-de-modelos.html", "Capítulo 4 Evaluación de modelos", " Capítulo 4 Evaluación de modelos El ciclo de vida de un modelo empieza con su propia definición, pasando por la extracción y tratamiento de los datos y la evaluación, tanto antes de ponerlo en producción, como en la monitorización de su calidad predictiva. La diagnosis o evaluación es la clave para lograr un ecosistema de modelos que impacte en la organización. Hay muchas métricas para evaluar como de bien o de mal funciona un modelo o algoritmo. Para determinar cuáles usar en un problema particular, necesitamos formas sistemáticas de evaluar cómo funcionan los diferentes métodos y comparar uno con otro. La evaluación no es tan simple como podría parecer a primera vista. La diagnosis de los modelos puede realizarse desde dos perspectivas: Negocio y Estadística. Ambas pueden ser utilizadas para monitorizar la calidad de los modelos en producción. La frecuencia de análisis depende del tipo de modelo. Diagnosis de Negocio: Se refiere a la utilización de métricas que indican si se cumplen las hipótesis sobre las cuales se ha construido el modelo, además de evaluar su calidad predictiva. Ejemplo de estas métricas son: R2, MAPE, AUC, LIFT, etc Diagnosis Estadística: Se refiere a la discusión del significado de los resultados, teniendo en cuenta el sentido del negocio. Elementos susceptibles de esta interpretación son: parámetros, análisis decom, due-to, etc. "],
["diagnosis-de-negocio.html", "4.1 Diagnosis de Negocio", " 4.1 Diagnosis de Negocio Los parámetros de los modelos estadisticos sirven para cuantificar el efecto de las palancas. Su interpretación depende de la propia especificación del modelo. Los principales tipos de parámetros son: elasticidad, semi-elasticidad, piecewise, yes/no. Si el output es 0-1, la interpretación de los parámetros depende de la función enlace utilizada (logit o probit). Análisis de Descomposición. Mide el efecto de cada input o driver sobre el output de un periodo Análisis de due-to. Compara el efecto de los inputs o drivers en el output entre dos periodos "],
["evaluacion-en-respuesta-binaria.html", "4.2 Evaluación en Respuesta Binaria", " 4.2 Evaluación en Respuesta Binaria No todos los problemas son iguales, con lo que no todos los problemas pueden usar las mismas métricas de evaluación. En esta sección veremos las métricas más usuales para los tipos de problemas que nos podemos encontrar. Si nos centramos en modelos supervisados, nos encontramos básicamente dos problemas distintos: clasificación y regresión. 4.2.1 Clasificación En los problemas de clasificación tenemos la variable objetivo que son las clases o etiquetas que debemos predecir y una serie de variables que son los predictores. Es decir, usando los predictores obtenemos una etiqueta. Nos podemos encontrar con problemas de clasificación binaria (dos clases) o múltiple (más de dos clases). Para simplificar nos centraremos en la clasificación binaria, pero lo podemos trasladar a los problemas de clasificación múltiple. 4.2.1.1 Confusion matrix La confusion matrix o matriz de confusión muestra el número de predicciones correctas e incorrectas hechas por el modelo de clasificación en comparación con los resultados reales en los datos. La matriz de confusión es una matriz \\(n \\times n\\), dónde \\(n\\) es el número de clases. La siguiente tabla muestra una matriz de confusión de \\(2x2\\) para dos clases (positiva y negativa). Accuracy: la proporción del número total de predicciones correctas. \\[ACC = \\frac{TP+TN}{TP+TN+FP+FN}\\] Positive Predictive Value or Precision: la proporción de casos positivos que fueron identificados correctamente. \\[PPV = \\frac{TP}{TP+FP}\\] Negative Predictive Value: la proporción de casos negativos que fueron identificados correctamente. \\[ NPV = \\frac{TN}{TN+FN} \\] Sensitivity or Recall: la proporción de casos positivos reales que están correctamente identificados. \\[TPR = \\frac{TP}{TP+FN}\\] Specificity: la proporción de casos negativos reales que están correctamente identificados. \\[TNR = \\frac{TN}{TN+FP}\\] 4.2.1.2 Log-Loss La log-loss o pérdida logarítmica entra en los detalles más finos de un clasificador. En particular, si la salida bruta del clasificador es una probabilidad numérica en lugar de una etiqueta de clase de \\(0\\) o \\(1\\), se puede usar la log-loss. La probabilidad se puede entender como un indicador de confianza. Si la etiqueta es \\(0\\) pero el clasificador cree que pertenece a la clase \\(1\\) con probabilidad de \\(0,51\\). Aunque el clasificador estaría cometiendo un error de clasificación, el error se comente por poco, ya que la probabilidad está muy cerca del punto de corte de \\(0.5\\). La log-loss es una medición de precisión que incorpora esta idea de confianza probabilística. La log-loss para un clasificador binario es \\[LogLoss = - \\frac{1}{n} \\sum_{i=1}^{n} y_i \\log p_i + (1-y_i) \\log (1-p_i)\\] donde \\(n\\) es el número de registros, \\(y_i\\) es la etiqueta de la muestra \\(i\\), y \\(p_i\\) es la probabilidad del obtenida en el modelo. 4.2.1.3 Curvas ROC Para los modelos de clasificación obtenidos a partir de una probabilidad se suelen usar las curvas ROC. Una curva ROC (acrónimo de Receiver Operating Characteristic, o Característica Operativa del Receptor) es una representación gráfica de la sensitivity (TPR) frente a la specificity (TNR) para un sistema clasificador binario según se varía el umbral de discriminación. La curva ROC se puede usar para generar estadísticos que resumen el rendimiento (o la efectividad, en su más amplio sentido) del clasificador. A continuación se proporcionan algunos: El punto de inserción de la curva ROC con la línea convexa a la línea de discriminación. El área entre la curva ROC y la línea de convexo-paralela discriminación. El área bajo la curva ROC, llamada comúnmente AUC (area under curve). El indicador más utilizado en muchos contextos es el área bajo la curva ROC o AUC. Este índice se puede interpretar como la probabilidad de que un clasificador ordenará o puntuará una instancia positiva elegida aleatoriamente más alta que una negativa. En la figura abajo se muestran tres ejemplos de curvas ROC. La gráfica de la izquierda es la curva de un modelo perfecto, la del medio es la de un caso real con una \\(AUC = 0.8\\) y la de la derecha es la gráfico de un modelo no informativo. 4.2.1.4 Gráficos de ganancia y elevación (Gain and Lift Charts) La ganancia o la elevación es una medida de la efectividad de un modelo de clasificación calculado como la relación entre los resultados obtenidos con y sin el modelo. Los gráficos de ganancia y elevación son ayudas visuales para evaluar el rendimiento de los modelos de clasificación. Sin embargo, en contraste con la matriz de confusión que evalúa los modelos en toda la población, los gráficos de ganancia o elevación evalúan el modelo en una porción de la población. Para crear estos gráficos es necesario crear un ranking basado en la creabilidad de la predicción hecha por el modelo. En la figura tenemos un ejemplo de como obtener los puntos de las curvas de ganancia y elevación, y sus correspondientes gráficos. Igual que las curvas ROC, se busca el mayor AUC en las curvas de ganancia. Mientras que para los gráficos de elevación el modelo perfecto es el que la diferencia entre la línea azul y roja es nula. En otras palabras queremos una AUC mínima del gráfico de elevación. 4.2.2 Medidas de desigualdad 4.2.2.1 El coeficiente de Gini El coeficiente de Gini es una medida de la desigualdad ideada por el estadístico italiano Corrado Gini. El coeficiente de Gini es un número entre \\(0\\) y \\(1\\), en donde \\(0\\) se corresponde con la perfecta igualdad y donde el valor \\(1\\) se corresponde con la perfecta desigualdad. El coeficiente de Gini se calcula como una proporción de las áreas en el diagrama de la curva de Lorenz. De forma resumida, la Curva de Lorenz es una gráfica de concentración acumulada de la distribución superpuesta a la curva de la distribución de frecuencias de los individuos, y su expresión en porcentajes es el índice de Gini. El coeficiente de Gini puede obtener mediante la siguiente fórmula: \\[G = \\left| 1-\\sum_{k=1}^{n-1} (X_{k+1}-X_k)(Y_{k+1}+Y_k) \\right|\\] donde \\(X\\) es la proporción acumulada de la variable población, \\(Y\\) es la proporción acumulada de la variable a estudiar la desigualdad y \\(n\\) es el número de la población. 4.2.2.2 Índice de entropía El índice de entropía generalizado se ha propuesto como una medida de la desigualdad en una población. Se deriva de la teoría de la información como una medida de redundancia en los datos. En la teoría de la información, una medida de redundancia puede interpretarse como no aleatoriedad o compresión de datos; por lo tanto, esta interpretación también se aplica a este índice. La fórmula de la entropía general para un valor real \\(\\alpha\\) es: \\[GE(\\alpha) = \\begin{cases} \\frac{1}{n\\alpha (\\alpha -1)} \\sum_{i=1}^{n} \\left(\\left( \\frac{y_i}{\\bar{y}} \\right) ^{\\alpha} -1\\right), &amp;\\quad \\alpha\\neq0,1 ,\\\\ \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i}{\\bar{y}} \\ln \\frac{y_i}{\\bar{y}} &amp;\\quad \\alpha = 1 ,\\\\ -\\frac{1}{n} \\sum_{i=1}^{n} \\ln \\frac{y_i}{\\bar{y}} &amp;\\quad \\alpha = 0 .\\\\ \\end{cases}\\] donde \\(n\\) el número de muestras y \\(y\\) es la medida de desigualdad. "],
["evaluacion-en-respuesta-continua.html", "4.3 Evaluación en Respuesta Continúa", " 4.3 Evaluación en Respuesta Continúa 4.3.1 Modelos de Regresión En los problemas de regresión siempre tenemos una variable numérica dependiente que es la que queremos predecir y el resto son los predictores. Para evaluar los modelos de regresión tenemos varias métricas para evaluar el error cometido en al predicción: RMSE (root mean squared error) o error cuadrado medio: RMSE es la métrica más popular para medir la tasa de error de un modelo de regresión. \\[RMSE = \\sqrt {\\frac{\\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2}{n}}\\] donde \\(n\\) es el número de muestras, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. MAE (mean abosulte error) o error absoluto medio: \\[MAE = \\frac{\\sum_{i=1}^{n} | \\hat{y}_i - y_i |}{n}\\] donde \\(n\\) es el número de muestras, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. RSE (relative squared error) o error relativo cuadrado: \\[RSE = \\sqrt \\frac{\\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2}{\\sum_{i=1}^{n} (\\bar{y} - y_i)^2}\\] donde \\(n\\) es el número de muestras, \\(\\bar{y}\\) es la media de la variable objetivo, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. RAE (relative absolute error) o error relativo absoluto: \\[RAE = \\frac{\\sum_{i=1}^{n} |\\hat{y}_i - y_i|}{\\sum_{i=1}^{n} |\\bar{y} - y_i|}\\] donde \\(n\\) es el número de muestras, \\(\\bar{y}\\) es la media de la variable objetivo, \\(\\hat{y}_i\\) el valor predicho de la variable objetivo y \\(y_i\\) el valor real de la variable objetivo. Coeficiente \\(R^2\\): \\(R^2\\) resume el poder explicativo del modelo de regresión y se calcula a partir de los términos de las sumas de cuadrados. El coeficiente \\(R^2\\) toma valores entre \\(0\\) y \\(1\\), si \\(R^2=1\\) la regresión es perfecta. \\[R^2 = \\frac {SSR}{SST} = 1 - \\frac{SSE}{SST}, \\] donde \\[SST = \\sum_{i=1}^{n} (y - \\bar{y})^2 ,\\] \\[SSR = \\sum_{i=1}^{n} (\\hat{y} - \\bar{\\hat{y}})^2 ,\\] \\[SSE = \\sum_{i=1}^{n} (y-\\hat{y})^2 .\\] 4.3.2 Modelos de Series temporales Las series temporales son básicamente un problema de regresión. La diferencia es que hay una variable temporal y el objetivo es predecir el futuro dado un histórico. Por lo tanto, las métricas utilizadas son las mismas que las usadas para los problemas de regresión vistas en la sección anterior. Otras métricas usadas frecuentemente para la evaluación de series temporales son: MAPE MAPE viene de Mean Absolute Percentage Error. Los errores porcentuales tienen la ventaja de ser independientes de la escala y, por lo tanto, se utilizan con frecuencia para comparar el rendimiento del pronóstico entre diferentes conjuntos de datos. MAPE es el más usual. \\[MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{100·|\\hat{y_i}-y_i|}{y_i}\\] AIC AIC viene de Akaike information criterion. Se define como \\[AIC = 2k-2\\ln (\\hat{L})\\] Dado un conjunto de modelos candidatos para los datos, el modelo preferido es el que tiene el valor mínimo en el AIC. Por lo tanto AIC no sólo recompensa la bondad de ajuste, sino también incluye una penalidad, que es una función creciente del número de parámetros estimados. BIC BIC**_ viene de Bayesian Information Criterion)_. Se define como \\[BIC = \\ln (n) k - 2 \\ln (\\hat{L})\\] donde \\(\\hat{L}\\) es máximo de la función de verosimilitud, \\(n\\) es el número de muestras, \\(k\\) es el número de parámetros estimados por el modelo. La fórmula del BIC es similar a la fórmula del AIC, pero con una penalización distinta que varia según el número de muestras de los datos. "],
["evaluacion-en-clustering.html", "4.4 Evaluación en Clustering", " 4.4 Evaluación en Clustering El Clustering es una forma de tratar los datos para los que no se conocen o no están definidos los grupos. Por tanto, tenemos que conceptualizar los grupos. Este hecho dificultad evaluar la calidad de los clasificación obtenida. 4.4.1 Silueta El coeficiente silueta proporciona una representación gráfica del grado de integración de un objeto en su cluster. El coeficiente silueta de un objeto \\(i\\) se define como: \\[s_i=\\dfrac{b_i -a_i}{max(b_i -a_i)}\\] donde \\(a_i\\) denota la distancia media entre el objeto \\(i\\) y todos los otros objetos de su cluster y \\(b_i\\) denota la distancia media mínima entre \\(i\\) y los objetos de otros clusters. Los objetos con un coeficiente de silueta \\(s_i\\) alto están bien integrados en su cluster; aquéllos con un si bajo tienden a estar entre clusters. "],
["metodos-de-re-muestreo.html", "4.5 Métodos de re-muestreo", " 4.5 Métodos de re-muestreo 4.5.1 Training &amp; testing Lo primero que debemos hacer para conseguir una buena evaluación es dividir los datos en dos subconjuntos. Uno para entrenar el modelo (training) y otro para evaluar el modelo (testing). El partición entre estos dos subconjuntos suele hacerse de forma aleatoria, aunque según el problema podemos usar otros criterios. Por ejemplo, si los datos que tenemos son una serie temporal, entonces podemos dividirlos a partir de un cierto tiempo. Es decir, coger como test los datos más recientes. La razón de hacer esta división es usar los datos del subconjunto training para entrenar el modelo y luego evaluar los datos del testing. De esta manera simulamos correctamente una evaluación, ya que no podemos evaluar unos datos si hemos entrenado con ellos. Por lo tanto, los datos de testing no deben ser observados por el algoritmo. 4.5.2 Cross validation El procedimiento que se suele usar para evaluar un modelo es cross validation o validación cruzada. La idea básica de cross validation consiste en dividir los datos en \\(k\\) subconjuntos. Cada subconjunto se predice mediante un modelo entrenado con el resto. De esta manera podemos hacer una evaluación sobre todos los datos y evitamos el problema de obtener una muestra sesgada si sólo lo hiciéramos una vez. "],
["practica-en-r.html", "4.6 Práctica en R", " 4.6 Práctica en R Evaluaremos la calidad predictiva de dos modelos: Cuando la variable respuesta es binaria. Cuando la variable respuesta es contínua. 4.6.1 Preparación de los datos Definimos el Entorno de Trabajo El primer paso es crear una carpeta con nuestros modelos y resultados dentro de nuestro espacio de trabajo (proyecto). Obtenemos la ruta completa del directorio de trabajo6. myWD &lt;- getwd() Elegimos un nombre para nuestra carpeta con resultados myWorkingFolderName &lt;- &#39;ModelResults&#39; Creamos la carpeta donde guardaremos nuestros resultados y ficheros dir.create( paste0(getwd(),&quot;/&quot;,myWorkingFolderName)) Accedemos a los datos originales Cargamos la librería insuranceData que contiene los datos que utilizaremos7 if (!require(insuranceData)) install.packages(&#39;insuranceData&#39;) library(insuranceData) Para ver los contenidos de la librería insuranceData ejecutamos: data(package=&#39;insuranceData&#39;) Vemos que hay 10 datasets. Trabajaremos con el primero: AutoBi (Automobile Bodily Injury Claims8). Cargamos el conjunto de datos seleccionado: pérdidas en accidentes de coches data(&quot;AutoBi&quot;) Descripción de las 8 variables del conjunto de datos (tabla) ‘AutoBi’: Casenum. Identificador de la reclamación (esta variable no se utiliza en los modelos) Attorney. Indica si el reclamante está representado por un abogado (1= Sí, 2 = No) Clmsex. Sexo del reclamante (1 = Hombre, 2 = Mujer) Marital. Estado Civil del reclamante (1 = Casado, 2 = Soltero, 3 = Viudo, 4 = divorciado/separado) Clminsur. Indica si el conductor del vehículo del reclamante estaba o no asegurado (1 = Si, 2 = No, 3 = No aplica) Seatbelt. Si el reclamante llevaba o no un cinturón de seguridad en el asiento infantil (1 = Si, 2 = No, 3 = No Aplica) Clmage. Edad del reclamante. Loss (*). La pérdida económica total del reclamante (en miles). Esta es la variable objetivo o dependiente del conjunto de datos. Revisamos el contenido de la tabla y el tipo de datos que contiene str(AutoBi) FALSE &#39;data.frame&#39;: 1340 obs. of 8 variables: FALSE $ CASENUM : int 5 13 66 71 96 97 120 136 152 155 ... FALSE $ ATTORNEY: int 1 2 2 1 2 1 1 1 2 2 ... FALSE $ CLMSEX : int 1 2 1 1 1 2 1 2 2 1 ... FALSE $ MARITAL : int NA 2 2 1 4 1 2 2 2 2 ... FALSE $ CLMINSUR: int 2 1 2 2 2 2 2 2 2 2 ... FALSE $ SEATBELT: int 1 1 1 2 1 1 1 1 1 1 ... FALSE $ CLMAGE : int 50 28 5 32 30 35 19 34 61 NA ... FALSE $ LOSS : num 34.94 10.892 0.33 11.037 0.138 ... Exploramos el contenido con estadísticos descriptivos básicos summary(AutoBi) FALSE CASENUM ATTORNEY CLMSEX MARITAL FALSE Min. : 5 Min. :1.000 Min. :1.000 Min. :1.000 FALSE 1st Qu.: 8579 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 FALSE Median :17453 Median :1.000 Median :2.000 Median :2.000 FALSE Mean :17213 Mean :1.489 Mean :1.559 Mean :1.593 FALSE 3rd Qu.:25703 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:2.000 FALSE Max. :34253 Max. :2.000 Max. :2.000 Max. :4.000 FALSE NA&#39;s :12 NA&#39;s :16 FALSE CLMINSUR SEATBELT CLMAGE LOSS FALSE Min. :1.000 Min. :1.000 Min. : 0.00 Min. : 0.005 FALSE 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:19.00 1st Qu.: 0.640 FALSE Median :2.000 Median :1.000 Median :31.00 Median : 2.331 FALSE Mean :1.908 Mean :1.017 Mean :32.53 Mean : 5.954 FALSE 3rd Qu.:2.000 3rd Qu.:1.000 3rd Qu.:43.00 3rd Qu.: 3.995 FALSE Max. :2.000 Max. :2.000 Max. :95.00 Max. :1067.697 FALSE NA&#39;s :41 NA&#39;s :48 NA&#39;s :189 Para llamar directamente a las variables por sus nombres en la tabla AutoBi utilizamos el comando attach attach(AutoBi) Exploramos la variable objetivo LOSS es la variable objetivo una variable altamente asimétrica (con posibles outliers a la derecha o pérdida muy severa)9. Analizamos la variable target summary(LOSS) FALSE Min. 1st Qu. Median Mean 3rd Qu. Max. FALSE 0.005 0.640 2.331 5.954 3.995 1067.697 Analizamos la distribución de la variable target hist(LOSS, breaks=300 , probability = T) lines(density(LOSS), col=&quot;red&quot;,main=&quot;Loss distribution&quot;) Utilizamos una medida robusta (depende de la mediana y del IQR10) para segmentar los datos en dos clases: 1 si las pérdidas son atípicamente altas o 0 si no lo son. lsup &lt;- median(LOSS) + 1.5*IQR(LOSS) # Criterio basado en estadisticos robustos sum(LOSS&gt;=lsup) # 153 datos de perdidas atipicamente altas FALSE [1] 153 (Opcional) Guardamos el gráfico del histograma de las pérdidas no severas Path_to_graphics &lt;- paste0(getwd(),&quot;/&quot;,&quot;Graphics&quot;) dir.create(Path_to_graphics) png(paste0(Path_to_graphics,&quot;/histograma.png&quot;)) hist(LOSS[LOSS&lt;lsup], breaks = 100, probability = T, xlab=&quot;loss (pérdida en miles US $)&quot;, main=&quot;Pérdida no severa&quot;) lines(density(LOSS[LOSS&lt;lsup]),col=&quot;red&quot;) dev.off() FALSE png FALSE 2 Creamos el dataset de trabajo. Creamos un dataset o tabla de trabajo eliminando la variable CASENUM (id) y filtrando por la variable LOSS y el valor lsup= 72.22587 (miles). df_autobi &lt;- AutoBi[ , -match(&quot;CASENUM&quot;, colnames(AutoBi)) ] Fijamos los predictores categóricos como factores: Representado por un abogado: ‘1’ = representado por letrado y ‘2’ = no representado df_autobi$ATTORNEY &lt;- ordered(df_autobi$ATTORNEY, levels = 1:2) Sexo: ‘1’ = hombre y ‘2’ = mujer df_autobi$CLMSEX &lt;- ordered(df_autobi$CLMSEX , levels = 1:2) Estado civil: ‘1’ = casado, ‘2’ = soltero, ‘3’ = viudo y ‘4’ = divorciado / separado df_autobi$MARITAL &lt;- ordered(df_autobi$MARITAL , levels = 1:4) Vehículo asegurado: ‘1’ = vehículo estaba asegurado y ‘2’= no lo estaba df_autobi$CLMINSUR &lt;- ordered(df_autobi$CLMINSUR, levels = 1:2) Cinturón de seguridad: ‘1’ = llevaba cinturón abrochado y ‘2’ = no lo llevaba df_autobi$SEATBELT &lt;- ordered(df_autobi$SEATBELT, levels = 1:2) Pérdida: ‘1’= pérdida severa y ‘2’= pérdida no severa df_autobi$Y &lt;- ifelse(df_autobi$LOSS&gt;= lsup,1,0) Exploramos el dataset que acabamos de crear y verificamos la proporción de casos con pérdida severa (11.42%) summary(df_autobi) FALSE ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE FALSE 1:685 1 :586 1 :624 1 : 120 1 :1270 Min. : 0.00 FALSE 2:655 2 :742 2 :650 2 :1179 2 : 22 1st Qu.:19.00 FALSE NA&#39;s: 12 3 : 15 NA&#39;s: 41 NA&#39;s: 48 Median :31.00 FALSE 4 : 35 Mean :32.53 FALSE NA&#39;s: 16 3rd Qu.:43.00 FALSE Max. :95.00 FALSE NA&#39;s :189 FALSE LOSS Y FALSE Min. : 0.005 Min. :0.0000 FALSE 1st Qu.: 0.640 1st Qu.:0.0000 FALSE Median : 2.331 Median :0.0000 FALSE Mean : 5.954 Mean :0.1142 FALSE 3rd Qu.: 3.995 3rd Qu.:0.0000 FALSE Max. :1067.697 Max. :1.0000 FALSE Exploramos la relación de la pérdida con los factores. agg_loss_attorney &lt;- aggregate(LOSS, by = list(ATTORNEY) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_attorney)[[1]] &lt;- c(&quot;REPRESENTED&quot;,&quot;NOT REPRESENTED&quot;) ; dimnames(agg_loss_attorney)[[2]] &lt;- c(&quot;ATTORNEY&quot;,&quot;LOSS&quot;) agg_loss_clmsex &lt;- aggregate(LOSS, by = list(CLMSEX) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_clmsex)[[1]] &lt;- c(&quot;MALE&quot;,&quot;FEMALE&quot;) ; dimnames(agg_loss_clmsex)[[2]] &lt;- c(&quot;CLMSEX&quot;,&quot;LOSS&quot;) agg_loss_marital &lt;- aggregate(LOSS, by = list(MARITAL) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_marital)[[1]] &lt;- c(&quot;MARRIED&quot;,&quot;SINGLE&quot;,&quot;WIDOW&quot;,&quot;DIVORCED&quot;) ; dimnames(agg_loss_marital)[[2]] &lt;- c(&quot;MARITAL&quot;,&quot;LOSS&quot;) agg_loss_clminsur &lt;- aggregate(LOSS, by = list(CLMINSUR) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_clminsur)[[1]] &lt;- c(&quot;INSURED&quot;,&quot;NOT INSURED&quot;) ; dimnames(agg_loss_clminsur)[[2]] &lt;- c(&quot;CLMINSUR&quot;,&quot;LOSS&quot;) agg_loss_seatbelt &lt;- aggregate(LOSS, by = list(SEATBELT) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_seatbelt)[[1]] &lt;- c(&quot;SEATBELT&quot;,&quot;NOT SEATBELT&quot;) ; dimnames(agg_loss_seatbelt)[[2]] &lt;- c(&quot;SEATBELT&quot;,&quot;LOSS&quot;) Creamos los sets train y test Aleatorizamos los datos y separamos el set de datos en train y test: N=nrow(df_autobi) Es recomendable fijar una semilla (seed) para los algoritmos de aleatorización internos de R if (!require(caret)) install.packages(&#39;caret&#39;) library(caret) set.seed(123456) inTrain &lt;- createDataPartition(df_autobi$Y, times = 1, p = 0.7, list = TRUE) dt_train &lt;- df_autobi[inTrain[[1]],] # 938 casos dt_test &lt;- df_autobi[-inTrain[[1]],] # 402 casos nrow(dt_train) FALSE [1] 938 summary(dt_train) FALSE ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE FALSE 1:471 1 :406 1 :439 1 : 77 1 :885 Min. : 0.00 FALSE 2:467 2 :523 2 :455 2 :833 2 : 17 1st Qu.:20.00 FALSE NA&#39;s: 9 3 : 10 NA&#39;s: 28 NA&#39;s: 36 Median :32.00 FALSE 4 : 25 Mean :33.06 FALSE NA&#39;s: 9 3rd Qu.:43.00 FALSE Max. :95.00 FALSE NA&#39;s :134 FALSE LOSS Y FALSE Min. : 0.0050 Min. :0.0000 FALSE 1st Qu.: 0.7123 1st Qu.:0.0000 FALSE Median : 2.3645 Median :0.0000 FALSE Mean : 5.4656 Mean :0.1141 FALSE 3rd Qu.: 4.0263 3rd Qu.:0.0000 FALSE Max. :273.6040 Max. :1.0000 FALSE nrow(dt_test) FALSE [1] 402 summary(dt_test) FALSE ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE FALSE 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 FALSE 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 FALSE NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 FALSE 4 : 10 Mean :31.31 FALSE NA&#39;s: 7 3rd Qu.:42.00 FALSE Max. :78.00 FALSE NA&#39;s :55 FALSE LOSS Y FALSE Min. : 0.0050 Min. :0.0000 FALSE 1st Qu.: 0.5175 1st Qu.:0.0000 FALSE Median : 2.1645 Median :0.0000 FALSE Mean : 7.0917 Mean :0.1144 FALSE 3rd Qu.: 3.7782 3rd Qu.:0.0000 FALSE Max. :1067.6970 Max. :1.0000 FALSE Comprobamos si se que los conjuntos train y test se han formado correctamente length(intersect(inTrain, setdiff(1:N,inTrain))) FALSE [1] 0 4.6.2 Clasificación Vamos a construir un modelo para identificar los casos con pérdidas severas. El primer ejemplo lo hacemos con Random Forest if (!require(randomForest)) install.packages(&#39;randomForest&#39;) library(randomForest) Creamos un objeto de clase ‘formula’ y se lo pasamos como argumento a la función randomForest11 set.seed(123456) fmla.rf1 &lt;- as.formula(paste0(&quot;Y&quot;,&quot; ~&quot;,paste0(colnames(df_autobi[,-c(7,8)]),collapse = &quot;+&quot;),collapse = &quot;&quot;)) rf1 &lt;- randomForest( fmla.rf1, data =dt_train, ntree = 5000, # se ejecuta muy rapido, podemos utilizar ntree &gt; = 2500 replace =TRUE, mtry=4, maxnodes =50, importance = TRUE, proximity = TRUE, keep.forest = TRUE, na.action=na.omit) Exploramos el objeto con los resutados rf1 FALSE FALSE Call: FALSE randomForest(formula = fmla.rf1, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, importance = TRUE, proximity = TRUE, keep.forest = TRUE, na.action = na.omit) FALSE Type of random forest: regression FALSE Number of trees: 5000 FALSE No. of variables tried at each split: 4 FALSE FALSE Mean of squared residuals: 0.1038307 FALSE % Var explained: 1.6 summary(rf1) FALSE Length Class Mode FALSE call 11 -none- call FALSE type 1 -none- character FALSE predicted 759 -none- numeric FALSE mse 5000 -none- numeric FALSE rsq 5000 -none- numeric FALSE oob.times 759 -none- numeric FALSE importance 12 -none- numeric FALSE importanceSD 6 -none- numeric FALSE localImportance 0 -none- NULL FALSE proximity 576081 -none- numeric FALSE ntree 1 -none- numeric FALSE mtry 1 -none- numeric FALSE forest 11 -none- list FALSE coefs 0 -none- NULL FALSE y 759 -none- numeric FALSE test 0 -none- NULL FALSE inbag 0 -none- NULL FALSE terms 3 terms call FALSE na.action 179 omit numeric str(rf1) FALSE List of 19 FALSE $ call : language randomForest(formula = fmla.rf1, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, imp| __truncated__ ... FALSE $ type : chr &quot;regression&quot; FALSE $ predicted : atomic [1:759] 0.007273 0.000081 0.675016 0.006908 0.017108 ... FALSE ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... FALSE .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... FALSE $ mse : num [1:5000] 0.104 0.119 0.117 0.12 0.121 ... FALSE $ rsq : num [1:5000] 0.0107 -0.1241 -0.112 -0.1409 -0.1452 ... FALSE $ oob.times : int [1:759] 1836 1929 1846 1829 1860 1811 1808 1830 1811 1797 ... FALSE $ importance : num [1:6, 1:2] 0.016961 -0.002353 0.004298 0.000851 0.001241 ... FALSE ..- attr(*, &quot;dimnames&quot;)=List of 2 FALSE .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE .. ..$ : chr [1:2] &quot;%IncMSE&quot; &quot;IncNodePurity&quot; FALSE $ importanceSD : Named num [1:6] 1.63e-04 1.05e-04 1.70e-04 8.66e-05 5.90e-05 ... FALSE ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE $ localImportance: NULL FALSE $ proximity : num [1:759, 1:759] 1 0.192 0 0.427 0 ... FALSE ..- attr(*, &quot;dimnames&quot;)=List of 2 FALSE .. ..$ : chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... FALSE .. ..$ : chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... FALSE $ ntree : num 5000 FALSE $ mtry : num 4 FALSE $ forest :List of 11 FALSE ..$ ndbigtree : int [1:5000] 99 99 99 99 99 99 99 99 99 99 ... FALSE ..$ nodestatus : int [1:99, 1:5000] -3 -3 -3 -3 -3 -3 -3 -1 -1 -3 ... FALSE ..$ leftDaughter : int [1:99, 1:5000] 2 4 6 8 10 12 14 0 0 16 ... FALSE ..$ rightDaughter: int [1:99, 1:5000] 3 5 7 9 11 13 15 0 0 17 ... FALSE ..$ nodepred : num [1:99, 1:5000] 1.26e-01 1.50e-02 1.66e-01 1.53e-16 2.61e-02 ... FALSE ..$ bestvar : int [1:99, 1:5000] 6 6 3 6 6 1 4 0 0 1 ... FALSE ..$ xbestsplit : num [1:99, 1:5000] 20.5 15.5 3.5 3.5 17.5 1.5 1.5 0 0 1.5 ... FALSE ..$ ncat : Named int [1:6] 1 1 1 1 1 1 FALSE .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE ..$ nrnodes : int 99 FALSE ..$ ntree : num 5000 FALSE ..$ xlevels :List of 6 FALSE .. ..$ ATTORNEY: num 0 FALSE .. ..$ CLMSEX : num 0 FALSE .. ..$ MARITAL : num 0 FALSE .. ..$ CLMINSUR: num 0 FALSE .. ..$ SEATBELT: num 0 FALSE .. ..$ CLMAGE : num 0 FALSE $ coefs : NULL FALSE $ y : atomic [1:759] 1 0 1 0 0 0 0 0 0 1 ... FALSE ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... FALSE .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... FALSE $ test : NULL FALSE $ inbag : NULL FALSE $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language Y ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + SEATBELT + CLMAGE FALSE .. ..- attr(*, &quot;variables&quot;)= language list(Y, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) FALSE .. ..- attr(*, &quot;factors&quot;)= int [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ... FALSE .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 FALSE .. .. .. ..$ : chr [1:7] &quot;Y&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... FALSE .. .. .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE .. ..- attr(*, &quot;term.labels&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... FALSE .. ..- attr(*, &quot;order&quot;)= int [1:6] 1 1 1 1 1 1 FALSE .. ..- attr(*, &quot;intercept&quot;)= num 0 FALSE .. ..- attr(*, &quot;response&quot;)= int 1 FALSE .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; FALSE .. ..- attr(*, &quot;predvars&quot;)= language list(Y, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) FALSE .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:7] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... FALSE .. .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Y&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... FALSE $ na.action :Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... FALSE .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... FALSE - attr(*, &quot;class&quot;)= chr [1:2] &quot;randomForest.formula&quot; &quot;randomForest&quot; Gráfico de la importancia relativa de los predictores varImpPlot(rf1,sort = T,main = &quot;Variable Importance&quot;) Gráfico del Error vs número de árboles plot(rf1, main=&quot;Error de clasificación vs núero de árboles&quot;) Gráfico de la probabilidad condicional: \\(P(Y=1|X_1 = ATTORNEY,\\ldots,X_6=SEATBELT)\\) rf1.prediction &lt;- as.data.frame(predict(rf1, newdata = dt_train)) summary(rf1.prediction) ## predict(rf1, newdata = dt_train) ## Min. :0.00007 ## 1st Qu.:0.00483 ## Median :0.03644 ## Mean :0.12016 ## 3rd Qu.:0.20796 ## Max. :0.80442 ## NA&#39;s :179 dt_train$pred_rf1 &lt;- rf1.prediction$`predict(rf1, newdata = dt_train)` head(dt_train,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1 1 1 &lt;NA&gt; 2 1 50 34.940 1 NA ## 2 2 2 2 1 1 28 10.892 1 3.739339e-01 ## 3 2 1 2 2 1 5 0.330 0 6.700844e-05 tail(dt_train,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1335 2 2 2 2 1 26 0.161 0 0.0007159829 ## 1338 2 2 1 2 1 39 0.099 0 0.0080326490 ## 1340 2 2 2 2 1 30 0.688 0 0.0011077024 summary(dt_train) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:471 1 :406 1 :439 1 : 77 1 :885 Min. : 0.00 ## 2:467 2 :523 2 :455 2 :833 2 : 17 1st Qu.:20.00 ## NA&#39;s: 9 3 : 10 NA&#39;s: 28 NA&#39;s: 36 Median :32.00 ## 4 : 25 Mean :33.06 ## NA&#39;s: 9 3rd Qu.:43.00 ## Max. :95.00 ## NA&#39;s :134 ## LOSS Y pred_rf1 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 ## 1st Qu.: 0.7123 1st Qu.:0.0000 1st Qu.:0.00483 ## Median : 2.3645 Median :0.0000 Median :0.03644 ## Mean : 5.4656 Mean :0.1141 Mean :0.12016 ## 3rd Qu.: 4.0263 3rd Qu.:0.0000 3rd Qu.:0.20796 ## Max. :273.6040 Max. :1.0000 Max. :0.80442 ## NA&#39;s :179 plot(density(dt_train$pred_rf1[!is.na(dt_train$pred_rf1)]), col=&quot;red&quot; , xlab=&quot;Probabilidad&quot; , main=&quot;Función de densidad estimada&quot;) Vemos que hay (claramente) dos concentraciones (clases) de probabilidades de pérdida, una concentración en torno a la probabilidad de pérdida no severa (\\(Y=0\\)) y otra para la pérdida severa (\\(Y=1\\)). Esto no lleva a la elección del punto de corte óptimo para obtener una regla de clasificación, es decir, un criterio para \\(Y_{predicted}=1\\) (pérdida severa), o bien, para \\(Y_{predicted}=0\\) (pérdida no severa). Una alternativa es el criterio de la Distancia de Kolmogorov-Smirnov (KS). Métricas de evaluación del poder de clasificación if (!require(ModelMetrics)) install.packages(&#39;ModelMetrics&#39;) library(ModelMetrics) if (!require(ROCR)) install.packages(&#39;ROCR&#39;) library(ROCR) if (!require(binaryLogic)) install.packages(&#39;binaryLogic&#39;) library(binaryLogic) Con el train creamos un objeto de tipo ‘prediction’12 rf1.pred &lt;- prediction(as.numeric(rf1$predicted),as.numeric(rf1$y)) Calculamos la Curva de ROC con la función ‘performance’ sobre el objeto ‘rf1’ rf1.perf &lt;- performance(rf1.pred,&quot;tpr&quot;,&quot;fpr&quot;) ## &quot;fpr&quot; = False positive rate. P(Yhat = + | Y = -). Estimated as: FP/N. ## &quot;tpr&quot; = True positive rate. P(Yhat = + | Y = +). Estimated as: TP/P. plot(rf1.perf) Elección del punto de corte: Criterio de la distancia de KS La distancia KS se calcula como: KS = abs(rf1.perf@y.values[[1]]-rf1.perf@x.values[[1]]) rf1.perf@alpha.values[[1]][rf1.perf@alpha.values[[1]]==Inf] &lt;- round(max(rf1.perf@alpha.values[[1]][rf1.perf@alpha.values[[1]]!=Inf]),2) KS.matrix= cbind(abs(rf1.perf@y.values[[1]]-rf1.perf@x.values[[1]]), rf1.perf@alpha.values[[1]]) Resumiendo colnames(KS.matrix) &lt;- c(&quot;KS-distance&quot;,&quot;cut-point&quot;) head(KS.matrix) ## KS-distance cut-point ## [1,] 0.000000000 0.7800000 ## [2,] 0.001497006 0.7826242 ## [3,] 0.002994012 0.7452204 ## [4,] 0.007994999 0.6750160 ## [5,] 0.006497993 0.6717595 ## [6,] 0.005000987 0.6529603 ind.ks &lt;- sort( KS.matrix[,1] , index.return=TRUE )$ix[nrow(KS.matrix)] El punto de corte óptimo de KS: rf1.KScutoff &lt;- KS.matrix[ind.ks,2] # := f(rf1.KS1) rf1.KScutoff ## cut-point ## 0.05177067 # 0.04 - 0.05 Gráfico de la Curva ROC y su métrica: Área bajo la curva ROC (AUC) Cálculo de AUC mediante la función ‘performance’ rf1.auc1 &lt;- performance(rf1.pred,&quot;auc&quot;)@y.values[[1]] rf1.auc1 FALSE [1] 0.7368889 -Cálculo de la curva ROC junto con la métrica AUC #win.graph() plot( rf1.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot;, xlab=&quot;Tasa de falsos positivos&quot; , ylab=&quot;Tasa de verdaderos positivos&quot;, main=&quot;Curva ROC con Random Forest&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4, 0.15 , c(paste0(&quot;AUC (Random Forest)=&quot;,round(rf1.auc1,4)),&quot;AUC (clasificacion al azar)=0.50&quot;),lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) Se realizar el mismo gráfico de la curva ROC utilizando la librería ggplot2. Para ello guardamos los datos en un data.frame library(&quot;ggplot2&quot;) df.perf &lt;- data.frame(x=rf1.perf@x.values[[1]],y=rf1.perf@y.values[[1]]) Construcción del objeto gráfico con ggplot2 #win.graph() p &lt;- ggplot(df.perf,aes(x=x,y=y)) + geom_path(size=1, colour=&quot;red&quot;) p &lt;- p + ggtitle(&quot;Curva ROC modelo Random Forest&quot;) p &lt;- p + theme_update(plot.title = element_text(hjust = 0.5)) p &lt;- p + geom_segment(aes(x=0,y=0,xend=1,yend=1),colour=&quot;blue&quot;,linetype= 2) p &lt;- p + geom_text(aes(x=0.75 , y=0.3 , label=paste(sep =&quot;&quot;,&quot;AUC (Random Forest) ) = &quot;,round(rf1.auc1,4) )),colour=&quot;black&quot;,size=4) p &lt;- p + geom_text(aes(x=0.75 , y=0.25 , label=paste(sep =&quot;&quot;,&quot;AUC (Coin toss) = &quot;,round(0.50,4) )),colour=&quot;black&quot;,size=4) p &lt;- p + scale_x_continuous(name= &quot;Tasa de falsos positivos&quot;) p &lt;- p + scale_y_continuous(name= &quot;Tasa de verdaderos positivos&quot;) p &lt;- p + theme( plot.title = element_text(size = 2), axis.text.x = element_text(size = 10), axis.text.y = element_text(size = 10), axis.title.x = element_text(size = 12,face = &quot;italic&quot;), axis.title.y = element_text(size = 12,face = &quot;italic&quot;,angle=90), legend.title = element_blank(), panel.background = element_rect(fill = &quot;grey&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(colour=&#39;white&#39;), plot.background = element_blank() ) p Métricas de evaluación del poder predictivo Calculamos la predicción en el test y evaluamos el poder de clasificación del modelo rf1.pred_test &lt;- as.data.frame(predict( rf1, newdata = dt_test)) dt_test$pred_rf1 &lt;- rf1.pred_test$`predict(rf1, newdata = dt_test)` head(dt_test,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.2483812 ## 12 1 1 1 2 1 42 29.620 1 0.2207249 ## 18 1 1 1 2 1 58 0.758 0 0.1995112 tail(dt_test,3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.431751239 ## 1339 1 2 2 1 1 18 3.277 0 0.003433201 summary(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## 4 : 10 Mean :31.31 ## NA&#39;s: 7 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00615 ## Median : 2.1645 Median :0.0000 Median :0.03819 ## Mean : 7.0917 Mean :0.1144 Mean :0.12815 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.22274 ## Max. :1067.6970 Max. :1.0000 Max. :0.78703 ## NA&#39;s :70 Con el test creamos un objeto de tipo ‘prediction’ y calculamos la curva ROC dt_test.pred &lt;- prediction(as.numeric(rf1.pred_test$`predict(rf1, newdata = dt_test)`),dt_test$Y) dt_test.perf &lt;- performance(dt_test.pred,&quot;tpr&quot;,&quot;fpr&quot;) Evaluación del poder de clasificación del modelo RF1 vía curva ROC rf1.test.auc &lt;- performance(dt_test.pred ,&quot;auc&quot;)@y.values[[1]] Gráfico de la curva ROC para el test #win.graph() plot( dt_test.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot; , main=&quot;Curva ROC modelo RF - test&quot;,xlab=&quot;Tasa de falsos positivos&quot;, ylab=&quot;Tasa de verdaderos positivos&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4, 0.2 , c(paste0(&quot;AUC (Random Forest)=&quot;,round(rf1.test.auc,4)),&quot;AUC (Coin toss)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) Métrica de error del clasificador RF: Error tipo I (\\(\\alpha\\)): 22.50%, indica el error que se comete clasificando una pérdida ‘severa’ como ‘no severa’ Error tipo II (\\(\\beta\\)): 43.15%, indica el error que se comete clasificando una pérdida ‘no severa’ como ‘severa’ % mala clasificación (\\(%mc\\)) : 40.66%, indica el % de veces que el modelo clasifica incorrectamente las pérdidas Accuracy = \\(100 - %\\): 59.34%, indica el % de veces que el modelo acierta clasificando las pérdidas Area bajo la curva ROC \\(AUC\\): 0.6988, medida global del poder de clasificación del modelo Finalmente calculamos la curva ROC junto con la métrica AUC Resumiendo: Una función útil para obtener rápidamente el análisis de un clasificador binario es la siguiente: metricBinaryClass = function( fitted.model , dataset , cutpoint=NULL , roc.graph=TRUE){ # fitted.model : The Binary Classification model that is under evaluation. If provided, dataset contains all variables in the fitted model (target and predictors). # dataset : If fitted.model is not provided, dataset should has only two columns, predictions and labels. # cuttpoint : potimal cutoff or cutpoint to be used to split continuous predictions into two response categories of target variable # roc.graph : If true, ROC curve graph for the model is shown #install.packages(&quot;binaryLogic&quot;) library(binaryLogic) if( missing(fitted.model) | is.null(fitted.model) ){ tabl &lt;- as.data.frame(dataset) } else { if( class(fitted.model)[1] %in% c(&#39;glm&#39;,&#39;lm&#39;,&#39;randomForest.formula&#39;,&#39;randomForest&#39;) ){ tabl.pred &lt;- as.data.frame(predict( fitted.model, newdata = dataset )) tabl &lt;- as.data.frame(cbind(tabl.pred[[1]], dataset[,&#39;Y&#39;] )) tabl &lt;- tabl[!is.na(tabl[[1]]),] } if( class(fitted.model)[1] %in% c(&quot;gbm&quot;) ){ tabl.pred &lt;- as.data.frame(predict.gbm( fitted.model , newdata = dataset , n.trees = 5000 , type=&quot;response&quot; )) tabl &lt;- as.data.frame(cbind(tabl.pred[[1]], dataset[,&#39;Y&#39;] )) tabl &lt;- tabl[!is.na(tabl[[1]]),] } if( class(fitted.model)[1] %in% c(&#39;svm.formula&#39;,&#39;svm&#39;) ){ tabl.pred &lt;- as.data.frame(predict( fitted.model, newdata = dataset )) ids_NAs &lt;- na.index(dataset) tabl &lt;- as.data.frame( cbind(tabl.pred[[1]], dataset[-ids_NAs,&#39;Y&#39;]) ) tabl &lt;- tabl[!is.na(tabl[[1]]),] } } colnames(tabl) &lt;- c(&#39;predicted&#39;,&#39;actual&#39;) # ROCR objects require(ROCR) obj.pred &lt;- prediction(tabl$predicted,tabl$actual) obj.perf &lt;- performance(obj.pred,&quot;tpr&quot;,&quot;fpr&quot;) obj.auc &lt;- performance(obj.pred,&quot;auc&quot;)@y.values[[1]] # For ROC curve: obj.perf@alpha.values[[1]][obj.perf@alpha.values[[1]]==Inf] &lt;- max(obj.perf@alpha.values[[1]][obj.perf@alpha.values[[1]]!=Inf]) # KS criteria KS.matrix= cbind(abs(obj.perf@y.values[[1]]-obj.perf@x.values[[1]]), obj.perf@alpha.values[[1]]) # KS cutoff # colnames(KS.matrix) &lt;- c(&quot;KS-distance&quot;,&quot;cut-point&quot;) ind.ks &lt;- sort( KS.matrix[,1] , index.return=TRUE )$ix[nrow(KS.matrix)] if( missing(cutpoint) | is.null(cutpoint) ) cutpoint &lt;- KS.matrix[ind.ks,2] if( !(is.binary(tabl)) ){ # Make predictions objs. # Binary metrics tp = sum( tabl$predicted &gt; cutpoint &amp; tabl$actual &gt; cutpoint) fp = sum( tabl$predicted &gt; cutpoint &amp; tabl$actual &lt;= cutpoint) tn = sum( tabl$predicted &lt;= cutpoint &amp; tabl$actual &lt;= cutpoint) fn = sum( tabl$predicted &lt;= cutpoint &amp; tabl$actual &gt; cutpoint) pos = tp+fn neg = tn+fp acc= 100*(tp+tn)/(pos+neg) prec= 100*tp/(tp+fp) sens= 100*tp/(tp+fn) # = tpr = recall = 1 - error alpha spec= 100*tn/(tn+fp) # 1- error beta fpr = 100*fp/neg # error beta (tipo II) = 1 - spec fnr = 100*fn/pos # error alpha (tipo I) = 1- recall = 1- sens } if( is.binary(tabl) ){ tp = sum( tabl$predicted == 1 &amp; tabl$actual == 1) fp = sum( tabl$predicted == 1 &amp; tabl$actual == 0) tn = sum( tabl$predicted == 0 &amp; tabl$actual == 0) fn = sum( tabl$predicted == 0 &amp; tabl$actual == 1) pos = tp+fn neg = tn+fp acc= 100*(tp+tn)/(pos+neg) prec= 100*tp/(tp+fp) sens= 100*tp/(tp+fn) # = tpr = recall = 1 - error alpha spec= 100*tn/(tn+fp) # 1- error beta fpr = 100*fp/neg # error beta (tipo II) = 1 - spec fnr = 100*fn/pos # error alpha (tipo I) = 1- recall = 1- sens } if(roc.graph==TRUE){ win.graph() plot( obj.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot;,xlab=&quot;Tasa de falsos positivos&quot; , ylab=&quot;Tasa de verdaderos positivos&quot;, main=&quot;Curva ROC modelo clasificación&quot;) abline( 0.0 , 1.0 , col=&quot;blue&quot;, lwd=2, lty=2) abline( 0.0 , 0.0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.45, 0.2 , c(paste0(&quot;AUC (Model)=&quot;,round(obj.auc,4)),&quot;AUC (Rolling dice)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) } list(ClassError.tI=round(fnr,2), ClassError.tII=round(fpr,2), Accuracy=round(acc,2),Sensitivity = round(sens,2) , Specificity= round(spec,2), auc= obj.auc , Fisher.F1=round(2*prec*sens/(prec+sens),4) ) } metricBinaryClass( fitted.model = rf1 , dataset= dt_test , cutpoint=rf1.KScutoff , roc.graph=TRUE) ## $ClassError.tI ## [1] 22.5 ## ## $ClassError.tII ## [1] 44.52 ## ## $Accuracy ## [1] 58.13 ## ## $Sensitivity ## [1] 77.5 ## ## $Specificity ## [1] 55.48 ## ## $auc ## [1] 0.698887 ## ## $Fisher.F1 ## [1] 30.8458 4.6.3 Regresión Vamos a construir un modelo para prever las pérdidas. Modelo con Random Forest en train fmla.rf2 &lt;- as.formula(paste0(&#39;LOSS&#39;,&#39;~&#39;,paste0(colnames(df_autobi[,-c(7,8)]),collapse = &quot;+&quot;),collapse = &#39;&#39;)) set.seed(112233) #recomendado rf2 &lt;- randomForest( fmla.rf2, data =dt_train, ntree = 5000, replace =TRUE, mtry=4, maxnodes =50, importance = TRUE, na.action=na.omit) summary(rf2) ## Length Class Mode ## call 9 -none- call ## type 1 -none- character ## predicted 759 -none- numeric ## mse 5000 -none- numeric ## rsq 5000 -none- numeric ## oob.times 759 -none- numeric ## importance 12 -none- numeric ## importanceSD 6 -none- numeric ## localImportance 0 -none- NULL ## proximity 0 -none- NULL ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## forest 11 -none- list ## coefs 0 -none- NULL ## y 759 -none- numeric ## test 0 -none- NULL ## inbag 0 -none- NULL ## terms 3 terms call ## na.action 179 omit numeric str(rf2) ## List of 19 ## $ call : language randomForest(formula = fmla.rf2, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, imp| __truncated__ ## $ type : chr &quot;regression&quot; ## $ predicted : atomic [1:759] 2.481 0.673 37.787 1.805 4.297 ... ## ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ mse : num [1:5000] 543 499 466 463 501 ... ## $ rsq : num [1:5000] -0.636 -0.504 -0.403 -0.395 -0.511 ... ## $ oob.times : int [1:759] 1830 1844 1839 1796 1845 1867 1829 1890 1824 1844 ... ## $ importance : num [1:6, 1:2] 18.05 2.03 -3.02 4.07 6.17 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..$ : chr [1:2] &quot;%IncMSE&quot; &quot;IncNodePurity&quot; ## $ importanceSD : Named num [1:6] 1.161 1.077 1.206 0.401 0.755 ... ## ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## $ localImportance: NULL ## $ proximity : NULL ## $ ntree : num 5000 ## $ mtry : num 4 ## $ forest :List of 11 ## ..$ ndbigtree : int [1:5000] 99 99 99 99 99 99 99 99 99 99 ... ## ..$ nodestatus : int [1:99, 1:5000] -3 -3 -3 -3 -3 -3 -3 -3 -1 -3 ... ## ..$ leftDaughter : int [1:99, 1:5000] 2 4 6 8 10 12 14 16 0 18 ... ## ..$ rightDaughter: int [1:99, 1:5000] 3 5 7 9 11 13 15 17 0 19 ... ## ..$ nodepred : num [1:99, 1:5000] 4.96 2.43 6.21 3.78 1.25 ... ## ..$ bestvar : int [1:99, 1:5000] 6 1 1 5 6 5 6 6 0 6 ... ## ..$ xbestsplit : num [1:99, 1:5000] 24.5 1.5 1.5 1.5 20.5 1.5 52.5 15.5 0 13.5 ... ## ..$ ncat : Named int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## ..$ nrnodes : int 99 ## ..$ ntree : num 5000 ## ..$ xlevels :List of 6 ## .. ..$ ATTORNEY: num 0 ## .. ..$ CLMSEX : num 0 ## .. ..$ MARITAL : num 0 ## .. ..$ CLMINSUR: num 0 ## .. ..$ SEATBELT: num 0 ## .. ..$ CLMAGE : num 0 ## $ coefs : NULL ## $ y : atomic [1:759] 10.892 0.33 11.037 0.138 3.538 ... ## ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ test : NULL ## $ inbag : NULL ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language LOSS ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + SEATBELT + CLMAGE ## .. ..- attr(*, &quot;variables&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;factors&quot;)= int [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ... ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:7] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## .. .. .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;term.labels&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;order&quot;)= int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;intercept&quot;)= num 0 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:7] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## $ na.action :Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;randomForest.formula&quot; &quot;randomForest&quot; Importancia Relativa de las Variables Input varImpPlot(rf2,sort = T,main=&quot;Variable Importance&quot;) Previsión en test rf2.prediction &lt;- as.data.frame(predict(rf2, newdata = dt_test)) dt_test$pred_rf2 &lt;- rf2.prediction[[1]] head(dt_test, 3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.2483812 ## 12 1 1 1 2 1 42 29.620 1 0.2207249 ## 18 1 1 1 2 1 58 0.758 0 0.1995112 ## pred_rf2 ## 6 7.914495 ## 12 8.488978 ## 18 9.846624 tail(dt_test, 3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.431751239 ## 1339 1 2 2 1 1 18 3.277 0 0.003433201 ## pred_rf2 ## 1336 NA ## 1337 36.665696 ## 1339 3.978978 summary(dt_test, 3) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 2 :195 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 (Other):200 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 NA&#39;s : 7 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## Mean :31.31 ## 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 pred_rf2 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 Min. : 0.3916 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00615 1st Qu.: 2.0644 ## Median : 2.1645 Median :0.0000 Median :0.03819 Median : 3.4303 ## Mean : 7.0917 Mean :0.1144 Mean :0.12815 Mean : 6.3906 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.22274 3rd Qu.: 7.8241 ## Max. :1067.6970 Max. :1.0000 Max. :0.78703 Max. :57.5121 ## NA&#39;s :70 NA&#39;s :70 Graficamos la distribución de los valores estimados en el train plot(density(dt_test$pred_rf2[!is.na(dt_test$pred_rf2) &amp; dt_test$pred_rf2 &lt; 30]), ylim= c(0,.25) , col=&quot;red&quot; , main=&quot;&quot;) lines(density(dt_test$LOSS[dt_test$LOSS&lt;30]),col=&quot;blue&quot;,lty=1) modelchecktest1 &lt;- as.data.frame( cbind(real=dt_test$LOSS , predicted=dt_test$pred_rf2) ) modelchecktest1[is.na(modelchecktest1)] &lt;- 0 summary(modelchecktest1) ## real predicted ## Min. : 0.0050 Min. : 0.000 ## 1st Qu.: 0.5175 1st Qu.: 1.316 ## Median : 2.1645 Median : 2.414 ## Mean : 7.0917 Mean : 5.278 ## 3rd Qu.: 3.7782 3rd Qu.: 7.424 ## Max. :1067.6970 Max. :57.512 Error de ajuste del modelo plot(modelchecktest1, xlim=c(0,100) , ylim=c(0,100) , pch=&quot;.&quot; , cex=1.5) segments( 0, 0 , 100, 100 , col=&quot;red&quot;) Resumiendo Una función útil para medir el error: modelMetrics(real=modelchecktest1$real, pred=modelchecktest1$predicted ) ## Accuracy metrics (global): ## MAE(ref) = 8.9208 ## MAE = 7.7751 ## RMSE = 54.5763 ## MAPE = 127.55 ## MAPE(sim) = 68.64 ## WMAPE = 109.64 Commentario: El error de ajuste del modelo de regresión es demasiado alto: \\(RMSE= 54.57\\) y el \\(MAPE=127.19%\\) Con estos errores de predicción, es preferible utilizar a un modelo de clasificación en lugar de un modelo de regresión. Ejercicio sugerido Ajustar un Modelo de Regresión Logística para \\(Y\\) y comparar los resultados con los proporcionados por el Random Forest Ajustar un Modelo de Regresión Lineal para \\(LOSS\\) y comparar los resultados con los proporcionados por el Random Forest Si queremos cambiar la ruta, podemos hacer ‘myWd &lt;- setwd(“Ruta y Nombre de la carpeta”)’.↩ https://CRAN.R-project.org/package=insuranceData↩ https://www.rdocumentation.org/packages/insuranceData/versions/1.0/topics/AutoBi↩ A loss is the injury or damage sustained by the insured in consequence of the happening of one or more of the accidents or misfortunes against which the insurer, in consideration of the premium, has undertaken to indemnify the insured.↩ The interquartile range of an observation variable is the difference of its upper and lower quartiles. It is a measure of how far apart the middle portion of data spreads in value↩ https://www.rdocumentation.org/packages/randomForest/versions/4.6-12/topics/randomForest↩ https://www.r-bloggers.com/a-small-introduction-to-the-rocr-package/↩ "],
["modelos-de-regresion-lineal.html", "Capítulo 5 Modelos de regresión lineal ", " Capítulo 5 Modelos de regresión lineal "],
["modelo.html", "5.1 Modelo", " 5.1 Modelo El modelo de regresión se utiliza para representar una relación de dependencia entre: Una variable \\(Y\\) denominada variable respuesta o dependiente: que depende de otras y que tratamos de explicar/predecir. Otras variables \\(X_1, X_2, \\ldots, X_K\\) denominadas variables explicativas o independientes que permiten explicarla/predecirla. Una regresión es lineal, cuando la función \\(f(x)\\) que relaciona \\(X\\) e \\(Y\\) es una función lineal ( \\(Y = f(x)\\) ). Teniendo \\(K\\) variables explicativas, la regresión lineal se plantea de la siguiente manera: \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_K X_K + \\epsilon \\] De manera que el valor de la predicción de la variable \\(Y\\) será: \\[ \\widehat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_K X_K \\] O lo que es lo mismo: \\[ \\widehat{Y} = Y - \\epsilon \\] Así, \\(\\epsilon\\) será el error cometido. En función del número \\(K\\) de variables explicativas que tengamos, la regresión lineal puede ser: Simple si hay una única variable independiente (\\(K = 1\\)). Múltiple si hay varias variables independendientes (\\(K &gt; 1\\)). "],
["aplicacion-en-r.html", "5.2 Aplicación en R", " 5.2 Aplicación en R 5.2.1 Regresión lineal simple Para realizarla usaremos la base de datos Boston de la librer?a MASS. library(MASS) Veamos la descripción de Boston en la ayuda de R: ?Boston ## starting httpd help server ... done Observamos que es un data.frame con 506 observaciones y 14 variables. Podemos explorar un poco más los datos usando las funciones head, tail y summary. head(Boston,5) ## crim zn indus chas nox rm age dis rad tax ptratio black ## 1 0.00632 18 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 ## 2 0.02731 0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 ## 3 0.02729 0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 ## 4 0.03237 0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 ## 5 0.06905 0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 ## lstat medv ## 1 4.98 24.0 ## 2 9.14 21.6 ## 3 4.03 34.7 ## 4 2.94 33.4 ## 5 5.33 36.2 tail(Boston,5) ## crim zn indus chas nox rm age dis rad tax ptratio black ## 502 0.06263 0 11.93 0 0.573 6.593 69.1 2.4786 1 273 21 391.99 ## 503 0.04527 0 11.93 0 0.573 6.120 76.7 2.2875 1 273 21 396.90 ## 504 0.06076 0 11.93 0 0.573 6.976 91.0 2.1675 1 273 21 396.90 ## 505 0.10959 0 11.93 0 0.573 6.794 89.3 2.3889 1 273 21 393.45 ## 506 0.04741 0 11.93 0 0.573 6.030 80.8 2.5050 1 273 21 396.90 ## lstat medv ## 502 9.67 22.4 ## 503 9.08 20.6 ## 504 5.64 23.9 ## 505 6.48 22.0 ## 506 7.88 11.9 summary(Boston) ## crim zn indus chas ## Min. : 0.00632 Min. : 0.00 Min. : 0.46 Min. :0.00000 ## 1st Qu.: 0.08204 1st Qu.: 0.00 1st Qu.: 5.19 1st Qu.:0.00000 ## Median : 0.25651 Median : 0.00 Median : 9.69 Median :0.00000 ## Mean : 3.61352 Mean : 11.36 Mean :11.14 Mean :0.06917 ## 3rd Qu.: 3.67708 3rd Qu.: 12.50 3rd Qu.:18.10 3rd Qu.:0.00000 ## Max. :88.97620 Max. :100.00 Max. :27.74 Max. :1.00000 ## nox rm age dis ## Min. :0.3850 Min. :3.561 Min. : 2.90 Min. : 1.130 ## 1st Qu.:0.4490 1st Qu.:5.886 1st Qu.: 45.02 1st Qu.: 2.100 ## Median :0.5380 Median :6.208 Median : 77.50 Median : 3.207 ## Mean :0.5547 Mean :6.285 Mean : 68.57 Mean : 3.795 ## 3rd Qu.:0.6240 3rd Qu.:6.623 3rd Qu.: 94.08 3rd Qu.: 5.188 ## Max. :0.8710 Max. :8.780 Max. :100.00 Max. :12.127 ## rad tax ptratio black ## Min. : 1.000 Min. :187.0 Min. :12.60 Min. : 0.32 ## 1st Qu.: 4.000 1st Qu.:279.0 1st Qu.:17.40 1st Qu.:375.38 ## Median : 5.000 Median :330.0 Median :19.05 Median :391.44 ## Mean : 9.549 Mean :408.2 Mean :18.46 Mean :356.67 ## 3rd Qu.:24.000 3rd Qu.:666.0 3rd Qu.:20.20 3rd Qu.:396.23 ## Max. :24.000 Max. :711.0 Max. :22.00 Max. :396.90 ## lstat medv ## Min. : 1.73 Min. : 5.00 ## 1st Qu.: 6.95 1st Qu.:17.02 ## Median :11.36 Median :21.20 ## Mean :12.65 Mean :22.53 ## 3rd Qu.:16.95 3rd Qu.:25.00 ## Max. :37.97 Max. :50.00 Antes de continuar, hacemos la división de Boston en trainy test. id_train &lt;- sample(1:nrow(Boston), size = 0.8*nrow(Boston)) train &lt;- Boston[id_train, ] test &lt;- Boston[-id_train, ] Ajustamos el modelo de regresión lineal simple para predecir la variable medv utilizando la variable lstat de nuestro conjunto de datos Boston. Para ello usaremos la función lm. reg_ls &lt;- lm(medv~lstat, data = train) reg_ls ## ## Call: ## lm(formula = medv ~ lstat, data = train) ## ## Coefficients: ## (Intercept) lstat ## 34.2875 -0.9268 Veamos los coeficientes de la regresión reg_ls$coefficients ## (Intercept) lstat ## 34.2874714 -0.9268229 Donde el término independiente es: reg_ls$coefficients[1] ## (Intercept) ## 34.28747 y el coeficiente de la variable lstates: reg_ls$coefficients[2] ## lstat ## -0.9268229 De manera que la recta de regresión lineal, siendo \\(y\\) la variable medv y \\(x\\) la variable lstat, es: ## y = 34.28747 + -0.9268229 x Si queremos obtener los errores residuales de las observaciones correspondientes: residuales &lt;- reg_ls$residuals # Veamos los residuales de las 10 primeras observaciones residuales[1:10] ## 349 443 387 337 214 486 ## -4.2358020 -0.5114789 2.4230812 -5.7046066 2.5061277 -3.2816847 ## 163 245 150 49 ## 17.4920286 -5.1021847 0.9928806 8.6679432 Una vez obtenido el modelo de regresión lineal, para realizar la predicción sobre un nuevo conjunto de datos, utilizamos la función predict, de la siguiente manera: predic &lt;- predict(reg_ls, newdata = test) #Veamos la predicción de las 10 primeras observaciones predic[1:10] ## 7 15 26 27 28 30 32 39 ## 22.76706 24.77827 18.98562 20.56122 18.27197 23.18413 22.20170 24.89876 ## 50 51 ## 19.27294 21.82170 Algunas representaciones gráficas de un modelo de regresión son: Dispersión de los puntos y la recta de regresión lineal simple obtenida: regresion &lt;- lm(medv~lstat, data = Boston) plot(Boston$lstat, Boston$medv, xlab = &quot;lstat&quot;, ylab = &quot;medv&quot;) abline(regresion, col=&#39;red&#39;, lwd=2) a &lt;- regresion$coefficients[[1]] b &lt;- regresion$coefficients[[2]] text(30,40,labels = paste(&#39;Y = &#39;, round(b,2),&#39;x +&#39;, round(a,2)), col=&#39;red&#39;) Análisis de residuos: par(mfrow=c(2,2)) plot(regresion) 5.2.2 Regresión lineal múltiple Utilizamos lo mismo que hemos hecho para la regresión lineal simple, con la diferencia de que ahora hay más de una variable independiente. Usamos la misma función, lm, y la sucesión de variables independientes estarán separadas con un +, es decir: reg_lm &lt;- lm(medv~lstat + age, data = train) reg_lm ## ## Call: ## lm(formula = medv ~ lstat + age, data = train) ## ## Coefficients: ## (Intercept) lstat age ## 33.69348 -0.96469 0.01568 Veamos los coeficientes de la regresión reg_lm$coefficients ## (Intercept) lstat age ## 33.69348204 -0.96469460 0.01568217 Donde el término independiente es: reg_lm$coefficients[1] ## (Intercept) ## 33.69348 el coeficiente de la variable lstat es: reg_lm$coefficients[2] ## lstat ## -0.9646946 y el coeficiente de la variable age es: reg_lm$coefficients[3] ## age ## 0.01568217 De manera que la recta de regresión lineal, siendo \\(y\\) la variable medv, \\(x1\\) la variable lstat y \\(x2\\) la variable age, será: ## y = 33.69348 + -0.9646946 x1 + 0.01568217 x2 Veamos los gráficos de dispersión 2 a 2: pairs(Boston[,c(&#39;medv&#39;,&#39;lstat&#39;, &#39;age&#39;)],panel = panel.smooth) Análogamente a como hemos hecho con la regresión lineal, podemos obtener los residuos y utilizar la función predict en un nuevo conjunto de datos. Hay otras opciones de poner la variables independientes. Por ejemplo, si quisieramos usar todas las variables, como conjunto de variables independientes, bastaría con escribir: reg_lm2 &lt;- lm(medv~., data = train) reg_lm2 ## ## Call: ## lm(formula = medv ~ ., data = train) ## ## Coefficients: ## (Intercept) crim zn indus chas ## 36.337595 -0.105233 0.042602 0.015315 2.192578 ## nox rm age dis rad ## -17.448708 3.832991 -0.006219 -1.428698 0.288890 ## tax ptratio black lstat ## -0.013475 -0.945061 0.009244 -0.468843 Por otro lado, si quisieramos usarlas todas excepto alguna, podemos escribir: reg_lm3 &lt;- lm(medv~.-age, data = train) reg_lm3 ## ## Call: ## lm(formula = medv ~ . - age, data = train) ## ## Coefficients: ## (Intercept) crim zn indus chas ## 36.536731 -0.105615 0.043488 0.014328 2.171203 ## nox rm dis rad tax ## -17.915132 3.791779 -1.405441 0.291971 -0.013557 ## ptratio black lstat ## -0.947918 0.009174 -0.477268 "],
["modelos-de-respuesta-0-1.html", "Capítulo 6 Modelos de Respuesta 0-1 ", " Capítulo 6 Modelos de Respuesta 0-1 "],
["motivacion.html", "6.1 Motivación", " 6.1 Motivación Un modelo de churn es una herramienta que permite evaluar la probabilidad de baja o fuga de un cliente en función de sus características propias y del tipo de relación que tiene con la empresa. La variable que se analiza toma valor 1 ó 0. Para representar la relación entre esa variable binaria (output) y las variables explicativas (inputs), se utilizan modelos de tipo logit o probit. "],
["modelos-lineales-generalizados.html", "6.2 Modelos Lineales Generalizados", " 6.2 Modelos Lineales Generalizados Los Modelos Lineales Generalizados son una extensión de los modelos lineales clásicos. Un modelo lineal se basa en un vector de observaciones \\(\\mathbf{Y}\\) con \\(n\\) componentes, que son una realización de una variable aleatoria \\(\\mathbf{Y}\\) cuyas componentes están independientemente distribuidas con media \\(\\mu\\). Un modelo lineal puede ser descrito como: \\[\\mathbf{Y} = \\mathbf{\\mu} + \\mathbf{\\epsilon}\\] La parte sistemática de un modelo es una especificación para \\(\\mu\\) en función de un número pequeño de parámetros, \\(\\beta_1, \\ldots, \\beta_p.\\) Esa especificación se hace de la siguiente manera: \\[ \\mu_i = \\sum_{j=1}^p X_{ij}\\beta_j; i=1,\\ldots,n. \\] O en forma matricial, \\[ E(\\mathbf{Y}) = \\mathbf{\\mu} = \\mathbf{x} \\mathbf{\\beta} \\] donde \\(\\mathbf{X}\\) es una matriz \\(n \\times p\\), con las covariables o regresoras del modelo. Para la parte aleatoria se supone independencia y varianza constante de los errores. En un modelo lineal clásico, se tiene que: \\[ \\mathbf{\\epsilon} \\sim N(0, \\sigma^2 \\mathbf{I}) \\] Por tanto un modelo lineal clásico puede ser resumido de la forma: \\[ \\begin{align} \\mathbf{Y} &amp; \\sim N(\\mathbf{\\mu}, \\sigma^2 \\mathbf{I}) \\\\ E(\\mathbf{Y}) &amp; = \\mathbf{X}\\mathbf{\\beta} \\\\ Var(\\mathbf{Y}) &amp; = \\sigma^2\\mathbf{I} \\end{align} \\] La generalización de los modelos lineales incluye una especificación de tres aspectos principales: Las componentes de \\(\\mathbf{Y}\\) tienen distribución normal con varianza constante y son independientes. En la parte sistemática, las covariables, \\(x_1, x_2, ..., x_p\\), producen un predictor lineal \\(\\eta\\), dado por: \\[ \\eta= \\sum_{j=1}^p X_{ij}\\beta_j \\] La relación entre los componentes sistemáticos y aleatorios se hace a través de una función de manera que: \\[\\mathbf{\\mu}=\\mathbf{\\eta}\\] Los Modelos Lineales Generalizados o MLGs permiten dos extensiones. La primera extensión está en la función de enlace, que es la parte del modelo que determina la relación entre la media de la variable respuesta y las covariables. Esta función de enlace, ahora, podrá ser cualquier función monótona diferenciable y generalmente denotada por \\(g(\\mu)\\). La segunda extensión reside en la distribución especificada para la componente aleatoria. En los MLGs esta puede ser de la familia exponencial, de la cual la distribución normal forma parte. Se supone que si \\(\\mathbf{Y}\\) tiene una distribución de la familia exponencial para unos específicos \\(a(\\cdot), b(\\cdot)\\) y \\(c(\\cdot)\\) se asume la siguiente forma: \\[ f_Y ( \\mathbf{Y} | \\eta,\\phi) = \\exp \\left\\{ \\dfrac{\\mathbf{\\eta} - b(\\eta)}{a(\\phi)} + c(\\mathbf{Y},\\phi) \\right\\} \\] El parámetro \\(\\phi\\) es llamado parámetro de dispersión y, si es conocido, llamamos a su familia ``de familia exponencial lineal de parámetro canónico \\(\\theta\\)’’. Utilizando la ecuación anterior y algunas relaciones, se puede obtener expresiones para la media y la varianza de \\(\\mathbf{Y}\\) de la siguiente manera: \\[ \\begin{align} E(\\mathbf{Y}) &amp; = b&#39;(\\eta) \\\\ Var(\\mathbf{Y}) &amp; = a(\\phi)b&#39;&#39;(\\eta) \\end{align} \\] "],
["modelo-logit.html", "6.3 Modelo Logit", " 6.3 Modelo Logit Cuando la variable respuesta es continua, se utilizan métodos de regresión lineales o de otro tipo; en cambio, cuando la variable respuesta es cualitativa se utilizan los modelos llamados Modelos de Regresión Logística. El objetivo de estos modelos es encontrar el mejor ajuste para describir las relaciones entre las variables respuesta (dicotómica o cualitativa) y un grupo de variables explicativas. Esta diferencia (respecto a los modelos con variable respuesta cuantitativa) da lugar a distintos modelos paramétricos y a distintas hipótesis para estos modelos, pero, una vez salvada esta diferencia, los métodos empleados en Regresión Logística siguen los principios generales de los métodos de regresión lineal. La primera razón por la cual un Modelo de Regresión Lineal no es adecuado para este tipo de datos es que la variable respuesta sólo puede tomar 2 valores (0 y 1), de modo que si pretendiésemos elaborar una relación entre una variable explicativa y esta, tendríamos que condicionar la probabilidad de alguno de los valores de la variable respuesta a cada valor de la variable explicativa, es decir \\(E(Y= 1 | X = x_1)\\) y obtendríamos la curva logística: La relación existente no es lineal, sino que puede asociarse con la función de distribución de cierta variable aleatoria. Al utilizar la distribución Logística, representaremos la media de \\(Y\\), dado un valor \\(x\\) de la variable \\(X\\), por \\(\\pi(X)=E(Y/x)\\). El modelo de Regresión Logística es: \\[ \\pi(x) = \\frac{e^{\\beta_0+\\beta_1x}}{1+e^{\\beta_0+\\beta_1x}} \\] Aplicando la transformación Logit: \\[ g(x)=\\ln\\Big[\\frac{\\pi(x)}{1-\\pi(x)}\\Big]= \\beta_0+\\beta_1x \\] Hemos llegado a \\(g(x)\\), que tiene las propiedades que se desea que tenga un Modelo de Regresión Lineal; es lineal en sus parámetros; puede ser continua y su rango está entre \\(-\\infty\\) y \\(\\infty\\) dependiendo del rango de X. Como hemos dicho antes, también tenemos que tener clara la distribución de la parte aleatoria de nuestro modelo. En el Modelo Lineal Generalizado suponemos que un valor de la variable dependiente puede expresarse como \\(y=E(Y/x)+\\epsilon.\\) Donde \\(\\epsilon\\sim N(0,\\sigma^2)\\), con varianza constante para los distintos niveles de la variable independiente. Pero esto no ocurre así en el caso de una variable dicotómica. Si expresamos nuestro modelo como \\(Y = \\pi(x) + \\epsilon,\\) \\(\\epsilon\\) toma dos posibles valores: Si \\(Y=1,\\) con probabilidad \\(\\pi(x)\\), $= 1-(x) $, con probabilidad \\(\\pi(x)\\). Si \\(y=0, \\epsilon = -\\pi(x)\\), con probabilidad \\(1-\\pi(x)\\). Por tanto: \\[ E(\\epsilon)= (1-\\pi(x))\\pi(x)-\\pi(x)(1-\\pi(x))=0 \\] \\[ V(\\epsilon) = (1-\\pi(x))^2\\pi(x)-\\pi(x))^2(1-\\pi(x))=\\pi(x)(1-\\pi(x)) \\] La distribución de la variable dependiente \\(Y\\), dado un valor de \\(x\\) de la variable \\(X\\), sigue una distribución Binomial con probabilidad \\(\\pi(x)\\). "],
["modelo-probit.html", "6.4 Modelo Probit", " 6.4 Modelo Probit La relación existente entre \\(E(Y= 1/X=x_1)\\) y \\(X\\), que como dicho anteriormente no es linea, se asocia también con la curva de distribución normal.Este enfoque utiliza la inversa de la función de distribución normal para obtener una relación lineal entre \\(E(Y= 1/X=x_1)\\) y \\(X\\). Y una vez hayamos tenido los valores en forma de relación lineal del tipo \\(g(x) = B_0+B_1x_1\\) volveremos a transformarlo en una curva que se asemeje a una distribución aleatoria de la siguiente manera: \\[ E(Y=1/X) = \\int_{-\\infty}^{B_0+B_1 x_1}\\frac{1}{\\sqrt{2\\pi}}e^{\\frac{-z^2}{2}} \\] Así estimando los valores de \\(B_0\\) y \\(B_1\\), siguiendo el proceso anteriormente mencionado, obtendremos estimaciones de las probabilidades de un determinado valor de la variable respuesta \\((Y)\\) condicionada a unos determinados valores de las variables explicativas \\((X_1,X_2,...X_n)\\). "],
["modelos-de-regresion-logistica.html", "6.5 Modelos de regresión logística", " 6.5 Modelos de regresión logística Como ocurría en la regresión lineal, el objetivo es tratar de explicar/predecir el comportamiento de una variable \\(Y\\) en funci?n de otras variables \\(X1, X2, ... , Xk\\). La regresión logística se plantea de la siguiente manera: \\[ Y = \\frac{1}{1 + e^{-\\beta_0 - \\beta_1 X_1 - ... -\\beta_K X_K + \\epsilon}} \\] Los valores que devuelven se mueven en el rango \\([0,1]\\) En general, permite establecer una relación de dependencia entre una variable categórica \\(Y\\) (no necesariamente binaria) con un conjunto de variables independiente de cualquier tipo. En función de la naturaleza de la variable dependiente se distinguen diferentes tipos de modelos: Regresión Logística Binaria: asociada a un target binario. Es la más utilizada y referenciada. Regresión Logística Ordinal: asociado a un target ordinal. Regresión Logística Nominal: asociada a un target nominal. Al no ser una relación lineal, no es posible interpretar directamente el valor de los parámetros estimados. Para realizar una interpretación de estos se utilizan los denominados ‘ODDS Ratios’. A través de un ratio de ODDS se puede calcular qué influencia genera en el target el incremento de una unidad en el valor de la variable explicativa. Si \\(\\beta_i &gt; 0\\) el efecto de la variable explicativa \\(X_i\\) sobre la respuesta \\(Y\\) es de incremento: aumenta la probabilidad del target. Si \\(\\beta_i &lt; 0\\) el efecto que produce la variable explicativa \\(X_i\\) sobre la respuesta \\(Y\\) es decremento: disminuye la probabilidad del target. "],
["aplicacion-en-r-1.html", "6.6 Aplicación en R", " 6.6 Aplicación en R Para este ejemplo cargamos la librería ISLR y utilizamos el conjunto de datos de Smarket. Veamos información sobre los datos Smarket ?Smarket ## Warning in stats::runif(10): &#39;.Random.seed&#39; is not an integer vector but of ## type &#39;NULL&#39;, so ignored ## starting httpd help server ... done head(Smarket) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down ## 4 2001 -0.623 1.032 0.959 0.381 -0.192 1.2760 0.614 Up ## 5 2001 0.614 -0.623 1.032 0.959 0.381 1.2057 0.213 Up ## 6 2001 0.213 0.614 -0.623 1.032 0.959 1.3491 1.392 Up summary(Smarket) ## Year Lag1 Lag2 ## Min. :2001 Min. :-4.922000 Min. :-4.922000 ## 1st Qu.:2002 1st Qu.:-0.639500 1st Qu.:-0.639500 ## Median :2003 Median : 0.039000 Median : 0.039000 ## Mean :2003 Mean : 0.003834 Mean : 0.003919 ## 3rd Qu.:2004 3rd Qu.: 0.596750 3rd Qu.: 0.596750 ## Max. :2005 Max. : 5.733000 Max. : 5.733000 ## Lag3 Lag4 Lag5 ## Min. :-4.922000 Min. :-4.922000 Min. :-4.92200 ## 1st Qu.:-0.640000 1st Qu.:-0.640000 1st Qu.:-0.64000 ## Median : 0.038500 Median : 0.038500 Median : 0.03850 ## Mean : 0.001716 Mean : 0.001636 Mean : 0.00561 ## 3rd Qu.: 0.596750 3rd Qu.: 0.596750 3rd Qu.: 0.59700 ## Max. : 5.733000 Max. : 5.733000 Max. : 5.73300 ## Volume Today Direction ## Min. :0.3561 Min. :-4.922000 Down:602 ## 1st Qu.:1.2574 1st Qu.:-0.639500 Up :648 ## Median :1.4229 Median : 0.038500 ## Mean :1.4783 Mean : 0.003138 ## 3rd Qu.:1.6417 3rd Qu.: 0.596750 ## Max. :3.1525 Max. : 5.733000 En este caso la variable Y que queremos predecir/explicar es la variable Direction, y las variables independientes son Lag1, Lag2, Lag3, Lag4, Lag5 y Volume. Veamos que valores toma la variable Direction levels(Smarket$Direction) ## [1] &quot;Down&quot; &quot;Up&quot; Vemos que es una variable binaria que toma valores Downo Up. Antes de continuar pasamos esos valores a 0 o 1, respectivamente. Smarket$Direction &lt;- ifelse(Smarket$Direction == &#39;Up&#39;, 1, 0) Para realizar la regresión logística en R utilizaremos la función glm. Se puede observar en el código siguiente, que como nuestro Target es binario, el parámetro family lo debemos fijar a binomial. reg_logis &lt;- glm(Direction~Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial) Veamos que hemos obtenido summary(reg_logis) ## ## Call: ## glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + ## Volume, family = binomial, data = Smarket) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.446 -1.203 1.065 1.145 1.326 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.126000 0.240736 -0.523 0.601 ## Lag1 -0.073074 0.050167 -1.457 0.145 ## Lag2 -0.042301 0.050086 -0.845 0.398 ## Lag3 0.011085 0.049939 0.222 0.824 ## Lag4 0.009359 0.049974 0.187 0.851 ## Lag5 0.010313 0.049511 0.208 0.835 ## Volume 0.135441 0.158360 0.855 0.392 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1731.2 on 1249 degrees of freedom ## Residual deviance: 1727.6 on 1243 degrees of freedom ## AIC: 1741.6 ## ## Number of Fisher Scoring iterations: 3 Los coeficientes de la regresión logística obtenida serán: coef(reg_logis) ## (Intercept) Lag1 Lag2 Lag3 Lag4 ## -0.126000257 -0.073073746 -0.042301344 0.011085108 0.009358938 ## Lag5 Volume ## 0.010313068 0.135440659 Como se hace en los otros modelos, la función predict la utilizaremos para predecir un nuevo conjunto de datos a partir de nuestro modelo de regresión logística ajustado. Para un modelo binomial predeterminado, las predicciones serán de log-odds (probabilidades en la escala logit). Como vemos en el código a continuación, utilizamos el argumento type = response para guardar la predicción de las probabilidades. glm.probs &lt;- predict(reg_logis, type = &quot;response&quot;) Lo que hacemos a continuación es dar a una observación el valor del target \\(1\\) o \\(0\\) en función a la probabilidad obtenida. El corte en la probabilidad en este caso lo ponemos en \\(0.5\\), es decir, si la predicción que se ha obtenido de la probabilidad es menor que 0.5, le damos el valor \\(0\\), y sino el valor \\(1\\). El código que hace esto es de la siguiente manera: glm.pred &lt;- rep(1, nrow(Smarket)) glm.pred[glm.probs &lt; .5] &lt;- 0 Ahora, obtenemos la matriz de confusión, en el que podemos comparar el valor de la predicción obtenida (filas) con el verdadero valor (columnas). De esta manera, lo que está en la diagonal principal será lo que se ha predecido correctamente. table(glm.pred, Smarket$Direction) ## ## glm.pred 0 1 ## 0 145 141 ## 1 457 507 observamos la media de los valores que se ha predecido bien: mean(glm.pred == Smarket$Direction) ## [1] 0.5216 y la media de los que se han predecido mal: mean(glm.pred != Smarket$Direction) ## [1] 0.4784 Podemos ver de manera gráfica como han sido clasificados por nuestro modelo (en función de la probabilidad obtenida) frente a su valor real. nuevo &lt;- data.frame(glm.probs, glm.pred, Smarket$Direction) names(nuevo)[1] &lt;- &quot;probs&quot; names(nuevo)[2] &lt;- &quot;pred&quot; names(nuevo)[3] &lt;- &quot;direction&quot; nuevo$direction &lt;- ifelse(nuevo$direction == 1, &#39;Up&#39;, &#39;Down&#39;) nuevo$pred &lt;- ifelse(nuevo$pred == 1, &#39;Up&#39;, &#39;Down&#39;) library(ggplot2) ggplot(data = nuevo, aes(x = pred, y = probs, col = direction)) + geom_point() + labs(x = &#39;Predicci?n&#39;, y = &#39;Probabilidades&#39;) + ggtitle(&#39;Predicci?n VS Valor real&#39;) + theme(legend.title=element_blank()) + scale_colour_manual(values=c(&quot;blue&quot;, &quot;red&quot;)) "],
["modelos-de-series-temporales-1.html", "Capítulo 7 Modelos de Series Temporales ", " Capítulo 7 Modelos de Series Temporales "],
["series-temporales.html", "7.1 Series Temporales", " 7.1 Series Temporales 7.1.1 ¿Qué es una Serie Temporal? Una serie temporal es una secuencia de datos, medidos a intervalos de tiempo sucesivos regularmente espaciados. Ejemplos de series temporales son: tasas de interés mensuales, cantidad de lluvia anual, tasa de desempleo mensual, PIB anual, ondas cardíacas, etc. Una serie temporal (o simplemente una serie) es una secuencia de N observaciones ordenadas y equidistantes cronológicamente sobre una característica o varias características de una unidad observable en diferentes momentos. Si la serie es sobre una característica se dice que es univariante o escalar. Si la serie es sobre dos o más características se dice que es multivariante o vectorial. El estudio de las series temporales permite: (1) entender mejor el mecanismo de generación de los datos, que puede no ser claro inicialmente en una investigaci?n y/o (2) hacer pronósticos sobre el futuro, es decir: previsiones. Las previsiones se utilizan en forma constante en diversos campos: econom?a, finanzas, marketing, medio ambiente, ingeniería, etc. En general, las previsiones proporcionan una guía para las decisiones que deben tomarse. Algunos ejemplos de uso de las previsiones son: En Planeamiento y Control de Operaciones. Las decisiones de producción de un artículo con base en los pronósticos de ventas. Es posible por ejemplo, detectar una disminución en la tendencia de ventas que conlleve a reducir la producción, o al contrario. En Marketing. La decisión de invertir en publicidad puede depender de prever las ventas. En Economía. Las decisiones del Banco de España, por ejemplo para el control de la inflación, requieren la previsión y el examen del comportamiento de ciertas variables macroeconómicas, como el PIB, la tasa de desempleo, el IPC, las tasas de inter?s a distintos plazos, activas y pasivas. En Turismo. La previsión del de número de turistas mensuales para determinar la demanda hotelera. En Epidemiología y Medio Ambiente. La vigilancia de los niveles de contaminantes en el aire tiene como herramienta fundamental las series de tiempo. Pero adicionalmente el efecto de estos niveles sobre la salud. Todas las series temporales tienen características particulares. Asi por ejemplo, las series pueden: evolucionar alrededor de un nivel constante o tienen tendencias crecientes o decrecientes, evolucionar alrededor de un nivel que cambia sin seguir aparentemente un patrón concreto - tienen tendencia estocástica - presentar reducciones (en invierno) y aumentos (en verano) sistemáticos en su nivel cada 12 meses - son estacionales - presentar variabilidad constante alrededor de su nivel presentar variabilidad condicional o alta volatilidad, moverse conjuntamente con otras series - tendencia común - etc. En las secciones siguiente se describen brevemente algunos conceptos necesarios para la modelación básica de series temporales. "],
["operadores.html", "7.2 Operadores", " 7.2 Operadores 7.2.1 Operador de retardo simple El operador de retardo simple se define como \\[Bz_t=z_{t-1}\\] Si aplicamos el operador de retardo dos veces: \\[BBz_t=Bz_{t-1}=z_{t-2}\\] Del mismo modo, si aplicamos \\(n\\) veces el operador de retardo, obtenemos: \\[ BB \\ldots Bz_t=z_{t-n} \\] Definimos, por tanto \\[ B^n z_t=z_{t-n} \\] 7.2.2 Operador de adelanto simple De modo an?logo, definimos el operador de adelanto simple \\[ \\begin{align} Fz_t&amp;=z_{t+1}\\\\ F^n z_t&amp;=z_{t+n} \\end{align} \\] El operador \\(F\\) es el inverso del operador \\(B\\) ya que: \\[ FBz_t=BFz_t=z_t \\] Por tanto, \\(BF=FB=1,\\) lo que implica que \\(F=B^{-1}\\). 7.2.3 Polinomios en B Sea el polinomio en el operador de retardo \\(B\\): \\[ \\phi_0 - \\phi_1 B - \\ldots - \\phi_pB^p \\] La operación de este polinomio se define como: \\[ (\\phi_0 - \\phi_1 B - \\ldots - \\phi_pB^p)z_t=\\phi_0z_t+\\phi_1z_{t-1}+\\ldots+\\phi_pz_{t-p} \\] Llamamos polinomio autorregresivo de orden \\(p\\) al polinomio de grado \\(p\\) \\[ 1-\\phi_1B-\\dots-\\phi_pB^p \\] La razón de esta nomenclatura es que si tenemos una serie cuyo comportamiento puede expresarse como \\[ (1-\\phi_1B-\\dots-\\phi_pB^p)z_t=e_t \\] donde \\(e_t\\) es un término de error, la anterior expresión puede escribirse como: \\[ z_t=\\phi_1 z_{t-1}+ \\ldots + \\phi_p z_{t-p} + e_t \\] Es decir, como una regresión donde la serie \\(z_t\\) es el output y los propios retardos \\(1,2,\\ldots,p\\) de la variable actúan como inputs o regresores construyendo una autorregresión. En muchas ocasiones emplearemos las formas \\(\\phi(B), \\psi(B), \\varphi(B)\\) u otras semejantes para denotar polinomios en \\(B\\). Notaremos más adelante que asociaremos ciertas formas de expresar polinomios en \\(B\\) como \\(\\phi(B)\\) a clases de polinomios en \\(B\\) que juegan cierto papel especial. Por ejemplo, reservaremos la expresi?n \\(\\phi(B)\\) a polinomios autorregresivos. 7.2.4 Operador diferencia El operador diferencia respecto al pasado, en lo sucesivo simplemente operador diferencia, se define como: \\[ \\bigtriangledown z_t = z_t - z_{t-1}, \\] que puede expresarse como: \\[ \\bigtriangledown z_t = z_t - z_{t-1}, \\] que puede expresarse como \\[ (1-B)z_t=\\bigtriangledown z_t. \\] Por lo tanto: \\(\\bigtriangledown =1-B\\). El operador de , usualmente diferencia estacional, se define como \\[ \\bigtriangledown_s z_t=z_t-z_{t-s}=(1-B^s)z_t. \\] Luego, \\(\\bigtriangledown_s=(1-B^s).\\) Debe observarse que cuando aplicamos el operador \\(B\\) a una serie \\(S\\) lo que hacemos en realidad es adelantar la serie un periodo. Análogamente, cuando aplicamos el operador \\(F\\) a una serie \\(S\\) retrasamos la serie un periodo. "],
["alisado-exponencial.html", "7.3 Alisado Exponencial", " 7.3 Alisado Exponencial 7.3.1 ¿Qué es el Alisado Exponencial? Es una técnica aplicada a series de tiempo, para ``suavizarlas’’ u obtener previsiones. Mientras que, con la media móvil, las observaciones pasadas se ponderan por igual, en el alisado exponencial se asignan ponderaciones exponencialmente decrecientes en el tiempo. La fórmula utilizada es: \\[ y_1 = x_0 \\] \\[ y_t = (1-\\theta)x_{t-1}+\\theta y_{t-1}, t &gt; 1 \\] donde \\(\\{x_t\\}\\) son las observaciones reales, \\(\\{y_t\\}\\) son las estimaciones y \\(\\theta\\) es el factor de alisamiento, \\(0 &lt; \\theta &lt; 1\\). En otras palabras, con este método, la previsién para el periodo \\(t\\) (valor esperado) como la suma ponderada de todas la observaciones anteriores, dando mayor importancia a las observaciones más recientes que a las más antiguas. Como puede verse en: \\[ y_t = (1-\\theta) x_{t-1} +\\theta y_{t-1} \\] \\[ y_t = (1-\\theta)x_{t-1}+(1-\\theta)\\theta x_{t-2}+(1-\\theta) \\theta^2 y_{t-2} \\] \\[ y_t = (1-\\theta)[x_{t-1}+\\theta x_{t-2}+\\theta x_{t-3}+\\theta x_{t-4}+ ...] + \\theta^{t-1} x_0 \\] Así, los pesos asignados a las observaciones previas pertenecen a una proporción de la progresión geométrica: \\(\\{1, \\theta, \\theta^2, \\theta^3, ..\\}\\). Por otro lado, si la ecuación arriba se expresa como: \\[ y_t = x_{t-1} + \\theta(y_{t-1} - x_{t-1}) , \\] Se aprecia que \\(y_t\\) está formada por la suma de la observaci?n en el periodo anterior (\\(x_{t-1}\\)) más una proporción (\\(\\theta\\)) del error cometido (\\(y_{t-1} - x_{t-1}\\)). Por lo tanto el valor de \\(\\theta\\) controla la rapidez con que la previsión se adapta a los cambios del nivel de la serie (estado). Si \\(\\theta\\) es grande (próximo a 1), la previsión se adapta rápidamente a los cambios, por lo tanto se debe utilizar en series poco estables. Si \\(\\theta\\) es pequeño (próximo a 0), se consigue eliminar el efecto de las fluctuaciones, por lo tanto se debe utilizar en series estables. El valor de \\(\\theta\\) se puede optimizar minimizando la suma de cuadrados del error de previsión, es decir, resolviendo: \\(min(x_{t-1} - y_{t-1})^2\\). El alisado exponencial, t?cnicamente, es equivalente a un modelo ARIMA (0,1,1) sin constante. En otras palabras, se puede representar por: \\[ \\hat{y} = (1-\\theta)(1 + \\theta B + \\theta^2 B^2 + \\theta^3 B^3 + ...)x_{t-1} \\] donde \\(B\\) es el operador retardo y \\(\\theta\\) es el parámetro de amortiguamiento. Esta representación no implica recargar el último término con un peso mayor a los valores más recientes. Si existe un n?mero finito de per?odos observados, la ecuaci?n anterior se reescribe como: \\[ \\hat{y} = \\alpha (1 + \\theta B + \\theta^2 B^2 + ... + \\theta^p B^p)x_{t-1}\\] donde \\(p\\) es el número de periodos disponibles y $ 7.3.2 Librerías A lo largo de este documento se utilizan dos paquetes de R: XTS: eXtensible Time Series y HIGHCHARTER: a R wrapper for Highcharts javascript libray and its modules. . Los manual de usuario de ambos paquetes esta disponibles en la siguientes enlaces: Manual de XTS y Manual de HIGHCHARTER Para instalar un paquete de R, se puede usar el comando: install.packages(&quot;nombre del paquete&quot;). Por ejemplo, install.packages(&quot;xts&quot;). De forma alternativa: # Get xts if (!require(&quot;xts&quot;)) { install.packages(&quot;xts&quot;) library(xts) } "],
["lectura-y-visualizacion.html", "7.4 Lectura y Visualización", " 7.4 Lectura y Visualización 7.4.1 Datos Originales Definimos la carpeta de trabajo y leemos el fichero de los datos con la función read.zoo. En este ejemplo, los datos están en el fichero ClientesTotalesXTS.csv que tiene formato CSV. Leer los datos de esta manera tiene como ventaja que las fechas son reconocidas como tal. Al usar una función como read.csv entienden las fechas como textos y no siempre son bien entendidas por las funciones que necesitan series temporales como input. #setwd(&quot;C:/Users/rerodriguez/Desktop/script/rev&quot;) #seleccionar la carpeta de trabajo, donde se encuentran los datos y donde se guardan resultados. #datos = read.zoo(&quot;ClientesTotalesXTS.csv&quot;, sep=&#39;,&#39;, tz=&#39;&#39;,header=T, format=&#39;%d-%m-%Y&#39;) #matriz con los datos. Los nombres de las filas han sido reconocidos como fechas #datos = exp(datos) #transformación opcional datos = scan(&quot;http://robjhyndman.com/tsdldata/data/fancy.dat&quot;) datos = log(datos) #transformación opcional head(datos,5) #primeros 5 datos [1] 7.41747 7.78219 7.95181 8.17394 8.23030 tail(datos,5) #últimos 5 datos [1] 10.2607 10.3257 10.3360 10.7501 11.5585 7.4.2 Objeto XTS La forma más conocida para la creación de un objeto de la clase serie temporal, es el uso de la función ts. En este ejemplo, creamos la serie temporal client.ts a partir de datos. client.ts=ts(datos, frequency=12, start=c(1987,1)) #objeto TS Sin embargo, la manipulación de la serie es bastante más natural y amigable utilizando un objeto de la clase xts. En este ejemplo se crea el objeto de client a partir de datos y se hacen consultas básicas sobre su contenido (fechado, primer dato, últimas semanas, número de semanas en la muestra, etc.) client = as.xts(client.ts) #creación del objeto XTS is.xts(client) #debe devolver TRU [1] TRUE periodicity(client) #fechado de los datos Monthly periodicity from ene. 1987 to dic. 1993 first(client) #primer dato [,1] ene. 1987 7.41747 last(client) #último dato [,1] dic. 1993 11.5585 first(client, &#39;7 days&#39;) #primeros 7 dias [,1] ene. 1987 7.41747 feb. 1987 7.78219 mar. 1987 7.95181 abr. 1987 8.17394 may. 1987 8.23030 jun. 1987 8.22006 jul. 1987 8.37784 last(client, &#39;2 weeks&#39;) #últimas dos semanas [,1] nov. 1993 10.7501 dic. 1993 11.5585 ndays(client) #número de días en la muestra [1] 84 nweeks(client) #número de semanas en la muestra [1] 84 nmonths(client) #número de meses en la muestra [1] 84 nquarters(client) #número de trimestres en la muestra [1] 28 nyears(client) #número de años en la muestra [1] 7 7.4.3 Selección de datos usando las fechas Una funcionalidad interesante es la obtención de sub-muestras, utilizando la(s) fecha(s) como criterio(s) de selección. client[&#39;2012-02-01/2012-02-05&#39;] #todos los datos del 01 al 05 de Febrero de 2012 [,1] first(client[&#39;2012-02&#39;], &#39;5 days&#39;) #primeros 5 datos de Febrero de 2012 [,1] last(client[&#39;2013&#39;], &#39;1 week&#39;) #datos última semana de 2013 [,1] rbind(client[&#39;2011-02-01/2011-02-05&#39;],client[&#39;2012-02-01/2012-02-05&#39;]) #todos los datos del 01 al 05 de Febrero de 2011 y 2012 [,1] "],
["manipulacion.html", "7.5 Manipulación", " 7.5 Manipulación 7.5.1 Cambios de Fechado El cambio de fechado o periodicidad es una operación muy útil durante el trabajo con series temporales. En este ejemplo, como la variable analizada es Número Total Diario de Clientes, se utiliza la función sum para obtener el Número Total Semanal, Mensual, Trimestral y Anual de Clientes. client.sem=apply.weekly(client, sum) # datos semanales first(client.sem, &#39;3 weeks&#39;) [,1] ene. 1987 7.41747 feb. 1987 7.78219 mar. 1987 7.95181 client.mes=apply.monthly(client, sum) # datos mensuales first(client.mes, &#39;3 months&#39;) [,1] ene. 1987 7.41747 feb. 1987 7.78219 mar. 1987 7.95181 client.qua=apply.quarterly(client, sum) # datos trimestrales first(client.qua, &#39;3 quarters&#39;) [,1] mar. 1987 23.1515 jun. 1987 24.6243 sep. 1987 25.0787 client.yea=apply.yearly(client, sum) # datos anuales first(client.yea, &#39;3 years&#39;) [,1] dic. 1987 100.449 dic. 1988 105.113 dic. 1989 108.676 7.5.2 Imputación de Datos Faltantes La falta de algunos datos y/o la presencia de datos errones suele tratarse con procedimientos de imputación - para no perder histórico de la muestra disponible. El paquete xts posee funciones que permiten extender hacia adelante o hacia atrás, valores observados en la misma serie temporal. which(is.na(client)) #identifica las líneas con NA integer(0) client.na01=na.locf(client) #repite el ultimo anterior a NA client.na01[14:17,] [,1] feb. 1988 8.55608 mar. 1988 8.88532 abr. 1988 8.47763 may. 1988 8.68286 client.na02=na.locf(client, fromLast=TRUE) # repite el primero despues de NA client.na02[14:17,] [,1] feb. 1988 8.55608 mar. 1988 8.88532 abr. 1988 8.47763 may. 1988 8.68286 client.na03=na.locf(client, na.rm=TRUE, fromLast=TRUE) client.na03[14:17,] [,1] feb. 1988 8.55608 mar. 1988 8.88532 abr. 1988 8.47763 may. 1988 8.68286 7.5.3 Estadísticos en diferentes fechados El paquete xtspermite trabajar con series de estadísticos en fechado agregado. Por ejemplo, el máximo del mes, el mínimo del trimestre, etc. El ingrediente indispensable es el vector que indica los puntos de quiebre de la serie. Este vector se obtiene con la función endpoints. aux.mes=endpoints(client,&quot;months&quot;) #indica los finales de mes par(mfrow=c(1,3), cex.lab=0.8,cex.axis=0.8,las=2) plot(period.sum(client.na01,aux.mes), main=&quot;Total del Mes&quot;) plot(period.min(client.na01,aux.mes), main=&quot;Mínimo del Mes&quot;) plot(period.max(client.na01,aux.mes), main=&quot;Máximo del Mes&quot;) aux.qua=endpoints(client,&quot;quarters&quot;) #indica los finales de trimestre par(mfrow=c(1,3),cex.lab=0.8,cex.axis=0.8,las=2) plot(period.sum(client.na01,aux.qua), main=&quot;Total del Trimestre&quot;) plot(period.min(client.na01,aux.qua), main=&quot;Mínimo del Trimestre&quot;) plot(period.max(client.na01,aux.qua), main=&quot;Máximo del Trimestre&quot;) 7.5.4 División del conjunto de datos usando fechas Otra funcionalidad útil es split. Permite dividir el objeto original en sub-conjuntos, teniendo en cuenta un fechado y un horizonte. En este caso, se divide el objeto client en sub-muestras de 4 meses cada una. client.by.4months=split(client, f=&quot;months&quot;,k=4) #divide el conjunto de datos en partes de 4 meses cada una summary(client.by.4months) #indica el número de elemento que hay en cada parte Length Class Mode [1,] 4 xts numeric [2,] 4 xts numeric [3,] 4 xts numeric [4,] 4 xts numeric [5,] 4 xts numeric [6,] 4 xts numeric [7,] 4 xts numeric [8,] 4 xts numeric [9,] 4 xts numeric [10,] 4 xts numeric [11,] 4 xts numeric [12,] 4 xts numeric [13,] 4 xts numeric [14,] 4 xts numeric [15,] 4 xts numeric [16,] 4 xts numeric [17,] 4 xts numeric [18,] 4 xts numeric [19,] 4 xts numeric [20,] 4 xts numeric [21,] 4 xts numeric 7.5.5 Otras operaciones con los datos Finalmente, se presenta un ejemplo de una serie obtenida a partir del uso de operaciones básicas de R como diff y log. client.inc &lt;- diff(log(client), lag = 1) #Tasa de incremento diario client.inc &lt;- client.inc[-1] #Eliminamos el primer dato por ser NA par(mfrow=c(1,1),cex.lab=0.8,cex.axis=0.8,las=2) plot(client.inc, main = &quot;Nuevos Clientes&quot;, col = &quot;grey&quot;, xlab = &quot;Date&quot;, ylab = &quot;Variación&quot;, major.ticks=&#39;years&#39;, minor.ticks=FALSE) "],
["graficos.html", "7.6 Gráficos", " 7.6 Gráficos 7.6.1 Con xts Los gráficos de objetos xts son bastante más visuales o legibles que los objetos ts. La principal diferencia está en el reconocimiento de las fechas y su visualización en el eje horizontal. par(mfrow=c(1,1),cex.lab=0.8,cex.axis=0.8,las=2) plot(client, main = &quot;Clientes Totales, por día&quot;, col = &quot;darkblue&quot;,xlab = &quot;Date&quot;, ylab = &quot;Número de Clientes&quot;, major.ticks=&#39;quarters&#39;, minor.ticks=FALSE) plot(client.mes[&#39;1990-03/1993-12&#39;], main = &quot;Clientes Totales, por mes&quot;, col = &quot;blue&quot;,xlab = &quot;Date&quot;, ylab = &quot;Número de Clientes&quot;, major.ticks=&#39;years&#39;, minor.ticks=FALSE) 7.6.2 Con highcharter Los gráficos generados con highcharter utilizan la biblioteca Highcharts highchart() %&gt;% hc_chart(type=&quot;line&quot;,zoomType=&quot;x&quot;)%&gt;% hc_title(text = &quot;Clientes Totales, por día&quot;) %&gt;% hc_subtitle(text = &quot;Gráfico Tipo Línea&quot;) %&gt;% hc_legend(enabled = T) %&gt;% hc_tooltip(valueDecimals= 2,shared=T, crosshairs=T) %&gt;% hc_xAxis(type = &#39;datetime&#39;, tickInterval=10, labels = list(format = &#39;{value:%m-%Y}&#39;,rotation=-90)) %&gt;% hc_add_series(data=client.ts, name = &quot;Número de Clientes&quot;, color = bysCol[1], lineWidth= 1) %&gt;% hc_credits(enabled = TRUE, # add credits text = &quot;Elaborado por Innova-tsn&quot;, href = &quot;https://www.innova-tsn.com&quot;) %&gt;% hc_exporting(enabled = TRUE) hc &lt;- highchart(type=&quot;stock&quot;) %&gt;% hc_title(text = &quot;Clientes Totales, por día&quot;) %&gt;% hc_subtitle(text = &quot;Gráfico tipo Stock&quot;) %&gt;% hc_legend(enabled = T) %&gt;% hc_tooltip(valueDecimals= 0) %&gt;% hc_add_series(data=client.ts, name = &quot;Número de Clientes&quot;, color = bysCol[1]) %&gt;% hc_credits(enabled = TRUE, # add credits text = &quot;Elaborado por Innova-tsn&quot;, href = &quot;https://www.innova-tsn.com&quot;) hc "],
["unsupervised-learning.html", "Capítulo 8 Unsupervised Learning", " Capítulo 8 Unsupervised Learning En esta sección hablaremos sobre el aprendizaje no supervisado. Hablamos de aprendizaje no supervisado cuando no tenemos la etiqueta o clase a la que pertenece cada registro. Resumen sección Aplicaciones: segmentación de usuarios. "],
["k-means.html", "8.1 K-means", " 8.1 K-means 8.1.1 Modelo K-means Clustering es un algoritmo no supervisado que trata de agrupar los datos. Es decir, agrupa \\(n\\) observaciones en \\(k\\) grupos. Es importante remarcar que \\(k\\) debe ser fijado por el usuario. El algoritmo asigna aleatoriamente cada observación a un clúster y encuentra el centroide de cada clúster. Entonces, el algoritmo itera a través de dos pasos: Reasigna los puntos al centroide cuya distancia es menor. Calcula el nuevo centroide de cada grupo. Estos dos pasos se repiten hasta que la variación dentro del clúster no se puede reducir más. La variación dentro del clúster se calcula como la suma de las distancias entre los puntos y sus respectivos centroides. Es decir, Dado un conjunto de \\(n\\) observaciones, \\(x_1, ..., x_n\\). K-means construye una partición de las observaciones en \\(k\\) conjuntos (\\(k ≤ n\\)) a fin de minimizar la suma de las distancias dentro de cada grupo, \\(S = {S_{1}, S_{2}, …, S_{k}}\\). \\[\\min \\sum_{i=1}^{k}\\sum_{x_{j}\\in S_{j}} d(x_{j}, \\mu_{i}),\\] donde \\(\\mu_i\\) es el centroide de \\(S_i\\). Se suele usar la distancia euclidea, pero podemos buscar otras distancias que se adecuen mejor a los datos, como por ejemplo, la norma infinita o la distancia de Manhattan. 8.1.2 Implementación en R Para esta sección usaremos el data set de iris, donde tenemos datos sobre las dimensiones de pétalos y sépalos de distintas especies de flores. data(iris) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Nos centraremos en las dimensiones de los pétalos. library(ggplot2) p = ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point() p Ahora aplicamos K-means con \\(k=3\\) y \\(nstart=20\\). Esto significa que agrupará los datos en tres grupos y el algoritmo probará 20 distintas formas de empezar y se quedará con la mejor, es decir, seleccionará aquella con menor variación de los clústers. set.seed(20) irisCluster = kmeans(iris[, 3:4], 3, nstart = 20) irisCluster ## K-means clustering with 3 clusters of sizes 50, 52, 48 ## ## Cluster means: ## Petal.Length Petal.Width ## 1 1.462000 0.246000 ## 2 4.269231 1.342308 ## 3 5.595833 2.037500 ## ## Clustering vector: ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [36] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [71] 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 ## [106] 3 2 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 2 3 ## [141] 3 3 3 3 3 3 3 3 3 3 ## ## Within cluster sum of squares by cluster: ## [1] 2.02200 13.05769 16.29167 ## (between_SS / total_SS = 94.3 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; ## [5] &quot;tot.withinss&quot; &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; ## [9] &quot;ifault&quot; A continuación, hacemos una comprobación de si el algoritmo funciona correctamente. table(irisCluster$cluster, iris$Species) ## ## setosa versicolor virginica ## 1 50 0 0 ## 2 0 48 4 ## 3 0 2 46 Normalmente, esta comprobación no la podemos hacer, ya que al tratarse de aprendizaje no supervisado no tenemos las clases. p = ggplot() + geom_point(data = iris, aes(x = Petal.Length, y = Petal.Width, shape = iris$Species, color = as.factor(irisCluster$cluster))) + geom_point(data = as.data.frame(irisCluster$centers), aes(x = Petal.Length, y = Petal.Width), size = 3) p 8.1.3 Evaluación Como hemos visto se puede hacer una evaluación visual del funcionamiento del algoritmo. En el caso anterior se puede plotear bien, ya que sólo usamos dos componentes. En caso de tener más componentes podemos usar un PCA y usar las dos componentes principales. library(cluster) x = rbind(cbind(rnorm(10,0,0.5), rnorm(10,0,0.5)), cbind(rnorm(15,5,0.5), rnorm(15,5,0.5))) clusplot(clara(x, 2)) x4 = cbind(x, rnorm(25), rnorm(25)) clusplot(pam(x4, 2)) Hay que tener cuidado con estas visualizaciones, ya que reducir grandes dimensiones a dos componentes se pierde mucha información. Aunque visualmente parezca que no agrupa bien es posible que sí lo haga en una tercera componente. Otro método más numérico es usar el coeficiente de Silhouette. El coeficiente de Silhouette contrasta la distancia media con los elementos en el mismo grupo con la distancia media a los elementos en otros grupos. Los objetos con un valor alto se consideran agrupados. library(cluster) irisCluster = clara(iris[, 3:4], k = 3, metric = &quot;euclidean&quot;) si = silhouette(irisCluster) cat(paste(&quot;Cluster 1:&quot;, mean(si[, 3][si[, 1]==1]), &quot;\\nCluster 2:&quot;, mean(si[, 3][si[, 1]==2]), &quot;\\nCluster 3:&quot;, mean(si[, 3][si[, 1]==3]))) ## Cluster 1: 0.932477754552061 ## Cluster 2: 0.647244785444017 ## Cluster 3: 0.549691563362595 Nota: clara es una variante de K-means que se suele usar cuando tienes una gran cantidad de datos. Véase también pam. 8.1.4 Determinar el número de clústers óptimo Hay varios criterios para determinar el número óptimo de clústers, como por ejemplo, el coeficiente de Silhouette entre otros. El siguiente método usa 26 criterios distintos para determinar el número óptimo de clústers. library(NbClust) set.seed(4) nc = NbClust(iris[, 3:4], min.nc=2, max.nc=15, method=&quot;kmeans&quot;) ## *** : The Hubert index is a graphical method of determining the number of clusters. ## In the plot of Hubert index, we seek a significant knee that corresponds to a ## significant increase of the value of the measure i.e the significant peak in Hubert ## index second differences plot. ## ## *** : The D index is a graphical method of determining the number of clusters. ## In the plot of D index, we seek a significant knee (the significant peak in Dindex ## second differences plot) that corresponds to a significant increase of the value of ## the measure. ## ## ******************************************************************* ## * Among all indices: ## * 10 proposed 2 as the best number of clusters ## * 7 proposed 3 as the best number of clusters ## * 1 proposed 4 as the best number of clusters ## * 1 proposed 9 as the best number of clusters ## * 2 proposed 11 as the best number of clusters ## * 3 proposed 12 as the best number of clusters ## ## ***** Conclusion ***** ## ## * According to the majority rule, the best number of clusters is 2 ## ## ## ******************************************************************* barplot(table(nc$Best.n[1,]), xlab=&quot;Numer of Clusters&quot;, ylab=&quot;Number of Criteria&quot;, main=&quot;Number of Clusters Chosen by 26 Criteria&quot;) Como podemos observar el número optimo de clúster es dos, aunque hay siete criterios que dicen que el número óptimo es tres. Esta conclusión tiene sentido observando los datos. "],
["hierarchical-clustering.html", "8.2 Hierarchical clustering", " 8.2 Hierarchical clustering 8.2.1 Modelo El agrupamiento jerárquico es un método de análisis de grupos, el cual busca construir una jerarquía de grupos. Hoy dos tipos de estrategias para agrupamiento jerárquico: Aglomerativas: Este es un acercamiento ascendente. Cada observación comienza en su propio grupo y los pares de grupos son mezclados mientras uno sube en la jerarquía. Divisivas: Este es un acercamiento descendente. Todas las observaciones comienzan en un grupo y se realizan divisiones mientras uno baja en la jerarquía. Es aconsejable usar los métodos aglomerativos, ya que tienen menor orden de complejidad. Por esta razón nos centraremos en los métodos aglomerativos. El algoritmo funciona de la siguiente manera: Colocar cada punto en su propio clúster. Identificar los dos clústers más cercanos y combinarlos en un clúster. Repetir el paso anterior hasta que todos los puntos estén en un solo clúster. Hay varios criterios de enlace: Agrupamiento de máximo o completo enlace. Agrupamiento de mínimo o simple enlace. Agrupamiento de enlace media o promedio (UPGMA). Agrupamiento de mínima energía. La suma de todas las varianzas intra-grupo. El decrecimiento en la varianza para los grupos que están siendo mezclados (criterio de Ward). La probabilidad de que grupos candidatos se produzcan desde la misma función de distribución (V-enlace). 8.2.2 Implementación en R Como en la sección anterior usaremos el data set de iris, así podremos comparar los métodos. Los árboles jerárquicos se suelen representar con un dendograma. set.seed(44) hclusters = hclust(dist(iris[, 3:4]), method = &quot;complete&quot;) plot(hclusters) abline(h = 3, col = &quot;red&quot;) abline(h = 2, col = &quot;red&quot;) Como podemos observar en el dendograma el número óptimo de clusters es tres o cuatro. Seleccionamos tres para comparar con Species. clusterCut = cutree(hclusters, 3) table(clusterCut, iris$Species) ## ## clusterCut setosa versicolor virginica ## 1 50 0 0 ## 2 0 21 50 ## 3 0 29 0 p = ggplot() + geom_point(data = iris, aes(x = Petal.Length, y = Petal.Width, shape = iris$Species, color = as.factor(clusterCut))) p Parece que este método no va muy bien. Probamos ahora usando el criterio de agrupamiento de enlace media o promedio (UPGMA). hclusters &lt;- hclust(dist(iris[, 3:4]), method = &#39;average&#39;) plot(hclusters) clusterCut = cutree(hclusters, 3) table(clusterCut, iris$Species) ## ## clusterCut setosa versicolor virginica ## 1 50 0 0 ## 2 0 45 1 ## 3 0 5 49 p = ggplot() + geom_point(data = iris, aes(x = Petal.Length, y = Petal.Width, shape = iris$Species, color = as.factor(clusterCut))) p Estos resultados ya nos gustan más. Hay que recordar que normalment no podemos calcular la matriz de confusión en el aprendizaje no supervisado. La evaluación es análoga al método de K-means. La evaluación de los métodos no supervisados suele ser algo un poco subjetivo. Hay que buscar una métrica que se ajuste al problema y comparar distintos métodos y parámetros. "],
["other-clustering-methods.html", "8.3 Other clustering methods", " 8.3 Other clustering methods Caption for the picture. 8.3.0.1 Un caso práctico Veremos como aplicar las técnicas vistas anteriormente en un caso real. Usarremos un data set de Kaggle ¿¿¿?????? "],
["random-forests.html", "Capítulo 9 Random Forests", " Capítulo 9 Random Forests El primer paso es crear una carpeta con nuestros modelos y resultados dentro de nuestro espacio de trabajo (proyecto). Obtenemos el directorio de trabajo myWD &lt;- getwd() elegimos un nombre para nuestra carpeta con resultados myWorkingFolderName &lt;- &#39;ModelResults&#39; Creamos la carpeta donde guardaremos nuestros resultados y ficheros dir.create( paste0(getwd(),&quot;/&quot;,myWorkingFolderName)) ## Warning in dir.create(paste0(getwd(), &quot;/&quot;, myWorkingFolderName)): &#39;C: ## \\Users\\romy.rodriguez\\Documents\\INNOVA\\Formacion\\MiCurso\\ModelizacionR ## \\ModelResults&#39; already exists Cargamos librerías de trabajo Funciones para entrenar modelos de ML if (!require(caret)) install.packages(&#39;caret&#39;) ## Loading required package: caret ## Loading required package: lattice ## Loading required package: ggplot2 library(caret) Métricas de evaluación del poder de clasificación if (!require(ModelMetrics)) install.packages(&#39;ModelMetrics&#39;) ## Loading required package: ModelMetrics ## ## Attaching package: &#39;ModelMetrics&#39; ## The following objects are masked from &#39;package:caret&#39;: ## ## confusionMatrix, precision, recall, sensitivity, specificity library(ModelMetrics) Para crear curvas ROC if (!require(ROCR)) install.packages(&#39;ROCR&#39;) ## Loading required package: ROCR ## Loading required package: gplots ## ## Attaching package: &#39;gplots&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## lowess ## Loading required package: methods library(ROCR) Cargamos la librería insuranceData que contiene los datos que utilizaremos if (!require(insuranceData)) install.packages(&#39;insuranceData&#39;) ## Loading required package: insuranceData library(insuranceData) Para ver los contenidos de la librería ejecutamos: data(package=&#39;insuranceData&#39;) Vemos que hay 10 datasets. Trabajaremos con el primero: AutoBi (Automobile Bodily Injury Claims) Cargamos los datos de pérdidas en accidentes de coches: data(&quot;AutoBi&quot;) Descripción de las variables del fichero de datos AutoBi: Casenum. Identificador de la reclamación (esta variable no se utiliza ya que no es una variable predictora) Attorney. Indica si el reclamante está representado por un abogado (1= Sí, 2 = No) Clmsex. Indicador del ‘Sexo del reclamante’ (1 = Hombre, 2 = Mujer) Marital. Indicador del ‘Estado Civil del reclamante’ (1 = Casado, 2 = Soltero, 3 = Viudo, 4 = divorciado/separado) Clminsur. Indica si el conductor del vehículo del reclamante estaba o no asegurado (1 = S?, 2 = No, 3 = No aplica) Seatbelt. Si el reclamante llevaba o no un cinturón de seguridad en el asiento infantil (1 = S?, 2 = No, 3 = No Aplica) Clmage. Edad del reclamante Loss (*). La pérdida económica total del reclamante (en miles). Esta es la variable dependiente del conjunto de datos. Revisamos el contenido de la tabla y el tipo de datos que contiene str(AutoBi) ## &#39;data.frame&#39;: 1340 obs. of 8 variables: ## $ CASENUM : int 5 13 66 71 96 97 120 136 152 155 ... ## $ ATTORNEY: int 1 2 2 1 2 1 1 1 2 2 ... ## $ CLMSEX : int 1 2 1 1 1 2 1 2 2 1 ... ## $ MARITAL : int NA 2 2 1 4 1 2 2 2 2 ... ## $ CLMINSUR: int 2 1 2 2 2 2 2 2 2 2 ... ## $ SEATBELT: int 1 1 1 2 1 1 1 1 1 1 ... ## $ CLMAGE : int 50 28 5 32 30 35 19 34 61 NA ... ## $ LOSS : num 34.94 10.892 0.33 11.037 0.138 ... Estadísticas descriptivas básicas summary(AutoBi) ## CASENUM ATTORNEY CLMSEX MARITAL ## Min. : 5 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.: 8579 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :17453 Median :1.000 Median :2.000 Median :2.000 ## Mean :17213 Mean :1.489 Mean :1.559 Mean :1.593 ## 3rd Qu.:25703 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:2.000 ## Max. :34253 Max. :2.000 Max. :2.000 Max. :4.000 ## NA&#39;s :12 NA&#39;s :16 ## CLMINSUR SEATBELT CLMAGE LOSS ## Min. :1.000 Min. :1.000 Min. : 0.00 Min. : 0.005 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:19.00 1st Qu.: 0.640 ## Median :2.000 Median :1.000 Median :31.00 Median : 2.331 ## Mean :1.908 Mean :1.017 Mean :32.53 Mean : 5.954 ## 3rd Qu.:2.000 3rd Qu.:1.000 3rd Qu.:43.00 3rd Qu.: 3.995 ## Max. :2.000 Max. :2.000 Max. :95.00 Max. :1067.697 ## NA&#39;s :41 NA&#39;s :48 NA&#39;s :189 Para llamar directamente a las variables por sus nombres en la tabla AutoBi utilizamos el comando attach attach(AutoBi) Para mirar la distribución de la variable target: LOSS (pérdida económica) hist(LOSS, breaks=300 , probability = T) lines(density(LOSS), col=&quot;red&quot;,main=&quot;Loss distribution&quot;) es una variable altamente asimétrica (con posibles outliers a la derecha) Debido a la alta asimetría de la distribución de la variable target, utilizamos una medida robusta para segmentar los datos en dos clases: \\(1\\) si las pérdidas son atípicamente altas o \\(0\\) si no lo son. lsup &lt;- median(LOSS) + 1.5*IQR(LOSS) # Criterio basado en estadisticos robustos sum(LOSS&gt;=lsup) # 153 datos de perdidas atipicamente altas ## [1] 153 Guardamos el gráfico del histograma para futuros análisis y/o reportes Path_to_graphics &lt;- paste0(getwd(),&quot;/&quot;,&quot;Graphics&quot;) dir.create(Path_to_graphics) ## Warning in dir.create(Path_to_graphics): &#39;C:\\Users\\romy.rodriguez\\Documents ## \\INNOVA\\Formacion\\MiCurso\\ModelizacionR\\Graphics&#39; already exists png(paste0(Path_to_graphics,&quot;/histograma.png&quot;)) hist(LOSS[LOSS&lt;lsup],breaks = 100,probability = T, xlab=&quot;loss (pérdida en miles $US)&quot; , main=&quot;Datos de pérdida no severa&quot;) lines(density(LOSS[LOSS&lt;lsup]),col=&quot;red&quot;) dev.off() ## png ## 2 Creamos el dataset de trabajo. Creamos un dataset de trabajo eliminando la variable CASENUM (id) y filtrando por la variable LOSS y el valor lsup= 72.22587 (miles) df_autobi &lt;- AutoBi[ , -match(&quot;CASENUM&quot;, colnames(AutoBi)) ] Fijamos los predictores categóricos como factores: Representado por un abogado: \\(1\\) = representado por letrado y \\(2\\) = no representado df_autobi$ATTORNEY &lt;- ordered(df_autobi$ATTORNEY, levels = 1:2) Sexo del reclamante: \\(1\\) = hombre y \\(2\\) = mujer df_autobi$CLMSEX &lt;- ordered(df_autobi$CLMSEX , levels = 1:2) Estado civil del reclamante: \\(1\\) = casado, \\(2\\) = soltero, \\(3\\) = viudo y \\(4\\) = divorciado / separado df_autobi$MARITAL &lt;- ordered(df_autobi$MARITAL , levels = 1:4) \\(1\\) = vehículo estaba asegurado y \\(2\\)= no lo estaba df_autobi$CLMINSUR &lt;- ordered(df_autobi$CLMINSUR, levels = 1:2) \\(1\\) = llevaba cinturón abrochado y \\(2\\) = no lo llevaba df_autobi$SEATBELT &lt;- ordered(df_autobi$SEATBELT, levels = 1:2) \\(1\\)= representado por letrado y \\(2\\)= no representado df_autobi$Y &lt;- ifelse(df_autobi$LOSS&gt;= lsup,1,0) Proporción de atípicos 11.42% summary(df_autobi) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:685 1 :586 1 :624 1 : 120 1 :1270 Min. : 0.00 ## 2:655 2 :742 2 :650 2 :1179 2 : 22 1st Qu.:19.00 ## NA&#39;s: 12 3 : 15 NA&#39;s: 41 NA&#39;s: 48 Median :31.00 ## 4 : 35 Mean :32.53 ## NA&#39;s: 16 3rd Qu.:43.00 ## Max. :95.00 ## NA&#39;s :189 ## LOSS Y ## Min. : 0.005 Min. :0.0000 ## 1st Qu.: 0.640 1st Qu.:0.0000 ## Median : 2.331 Median :0.0000 ## Mean : 5.954 Mean :0.1142 ## 3rd Qu.: 3.995 3rd Qu.:0.0000 ## Max. :1067.697 Max. :1.0000 ## (Opcional) Ahondamos un poco más en la relación de la pérdida con los factores. Falta utilizar aggregate para estudiar las correlaciones entre las variables. agg_loss_attorney &lt;- aggregate(LOSS, by = list(ATTORNEY) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_attorney)[[1]] &lt;- c(&quot;REPRESENTED&quot;,&quot;NOT REPRESENTED&quot;) ; dimnames(agg_loss_attorney)[[2]] &lt;- c(&quot;ATTORNEY&quot;,&quot;LOSS&quot;) agg_loss_clmsex &lt;- aggregate(LOSS, by = list(CLMSEX) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_clmsex)[[1]] &lt;- c(&quot;MALE&quot;,&quot;FEMALE&quot;) ; dimnames(agg_loss_clmsex)[[2]] &lt;- c(&quot;CLMSEX&quot;,&quot;LOSS&quot;) agg_loss_marital &lt;- aggregate(LOSS, by = list(MARITAL) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_marital)[[1]] &lt;- c(&quot;MARRIED&quot;,&quot;SINGLE&quot;,&quot;WIDOW&quot;,&quot;DIVORCED&quot;) ; dimnames(agg_loss_marital)[[2]] &lt;- c(&quot;MARITAL&quot;,&quot;LOSS&quot;) agg_loss_clminsur &lt;- aggregate(LOSS, by = list(CLMINSUR) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_clminsur)[[1]] &lt;- c(&quot;INSURED&quot;,&quot;NOT INSURED&quot;) ; dimnames(agg_loss_clminsur)[[2]] &lt;- c(&quot;CLMINSUR&quot;,&quot;LOSS&quot;) agg_loss_seatbelt &lt;- aggregate(LOSS, by = list(SEATBELT) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_seatbelt)[[1]] &lt;- c(&quot;SEATBELT&quot;,&quot;NOT SEATBELT&quot;) ; dimnames(agg_loss_seatbelt)[[2]] &lt;- c(&quot;SEATBELT&quot;,&quot;LOSS&quot;) Resumen agg_loss_attorney ## ATTORNEY LOSS ## REPRESENTED 1 9.863109 ## NOT REPRESENTED 2 1.864745 agg_loss_clmsex ## CLMSEX LOSS ## MALE 1 5.652647 ## FEMALE 2 6.213765 agg_loss_marital ## MARITAL LOSS ## MARRIED 1 7.878564 ## SINGLE 2 4.130960 ## WIDOW 3 3.483867 ## DIVORCED 4 6.857743 agg_loss_clminsur ## CLMINSUR LOSS ## INSURED 1 4.626200 ## NOT INSURED 2 6.182775 agg_loss_seatbelt ## SEATBELT LOSS ## SEATBELT 1 5.85892 ## NOT SEATBELT 2 19.47986 Resumen combinando los tres mayores factores de riesgo (propensión) agg_loss_many &lt;- aggregate(LOSS, by = list(SEATBELT,ATTORNEY,MARITAL) , FUN= mean , na.rm=TRUE) dimnames(agg_loss_many)[[2]] &lt;- c(&quot;SEATBELT&quot;,&quot;ATTORNEY&quot;,&quot;MARITAL&quot;,&quot;LOSS&quot;) Aleatorizamos los datos y separamos el set de datos en train y test: N=nrow(df_autobi) Es importante fijar una semilla para los algoritmos de aleatorización internos de R set.seed(123456) inTrain &lt;- createDataPartition(df_autobi$Y, times = 1, p = 0.7, list = TRUE) dt_train &lt;- df_autobi[inTrain[[1]],] # 938 casos dt_test &lt;- df_autobi[-inTrain[[1]],] # 402 casos nrow(dt_train) ## [1] 938 summary(dt_train) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:471 1 :406 1 :439 1 : 77 1 :885 Min. : 0.00 ## 2:467 2 :523 2 :455 2 :833 2 : 17 1st Qu.:20.00 ## NA&#39;s: 9 3 : 10 NA&#39;s: 28 NA&#39;s: 36 Median :32.00 ## 4 : 25 Mean :33.06 ## NA&#39;s: 9 3rd Qu.:43.00 ## Max. :95.00 ## NA&#39;s :134 ## LOSS Y ## Min. : 0.0050 Min. :0.0000 ## 1st Qu.: 0.7123 1st Qu.:0.0000 ## Median : 2.3645 Median :0.0000 ## Mean : 5.4656 Mean :0.1141 ## 3rd Qu.: 4.0263 3rd Qu.:0.0000 ## Max. :273.6040 Max. :1.0000 ## nrow(dt_test) ## [1] 402 summary(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## 4 : 10 Mean :31.31 ## NA&#39;s: 7 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y ## Min. : 0.0050 Min. :0.0000 ## 1st Qu.: 0.5175 1st Qu.:0.0000 ## Median : 2.1645 Median :0.0000 ## Mean : 7.0917 Mean :0.1144 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 ## Max. :1067.6970 Max. :1.0000 ## Comprobamos si se han colado algún dato del train en el test length(intersect(inTrain, setdiff(1:N,inTrain))) ## [1] 0 O coincidencias -&gt; Ok "],
["a-entrenamiento-del-modelo-rf-clasificacion.html", "9.1 A. Entrenamiento del modelo RF-clasificación", " 9.1 A. Entrenamiento del modelo RF-clasificación if (!require(randomForest)) install.packages(&#39;randomForest&#39;) ## Loading required package: randomForest ## randomForest 4.6-12 ## Type rfNews() to see new features/changes/bug fixes. ## ## Attaching package: &#39;randomForest&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## margin library(randomForest) Creamos un objeto de clase ‘formula’ y se lo pasamos como argumento a la función randomForest set.seed(123456) fmla.rf1 &lt;- as.formula(paste0(&quot;Y&quot;,&quot; ~&quot;,paste0(colnames(df_autobi[,-c(7,8)]),collapse = &quot;+&quot;),collapse = &quot;&quot;)) rf1 &lt;- randomForest( fmla.rf1, data =dt_train, ntree = 5000, # El procedimiento es bastante rapido con una muestra tan pequena por lo que podemos utilizar ntree &gt; = 2500 replace =TRUE, mtry=4, maxnodes =50, importance = TRUE, proximity = TRUE, keep.forest = TRUE, na.action=na.omit) ## Warning in randomForest.default(m, y, ...): The response has five or fewer ## unique values. Are you sure you want to do regression? No se ha hecho tuning en los parámetros básicos del modelo, se puede hacer con ntree, mtry y maxnodes summary(rf1) ## Length Class Mode ## call 11 -none- call ## type 1 -none- character ## predicted 759 -none- numeric ## mse 5000 -none- numeric ## rsq 5000 -none- numeric ## oob.times 759 -none- numeric ## importance 12 -none- numeric ## importanceSD 6 -none- numeric ## localImportance 0 -none- NULL ## proximity 576081 -none- numeric ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## forest 11 -none- list ## coefs 0 -none- NULL ## y 759 -none- numeric ## test 0 -none- NULL ## inbag 0 -none- NULL ## terms 3 terms call ## na.action 179 omit numeric str(rf1) ## List of 19 ## $ call : language randomForest(formula = fmla.rf1, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, imp| __truncated__ ... ## $ type : chr &quot;regression&quot; ## $ predicted : atomic [1:759] 0.007273 0.000081 0.675016 0.006908 0.017108 ... ## ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ mse : num [1:5000] 0.104 0.119 0.117 0.12 0.121 ... ## $ rsq : num [1:5000] 0.0107 -0.1241 -0.112 -0.1409 -0.1452 ... ## $ oob.times : int [1:759] 1836 1929 1846 1829 1860 1811 1808 1830 1811 1797 ... ## $ importance : num [1:6, 1:2] 0.016961 -0.002353 0.004298 0.000851 0.001241 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..$ : chr [1:2] &quot;%IncMSE&quot; &quot;IncNodePurity&quot; ## $ importanceSD : Named num [1:6] 1.63e-04 1.05e-04 1.70e-04 8.66e-05 5.90e-05 ... ## ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## $ localImportance: NULL ## $ proximity : num [1:759, 1:759] 1 0.192 0 0.427 0 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... ## .. ..$ : chr [1:759] &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; ... ## $ ntree : num 5000 ## $ mtry : num 4 ## $ forest :List of 11 ## ..$ ndbigtree : int [1:5000] 99 99 99 99 99 99 99 99 99 99 ... ## ..$ nodestatus : int [1:99, 1:5000] -3 -3 -3 -3 -3 -3 -3 -1 -1 -3 ... ## ..$ leftDaughter : int [1:99, 1:5000] 2 4 6 8 10 12 14 0 0 16 ... ## ..$ rightDaughter: int [1:99, 1:5000] 3 5 7 9 11 13 15 0 0 17 ... ## ..$ nodepred : num [1:99, 1:5000] 1.26e-01 1.50e-02 1.66e-01 1.53e-16 2.61e-02 ... ## ..$ bestvar : int [1:99, 1:5000] 6 6 3 6 6 1 4 0 0 1 ... ## ..$ xbestsplit : num [1:99, 1:5000] 20.5 15.5 3.5 3.5 17.5 1.5 1.5 0 0 1.5 ... ## ..$ ncat : Named int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## ..$ nrnodes : int 99 ## ..$ ntree : num 5000 ## ..$ xlevels :List of 6 ## .. ..$ ATTORNEY: num 0 ## .. ..$ CLMSEX : num 0 ## .. ..$ MARITAL : num 0 ## .. ..$ CLMINSUR: num 0 ## .. ..$ SEATBELT: num 0 ## .. ..$ CLMAGE : num 0 ## $ coefs : NULL ## $ y : atomic [1:759] 1 0 1 0 0 0 0 0 0 1 ... ## ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ test : NULL ## $ inbag : NULL ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language Y ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + SEATBELT + CLMAGE ## .. ..- attr(*, &quot;variables&quot;)= language list(Y, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;factors&quot;)= int [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ... ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:7] &quot;Y&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## .. .. .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;term.labels&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;order&quot;)= int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;intercept&quot;)= num 0 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(Y, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:7] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Y&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## $ na.action :Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;randomForest.formula&quot; &quot;randomForest&quot; Gráfico de la importancia relativa de los predictores varImpPlot(rf1,sort = T,main = &quot;Variable Importance&quot;) Gráfico del Error vs número de árboles plot(rf1, main=&quot;Error de clasificación vs núero de árboles&quot;) Como valor predicho se obtiene la probabilidad condicional: \\(P(Y=1|X_1 = ATTORNEY,\\ldots,X_6=SEATBELT)\\) Miramos el resultado en el train: rf1.prediction &lt;- as.data.frame(predict(rf1, newdata = dt_train)) dt_train$pred_rf1 &lt;- rf1.prediction$`predict(rf1, newdata = dt_train)` head(dt_train) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1 1 1 &lt;NA&gt; 2 1 50 34.940 1 NA ## 2 2 2 2 1 1 28 10.892 1 3.739339e-01 ## 3 2 1 2 2 1 5 0.330 0 6.700844e-05 ## 4 1 1 1 2 2 32 11.037 1 8.044245e-01 ## 5 2 1 4 2 1 30 0.138 0 4.058483e-03 ## 7 1 1 2 2 1 19 3.538 0 1.521188e-02 tail(dt_train) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1332 1 2 2 2 1 13 1.951 0 0.0007952672 ## 1333 2 2 2 2 1 19 1.110 0 0.0006900556 ## 1334 2 1 2 2 1 49 0.100 0 0.0062276082 ## 1335 2 2 2 2 1 26 0.161 0 0.0007159829 ## 1338 2 2 1 2 1 39 0.099 0 0.0080326490 ## 1340 2 2 2 2 1 30 0.688 0 0.0011077024 summary(dt_train) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:471 1 :406 1 :439 1 : 77 1 :885 Min. : 0.00 ## 2:467 2 :523 2 :455 2 :833 2 : 17 1st Qu.:20.00 ## NA&#39;s: 9 3 : 10 NA&#39;s: 28 NA&#39;s: 36 Median :32.00 ## 4 : 25 Mean :33.06 ## NA&#39;s: 9 3rd Qu.:43.00 ## Max. :95.00 ## NA&#39;s :134 ## LOSS Y pred_rf1 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 ## 1st Qu.: 0.7123 1st Qu.:0.0000 1st Qu.:0.00483 ## Median : 2.3645 Median :0.0000 Median :0.03644 ## Mean : 5.4656 Mean :0.1141 Mean :0.12016 ## 3rd Qu.: 4.0263 3rd Qu.:0.0000 3rd Qu.:0.20796 ## Max. :273.6040 Max. :1.0000 Max. :0.80442 ## NA&#39;s :179 plot(density(dt_train$pred_rf1[!is.na(dt_train$pred_rf1)]), col=&quot;red&quot; , xlab=&quot;Predicciones&quot; , main=&quot;Función de densidad estimada&quot;) Vemos que hay (claramente) dos concentraciones (clases) de probabilidades de pérdida, una concentranción en torno a la probabilidad de pérdida no severa (\\(Y=0\\)) y otra para la pérdida severa (\\(Y=1\\)). Esto no lleva a determinar la elección del punto de corte óptimo para obtener una regla de clasificación, es decir, un criterio para \\(Y_predicted=1\\) (pérdida severa), o bien, para \\(Y_predicted=0\\) (pérdida no severa). Para ello utilizaremos el criterio de la distancia de Kolmogorov-Smirnov (KS). Calculamos la medida de “performance” del mecanismo (modelo) de predicción ‘rf1’ rf1.pred &lt;- prediction(as.numeric(rf1$predicted),as.numeric(rf1$y)) con el train creamos un objeto de tipo ‘prediction’ rf1.perf &lt;- performance(rf1.pred,&quot;tpr&quot;,&quot;fpr&quot;) 9.1.1 Criterio de la distancia de KS: rf1.perf@alpha.values[[1]][rf1.perf@alpha.values[[1]]==Inf] &lt;- round(max(rf1.perf@alpha.values[[1]][rf1.perf@alpha.values[[1]]!=Inf]),2) KS.matrix= cbind(abs(rf1.perf@y.values[[1]]-rf1.perf@x.values[[1]]), rf1.perf@alpha.values[[1]]) La distancia KS se calcula como: KS = abs(rf1.perf@y.values[[1]]-rf1.perf@x.values[[1]]) colnames(KS.matrix) &lt;- c(&quot;KS-distance&quot;,&quot;cut-point&quot;) head(KS.matrix) ## KS-distance cut-point ## [1,] 0.000000000 0.7800000 ## [2,] 0.001497006 0.7826242 ## [3,] 0.002994012 0.7452204 ## [4,] 0.007994999 0.6750160 ## [5,] 0.006497993 0.6717595 ## [6,] 0.005000987 0.6529603 ind.ks &lt;- sort( KS.matrix[,1] , index.return=TRUE )$ix[nrow(KS.matrix)] El punto de corte óptimo de KS rf1.KScutoff &lt;- KS.matrix[ind.ks,2] # := f(rf1.KS1) # 0.04 - 0.05 9.1.2 Gráfico de la Curva ROC y su métrica asociada Área bajo la curva ROC (AUC), para evaluar el poder de clasificación Tenemos dos maneras de calcular el área bajo la curva ROC: Cálculo de AUC mediante la función ‘performance’ rf1.auc1 &lt;- performance(rf1.pred,&quot;auc&quot;)@y.values[[1]] 0.737 - 0.738 Finalmente calculamos la curva ROC junto con la métrica AUC #win.graph() plot( rf1.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot;, xlab=&quot;Tasa de falsos positivos&quot; , ylab=&quot;Tasa de verdaderos positivos&quot;, main=&quot;Curva ROC modelo Random Forest&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4, 0.15 , c(paste0(&quot;AUC (Random Forest)=&quot;,round(rf1.auc1,4)),&quot;AUC (clasificaci?n al azar)=0.50&quot;),lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) Para realizar el mismo gráfico de la curva ROC utilizando la librería ggplot2 library(&quot;ggplot2&quot;) Generamos los datos en un data.frame df.perf &lt;- data.frame(x=rf1.perf@x.values[[1]],y=rf1.perf@y.values[[1]]) Costrucción del objeto gráfico con ggplot2 #win.graph() p &lt;- ggplot(df.perf,aes(x=x,y=y)) + geom_path(size=1, colour=&quot;red&quot;) p &lt;- p + ggtitle(&quot;Curva ROC modelo Random Forest&quot;) p &lt;- p + theme_update(plot.title = element_text(hjust = 0.5)) p &lt;- p + geom_segment(aes(x=0,y=0,xend=1,yend=1),colour=&quot;blue&quot;,linetype= 2) p &lt;- p + geom_text(aes(x=0.75 , y=0.3 , label=paste(sep =&quot;&quot;,&quot;AUC (Random Forest) ) = &quot;,round(rf1.auc1,4) )),colour=&quot;black&quot;,size=4) p &lt;- p + geom_text(aes(x=0.75 , y=0.25 , label=paste(sep =&quot;&quot;,&quot;AUC (Coin toss) = &quot;,round(0.50,4) )),colour=&quot;black&quot;,size=4) p &lt;- p + scale_x_continuous(name= &quot;Tasa de falsos positivos&quot;) p &lt;- p + scale_y_continuous(name= &quot;Tasa de verdaderos positivos&quot;) p &lt;- p + theme( plot.title = element_text(size = 2), axis.text.x = element_text(size = 10), axis.text.y = element_text(size = 10), axis.title.x = element_text(size = 12,face = &quot;italic&quot;), axis.title.y = element_text(size = 12,face = &quot;italic&quot;,angle=90), legend.title = element_blank(), panel.background = element_rect(fill = &quot;grey&quot;), panel.grid.minor = element_blank(), panel.grid.major = element_line(colour=&#39;white&#39;), plot.background = element_blank() ) Generamos el gráfico que hemos almacenado en la variable ‘p’: p Calculamos la predicción en el test y evaluamos el poder de clasificación del modelo rf1.pred_test &lt;- as.data.frame(predict( rf1, newdata = dt_test)) dt_test$pred_rf1 &lt;- rf1.pred_test$`predict(rf1, newdata = dt_test)` head(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.248381186 ## 12 1 1 1 2 1 42 29.620 1 0.220724924 ## 18 1 1 1 2 1 58 0.758 0 0.199511204 ## 21 1 1 2 &lt;NA&gt; 1 37 3.200 0 NA ## 22 2 2 1 2 1 39 0.230 0 0.008032649 ## 34 1 2 2 2 1 35 2.673 0 0.303488003 tail(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1326 1 2 2 2 1 19 3.269 0 0.001133968 ## 1328 1 2 3 2 1 71 0.505 0 0.625923580 ## 1330 2 2 2 2 1 33 1.535 0 0.001283937 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.431751239 ## 1339 1 2 2 1 1 18 3.277 0 0.003433201 summary(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## 4 : 10 Mean :31.31 ## NA&#39;s: 7 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00615 ## Median : 2.1645 Median :0.0000 Median :0.03819 ## Mean : 7.0917 Mean :0.1144 Mean :0.12815 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.22274 ## Max. :1067.6970 Max. :1.0000 Max. :0.78703 ## NA&#39;s :70 Con el test creamos un objeto de tipo ‘prediction’ dt_test.pred &lt;- prediction(as.numeric(rf1.pred_test$`predict(rf1, newdata = dt_test)`),dt_test$Y) dt_test.perf &lt;- performance(dt_test.pred,&quot;tpr&quot;,&quot;fpr&quot;) Evaluación del poder de clasificación del modelo RF1 vía curva ROC rf1.test.auc &lt;- performance(dt_test.pred ,&quot;auc&quot;)@y.values[[1]] Gráfico de la curva ROC para el test #win.graph() plot( dt_test.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot; , main=&quot;Curva ROC modelo RF - test&quot;,xlab=&quot;Tasa de falsos positivos&quot;, ylab=&quot;Tasa de verdaderos positivos&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4, 0.2 , c(paste0(&quot;AUC (Random Forest)=&quot;,round(rf1.test.auc,4)),&quot;AUC (Coin toss)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) 9.1.3 Métrica de error del clasificador RF: Error tipo I (\\(\\alpha\\)): 22.50%, indica el error que se comete clasificando una pérdida ‘severa’ como ‘no severa’ Error tipo II (\\(\\beta\\)): 43.15%, indica el error que se comete clasificando una pérdida ‘no severa’ como ‘severa’ % mala clasificación (\\(%mc\\)) : 40.66%, indica el % de veces que el modelo clasifica incorrectamente las pérdidas Accuracy = \\(100 - %\\): 59.34%, indica el % de veces que el modelo acierta clasificando las pérdidas Area bajo la curva ROC \\(AUC\\): 0.6988, medida global del poder de clasificación del modelo Finalmente calculamos la curva ROC junto con la métrica AUC Una función útil para obtener rápidamente el análisis de un clasificador binario es la siguiente: library(binaryLogic) metricBinaryClass( fitted.model = rf1 , dataset= dt_test , cutpoint=rf1.KScutoff , roc.graph=TRUE) ## $ClassError.tI ## [1] 22.5 ## ## $ClassError.tII ## [1] 44.52 ## ## $Accuracy ## [1] 58.13 ## ## $Sensitivity ## [1] 77.5 ## ## $Specificity ## [1] 55.48 ## ## $auc ## [1] 0.698887 ## ## $Fisher.F1 ## [1] 30.8458 metricBinaryClass(fitted.model = rf1 , dataset= dt_test , cutpoint=rf1.KScutoff , roc.graph=TRUE) ## $ClassError.tI ## [1] 22.5 ## ## $ClassError.tII ## [1] 44.52 ## ## $Accuracy ## [1] 58.13 ## ## $Sensitivity ## [1] 77.5 ## ## $Specificity ## [1] 55.48 ## ## $auc ## [1] 0.698887 ## ## $Fisher.F1 ## [1] 30.8458 9.1.4 Ejercicio propuesto: ¿Qué suecede con los errores de clasificación si cambiamos el punto de corte (cutpoint)? Tomar una serie de valores distintos para el parámetro cutpoint y graficar las distintas curvas ROC resultantes Graficar la superficie formada por los errores tipo I y tipo II versus el punto de corte ¿Qué valor minimiza ambos errores? "],
["b-entrenamiento-del-modelo-rf-regresion.html", "9.2 B. Entrenamiento del modelo RF-regresión", " 9.2 B. Entrenamiento del modelo RF-regresión fmla.rf2 &lt;- as.formula(paste0(&#39;LOSS&#39;,&#39;~&#39;,paste0(colnames(df_autobi[,-c(7,8)]),collapse = &quot;+&quot;),collapse = &#39;&#39;)) set.seed(112233) rf2 &lt;- randomForest( fmla.rf2, data =dt_train, ntree = 5000, replace =TRUE, mtry=4, maxnodes =50, importance = TRUE, na.action=na.omit) summary(rf2) ## Length Class Mode ## call 9 -none- call ## type 1 -none- character ## predicted 759 -none- numeric ## mse 5000 -none- numeric ## rsq 5000 -none- numeric ## oob.times 759 -none- numeric ## importance 12 -none- numeric ## importanceSD 6 -none- numeric ## localImportance 0 -none- NULL ## proximity 0 -none- NULL ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## forest 11 -none- list ## coefs 0 -none- NULL ## y 759 -none- numeric ## test 0 -none- NULL ## inbag 0 -none- NULL ## terms 3 terms call ## na.action 179 omit numeric str(rf2) ## List of 19 ## $ call : language randomForest(formula = fmla.rf2, data = dt_train, ntree = 5000, replace = TRUE, mtry = 4, maxnodes = 50, imp| __truncated__ ## $ type : chr &quot;regression&quot; ## $ predicted : atomic [1:759] 2.481 0.673 37.787 1.805 4.297 ... ## ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ mse : num [1:5000] 543 499 466 463 501 ... ## $ rsq : num [1:5000] -0.636 -0.504 -0.403 -0.395 -0.511 ... ## $ oob.times : int [1:759] 1830 1844 1839 1796 1845 1867 1829 1890 1824 1844 ... ## $ importance : num [1:6, 1:2] 18.05 2.03 -3.02 4.07 6.17 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..$ : chr [1:2] &quot;%IncMSE&quot; &quot;IncNodePurity&quot; ## $ importanceSD : Named num [1:6] 1.161 1.077 1.206 0.401 0.755 ... ## ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## $ localImportance: NULL ## $ proximity : NULL ## $ ntree : num 5000 ## $ mtry : num 4 ## $ forest :List of 11 ## ..$ ndbigtree : int [1:5000] 99 99 99 99 99 99 99 99 99 99 ... ## ..$ nodestatus : int [1:99, 1:5000] -3 -3 -3 -3 -3 -3 -3 -3 -1 -3 ... ## ..$ leftDaughter : int [1:99, 1:5000] 2 4 6 8 10 12 14 16 0 18 ... ## ..$ rightDaughter: int [1:99, 1:5000] 3 5 7 9 11 13 15 17 0 19 ... ## ..$ nodepred : num [1:99, 1:5000] 4.96 2.43 6.21 3.78 1.25 ... ## ..$ bestvar : int [1:99, 1:5000] 6 1 1 5 6 5 6 6 0 6 ... ## ..$ xbestsplit : num [1:99, 1:5000] 24.5 1.5 1.5 1.5 20.5 1.5 52.5 15.5 0 13.5 ... ## ..$ ncat : Named int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## ..$ nrnodes : int 99 ## ..$ ntree : num 5000 ## ..$ xlevels :List of 6 ## .. ..$ ATTORNEY: num 0 ## .. ..$ CLMSEX : num 0 ## .. ..$ MARITAL : num 0 ## .. ..$ CLMINSUR: num 0 ## .. ..$ SEATBELT: num 0 ## .. ..$ CLMAGE : num 0 ## $ coefs : NULL ## $ y : atomic [1:759] 10.892 0.33 11.037 0.138 3.538 ... ## ..- attr(*, &quot;na.action&quot;)=Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## $ test : NULL ## $ inbag : NULL ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language LOSS ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + SEATBELT + CLMAGE ## .. ..- attr(*, &quot;variables&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;factors&quot;)= int [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ... ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:7] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## .. .. .. ..$ : chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;term.labels&quot;)= chr [1:6] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;order&quot;)= int [1:6] 1 1 1 1 1 1 ## .. ..- attr(*, &quot;intercept&quot;)= num 0 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, SEATBELT, CLMAGE) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:7] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## $ na.action :Class &#39;omit&#39; Named int [1:179] 1 9 19 25 27 40 43 46 50 51 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:179] &quot;1&quot; &quot;10&quot; &quot;24&quot; &quot;30&quot; ... ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;randomForest.formula&quot; &quot;randomForest&quot; varImpPlot(rf2,sort = T,main=&quot;Variable Importance&quot;) rf2.prediction &lt;- as.data.frame(predict(rf2, newdata = dt_test)) dt_test$pred_rf2 &lt;- rf2.prediction[[1]] head(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.248381186 ## 12 1 1 1 2 1 42 29.620 1 0.220724924 ## 18 1 1 1 2 1 58 0.758 0 0.199511204 ## 21 1 1 2 &lt;NA&gt; 1 37 3.200 0 NA ## 22 2 2 1 2 1 39 0.230 0 0.008032649 ## 34 1 2 2 2 1 35 2.673 0 0.303488003 ## pred_rf2 ## 6 7.914495 ## 12 8.488978 ## 18 9.846624 ## 21 NA ## 22 2.412385 ## 34 8.022277 tail(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1326 1 2 2 2 1 19 3.269 0 0.001133968 ## 1328 1 2 3 2 1 71 0.505 0 0.625923580 ## 1330 2 2 2 2 1 33 1.535 0 0.001283937 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.431751239 ## 1339 1 2 2 1 1 18 3.277 0 0.003433201 ## pred_rf2 ## 1326 4.269137 ## 1328 10.602377 ## 1330 2.182710 ## 1336 NA ## 1337 36.665696 ## 1339 3.978978 summary(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## 4 : 10 Mean :31.31 ## NA&#39;s: 7 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 pred_rf2 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 Min. : 0.3916 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00615 1st Qu.: 2.0644 ## Median : 2.1645 Median :0.0000 Median :0.03819 Median : 3.4303 ## Mean : 7.0917 Mean :0.1144 Mean :0.12815 Mean : 6.3906 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.22274 3rd Qu.: 7.8241 ## Max. :1067.6970 Max. :1.0000 Max. :0.78703 Max. :57.5121 ## NA&#39;s :70 NA&#39;s :70 Graficamos la distribución de los valores estimados en el train plot(density(dt_test$pred_rf2[!is.na(dt_test$pred_rf2) &amp; dt_test$pred_rf2 &lt; 30]), ylim= c(0,.25) , col=&quot;red&quot; , main=&quot;&quot;) lines(density(dt_test$LOSS[dt_test$LOSS&lt;30]),col=&quot;blue&quot;,lty=1) modelchecktest1 &lt;- as.data.frame( cbind(real=dt_test$LOSS , predicted=dt_test$pred_rf2) ) modelchecktest1[is.na(modelchecktest1)] &lt;- 0 summary(modelchecktest1) ## real predicted ## Min. : 0.0050 Min. : 0.000 ## 1st Qu.: 0.5175 1st Qu.: 1.316 ## Median : 2.1645 Median : 2.414 ## Mean : 7.0917 Mean : 5.278 ## 3rd Qu.: 3.7782 3rd Qu.: 7.424 ## Max. :1067.6970 Max. :57.512 Error de ajuste del modelo plot(modelchecktest1, xlim=c(0,100) , ylim=c(0,100) , pch=&quot;.&quot; , cex=1.5) segments( 0, 0 , 100, 100 , col=&quot;red&quot;) modelMetrics(real=modelchecktest1$real, pred=modelchecktest1$predicted ) ## ------------------------------ ## Accuracy metrics (global): ## ------------------------------ ## MAE(ref) = 8.9208 ## MAE = 7.7751 ## RMSE = 54.5763 ## MAPE = 127.55 ## MAPE(sim) = 68.64 ## WMAPE = 109.64 ## ## ## Commentario: El error de ajuste del modelo de regresión es demasiado alto: \\(RMSE= 54.57\\) y el \\(MAPE=127.19%\\) Con estos errores de predicción, es preferible utilizar a un modelo de clasificación en lugar de un modelo de regresión. "],
["gradient-boosting-models.html", "Capítulo 10 Gradient Boosting Models ", " Capítulo 10 Gradient Boosting Models "],
["c-entrenamiento-del-modelo-gbm-clasificacion.html", "10.1 C. Entrenamiento del modelo GBM-clasificación", " 10.1 C. Entrenamiento del modelo GBM-clasificación if (!require(gbm)) install.packages(&#39;gbm&#39;) ## Loading required package: gbm ## Loading required package: survival ## ## Attaching package: &#39;survival&#39; ## The following object is masked from &#39;package:caret&#39;: ## ## cluster ## Loading required package: splines ## Loading required package: parallel ## Loaded gbm 2.1.3 library(gbm) Creamos un objeto de clase ‘formula’ y se lo pasamos como argumento a la función gbm xVars &lt;- colnames(AutoBi[ , -match(c(&quot;SEATBELT&quot;,&quot;CASENUM&quot;,&quot;LOSS&quot;), colnames(AutoBi)) ]) targets &lt;- c(&quot;LOSS&quot;,&quot;Y&quot;) fmla.gbm1 &lt;- as.formula(paste0(targets[2],&quot;~&quot;,paste0(xVars,collapse = &quot;+&quot;),collapse = &quot;&quot;)) set.seed(999) gbm1 &lt;- gbm(fmla.gbm1, data = dt_train, distribution=&quot;bernoulli&quot;, n.trees = 5000, interaction.depth = 3, n.minobsinnode = 20, shrinkage = 0.001 ) summary(gbm1) ## var rel.inf ## CLMAGE CLMAGE 40.705984 ## ATTORNEY ATTORNEY 26.230600 ## MARITAL MARITAL 23.253011 ## CLMSEX CLMSEX 5.331329 ## CLMINSUR CLMINSUR 4.479076 Como valor estimado se obtiene la probabilidad condicional $ P(Y=1|X_1=ATTORNEY,,X_6=SEATBELT)$ Miramos el resultado en el test: gbm1.prediction &lt;- as.data.frame(predict.gbm(gbm1, newdata = dt_train , n.trees = 5000 , type=&quot;response&quot;)) dt_train$pred_gbm1 &lt;- gbm1.prediction[[1]] Calculamos la medida de “performance” del mecanismo (modelo) de predicción ‘gbm1’ gbm1.pred &lt;- prediction(dt_train$pred_gbm1,dt_train$Y) # con el train creamos un gbm1.perf &lt;- performance(gbm1.pred,&quot;tpr&quot;,&quot;fpr&quot;) Calculamos el punto de corte gbm1.perf@alpha.values[[1]][gbm1.perf@alpha.values[[1]]==Inf] &lt;- round(max(gbm1.perf@alpha.values[[1]][gbm1.perf@alpha.values[[1]]!=Inf]),2) KS.matrix= cbind(abs(gbm1.perf@y.values[[1]]-gbm1.perf@x.values[[1]]), gbm1.perf@alpha.values[[1]]) colnames(KS.matrix) &lt;- c(&quot;KS-distance&quot;,&quot;cut-point&quot;) head(KS.matrix) ## KS-distance cut-point ## [1,] 0.000000000 0.4900000 ## [2,] 0.009345794 0.4940501 ## [3,] 0.018691589 0.4661792 ## [4,] 0.028037383 0.4474047 ## [5,] 0.037383178 0.4411769 ## [6,] 0.046728972 0.4358773 ind.ks &lt;- sort( KS.matrix[,1] , index.return=TRUE )$ix[nrow(KS.matrix)] El punto de corte óptimo de KS gbm1.KScutoff &lt;- KS.matrix[ind.ks,2] (Opcional) Area bajo la curva ROC gbm1.auc &lt;- performance(gbm1.pred ,&quot;auc&quot;)@y.values[[1]] (opcional) Curva ROC GBM - train #win.graph() plot( gbm1.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot; , main=&quot;Curva ROC modelo GBM&quot;,xlab=&quot;Tasa de falsos positivos&quot;, ylab=&quot;Tasa de verdaderos positivos&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4 , 0.2 , c(paste0(&quot;AUC (Gradient Boosting)=&quot;,round(gbm1.auc,4)),&quot;AUC (Coin toss)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) Calculamos la predicción en el test y evaluamos el poder de clasificación del modelo gbm1.pred_test &lt;- as.data.frame(predict.gbm( gbm1, newdata = dt_test , n.trees = 5000 , type = &quot;response&quot;)) dt_test$pred_gbm1 &lt;- gbm1.pred_test[[1]] Con el test creamos un objeto de tipo ‘prediction’ dt_gbm1.pred &lt;- prediction(dt_test$pred_gbm1,dt_test$Y) dt_gbm1.perf &lt;- performance(dt_gbm1.pred,&quot;tpr&quot;,&quot;fpr&quot;) Evaluación del poder de clasificaci?n del modelo GBM1 vía curva ROC gbm1.auc_test &lt;- performance( dt_gbm1.pred ,&quot;auc&quot;)@y.values[[1]] Error tipo I (\\(\\alpha\\)): 10.87% indica el error que se comete clasificando una pérdida ‘severa’ como ‘no severa’ Error tipo II (\\(\\beta\\)): 39.89% indica el error que se comete clasificando una pérdida ‘no severa’ como ‘severa’ % de mala clasificación: 35.81% nos da el % de veces que el modelo clasifica incorrectamente las pérdidas Accuracy = \\(100 - %mc\\): 63.43% nos da el % de veces que el modelo acierta clasificando las pérdidas Area bajo la curva ROC, \\(AUC\\): 0.7583 nos da una medida global del poder de clasificación del modelo Finalmente calculamos la curva ROC junto con la métrica AUC Evaluamos el poder de clasificación con la función metricBinaryClass: metricBinaryClass( fitted.model = gbm1 , dataset= dt_test , cutpoint=gbm1.KScutoff , roc.graph=TRUE) ## $ClassError.tI ## [1] 10.87 ## ## $ClassError.tII ## [1] 39.89 ## ## $Accuracy ## [1] 63.43 ## ## $Sensitivity ## [1] 89.13 ## ## $Specificity ## [1] 60.11 ## ## $auc ## [1] 0.7582743 ## ## $Fisher.F1 ## [1] 35.8079 "],
["d-entrenamiento-del-modelo-gbm-regresion.html", "10.2 D. Entrenamiento del modelo GBM-regresión", " 10.2 D. Entrenamiento del modelo GBM-regresión fmla.gbm2 &lt;- as.formula(paste0(targets[1],&quot;~&quot;,paste0(xVars,collapse = &quot;+&quot;),collapse = &quot;&quot;)) set.seed(1234) gbm2 &lt;- gbm(fmla.gbm2, data = dt_train, distribution=&quot;gaussian&quot;, n.trees = 5000, interaction.depth = 3, n.minobsinnode = 20, #keep.data = TRUE, #n.cores = 4, shrinkage = 0.001 ) summary(gbm2) ## var rel.inf ## CLMAGE CLMAGE 64.8214435 ## ATTORNEY ATTORNEY 23.3523204 ## CLMSEX CLMSEX 6.3215371 ## MARITAL MARITAL 4.7362733 ## CLMINSUR CLMINSUR 0.7684257 str(gbm2) ## List of 27 ## $ initF : num 5.47 ## $ fit : num [1:938] 11.97 2.05 1.35 10.23 1.61 ... ## $ train.error : num [1:5000] 319 319 319 319 319 ... ## $ valid.error : num [1:5000] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... ## $ oobag.improve : num [1:5000] 0.0145 0.012 0.03 0.0255 0.0247 ... ## $ trees :List of 5000 ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 45.5 0.0021 50.5 0.0278 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7900 4925 0 6911 0 ... ## .. ..$ : num [1:10] 469 240 163 50 20 30 50 27 229 469 ## .. ..$ : num [1:10] 0.000864 0.004873 0.002096 0.013409 0.027808 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 44 -0.000232 49.5 0.028103 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5298 7330 0 7143 0 ... ## .. ..$ : num [1:10] 469 237 149 57 20 37 57 31 232 469 ## .. ..$ : num [1:10] -0.000325 0.003 -0.000232 0.012877 0.028103 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 2 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 0.5 45.5 0.00533 0.01206 ... ## .. ..$ : int [1:10] 1 2 3 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 6 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 5 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3720 2928 1788 0 0 ... ## .. ..$ : num [1:10] 469 239 104 63 29 12 133 2 230 469 ## .. ..$ : num [1:10] -8.76e-05 2.92e-03 7.46e-03 5.33e-03 1.21e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00161 27.5 0.01629 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7053 2517 0 3592 0 ... ## .. ..$ : num [1:10] 469 234 53 151 29 122 151 30 235 469 ## .. ..$ : num [1:10] 0.000563 0.004449 -0.001607 0.006285 0.016288 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 22.5 -0.000873 39.5 0.004771 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3299 1078 0 237 0 ... ## .. ..$ : num [1:10] 469 234 69 143 70 73 143 22 235 469 ## .. ..$ : num [1:10] -0.000913 0.001745 -0.000873 0.003456 0.004771 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00115 39.5 0.00521 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2849 943 0 777 0 ... ## .. ..$ : num [1:10] 469 236 57 149 86 63 149 30 233 469 ## .. ..$ : num [1:10] -0.000706 0.001743 -0.001153 0.003258 0.005213 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00191 25.5 0.01062 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3587 1657 0 1270 0 ... ## .. ..$ : num [1:10] 469 240 57 157 23 134 157 26 229 469 ## .. ..$ : num [1:10] -0.000858 0.001844 -0.001908 0.003752 0.010618 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 36.5 -0.00105 49.5 0.0134 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4957 6725 0 2773 0 ... ## .. ..$ : num [1:10] 469 242 115 91 64 27 91 36 227 469 ## .. ..$ : num [1:10] -0.000127 0.003022 -0.001051 0.009813 0.013398 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00219 26.5 0.01675 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6019 2933 0 2899 0 ... ## .. ..$ : num [1:10] 469 238 52 161 21 140 161 25 231 469 ## .. ..$ : num [1:10] -0.000146 0.003384 -0.002187 0.005793 0.01675 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00182 29.5 0.0169 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6574 3062 0 3460 0 ... ## .. ..$ : num [1:10] 469 236 64 147 25 122 147 25 233 469 ## .. ..$ : num [1:10] 0.000358 0.004078 -0.00182 0.006184 0.016901 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 2 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00178 0.5 0.00216 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3441 2088 0 1571 0 ... ## .. ..$ : num [1:10] 469 241 59 154 87 66 1 28 228 469 ## .. ..$ : num [1:10] -0.000414 0.00217 -0.001777 0.004322 0.002157 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 23.5 -0.00141 28.5 0.01508 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7256 3999 0 1637 0 ... ## .. ..$ : num [1:10] 469 243 72 143 23 120 143 28 226 469 ## .. ..$ : num [1:10] 0.00104 0.00483 -0.00141 0.00735 0.01508 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00221 0.5 0.01001 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4863 2877 0 2941 0 ... ## .. ..$ : num [1:10] 469 240 56 165 80 84 1 19 229 469 ## .. ..$ : num [1:10] 0.000374 0.00369 -0.002208 0.005691 0.010006 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.00151 45.5 0.00491 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7366 3591 0 1414 0 ... ## .. ..$ : num [1:10] 469 240 68 139 88 51 139 33 229 469 ## .. ..$ : num [1:10] 0.000652 0.004523 -0.001514 0.007339 0.004911 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00167 29.5 0.01367 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4437 2093 0 2468 0 ... ## .. ..$ : num [1:10] 469 235 71 139 26 113 139 25 234 469 ## .. ..$ : num [1:10] -0.00059 0.00248 -0.00167 0.00489 0.01367 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.0019 49.5 0.011 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7114 4988 0 2105 0 ... ## .. ..$ : num [1:10] 469 221 78 118 86 32 118 25 248 469 ## .. ..$ : num [1:10] 0.000296 0.004422 -0.001896 0.00838 0.010957 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00253 26.5 0.01587 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6340 3252 0 2387 0 ... ## .. ..$ : num [1:10] 469 234 48 161 22 139 161 25 235 469 ## .. ..$ : num [1:10] 2.93e-05 3.71e-03 -2.53e-03 6.19e-03 1.59e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.000471 28.5 0.015072 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5279 986 0 3005 0 ... ## .. ..$ : num [1:10] 469 243 60 148 22 126 148 35 226 469 ## .. ..$ : num [1:10] -0.000205 0.003031 -0.000471 0.004289 0.015072 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5.00e-01 3.55e+01 3.69e-04 4.95e+01 1.29e-02 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6863 3955 0 2461 0 ... ## .. ..$ : num [1:10] 469 243 119 98 59 39 98 26 226 469 ## .. ..$ : num [1:10] 0.000704 0.004393 0.000369 0.008873 0.012947 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00239 29.5 0.01112 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6181 3050 0 1501 0 ... ## .. ..$ : num [1:10] 469 235 62 148 35 113 148 25 234 469 ## .. ..$ : num [1:10] -7.18e-05 3.55e-03 -2.39e-03 5.40e-03 1.11e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 44.5 0.00136 50.5 0.02481 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6180 3686 0 7293 0 ... ## .. ..$ : num [1:10] 469 238 153 53 22 31 53 32 231 469 ## .. ..$ : num [1:10] 0.000513 0.004089 0.001363 0.010884 0.024809 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.0015 27.5 0.00768 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2605 737 0 981 0 ... ## .. ..$ : num [1:10] 469 236 62 146 28 118 146 28 233 469 ## .. ..$ : num [1:10] -0.001365 0.000977 -0.001498 0.002354 0.007676 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00257 0.5 0.01423 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 9717 5060 0 3501 0 ... ## .. ..$ : num [1:10] 469 230 55 147 63 82 2 28 239 469 ## .. ..$ : num [1:10] 0.00108 0.00576 -0.00257 0.00881 0.01423 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 48.5 28.5 -0.00108 0.00235 ... ## .. ..$ : int [1:10] 1 2 3 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 6 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 5 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3136 3340 485 0 0 ... ## .. ..$ : num [1:10] 469 234 165 87 78 165 37 32 235 469 ## .. ..$ : num [1:10] -0.000687 0.001904 0.000541 -0.001083 0.002351 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.003 27.5 0.00866 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2682 1364 0 1329 0 ... ## .. ..$ : num [1:10] 469 233 49 160 31 129 160 24 236 469 ## .. ..$ : num [1:10] -0.00122 0.00119 -0.003 0.00278 0.00866 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00125 0.5 0.0123 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5828 3937 0 2946 0 ... ## .. ..$ : num [1:10] 469 229 65 132 63 68 1 32 240 469 ## .. ..$ : num [1:10] 0.00026 0.00389 -0.00125 0.00748 0.0123 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 2 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 19.5 -0.002443 0.5 -0.000531 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2448 2049 0 761 0 ... ## .. ..$ : num [1:10] 469 232 46 161 101 59 1 25 237 469 ## .. ..$ : num [1:10] -0.001076 0.001241 -0.002443 0.001122 -0.000531 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 19.5 -0.0034 26.5 0.0124 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4740 2323 0 2284 0 ... ## .. ..$ : num [1:10] 469 229 46 158 27 131 158 25 240 469 ## .. ..$ : num [1:10] -0.000457 0.002797 -0.003401 0.004044 0.012419 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00224 46.5 0.0085 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4334 3446 0 2334 0 ... ## .. ..$ : num [1:10] 469 240 57 151 100 51 151 32 229 469 ## .. ..$ : num [1:10] -0.000184 0.002785 -0.002242 0.005694 0.008501 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 26.5 -0.00172 0.5 0.0091 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4774 2261 0 1515 0 ... ## .. ..$ : num [1:10] 469 223 70 127 54 73 127 26 246 469 ## .. ..$ : num [1:10] -0.000366 0.002985 -0.001721 0.005081 0.009097 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 2 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 19.5 -0.00307 0.5 0.00207 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4113 1878 0 1462 0 ... ## .. ..$ : num [1:10] 469 224 42 162 98 63 1 20 245 469 ## .. ..$ : num [1:10] -0.000868 0.00217 -0.003068 0.003881 0.002071 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00251 45.5 0.00707 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 9162 6704 0 2249 0 ... ## .. ..$ : num [1:10] 469 233 52 150 110 40 150 31 236 469 ## .. ..$ : num [1:10] 0.000991 0.005439 -0.002506 0.009404 0.007069 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.00157 39.5 0.00762 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4671 1901 0 1382 0 ... ## .. ..$ : num [1:10] 469 240 67 147 70 77 147 26 229 469 ## .. ..$ : num [1:10] -0.000188 0.002895 -0.001572 0.004405 0.007621 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5.00e-01 4.45e+01 7.67e-05 5.15e+01 2.27e-02 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4479 4459 0 6005 0 ... ## .. ..$ : num [1:10] 469 237 154 51 23 28 51 32 232 469 ## .. ..$ : num [1:10] -6.34e-05 2.99e-03 7.67e-05 1.07e-02 2.27e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00115 50.5 0.01146 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 12508 4407 0 2265 0 ... ## .. ..$ : num [1:10] 469 231 55 148 112 36 148 28 238 469 ## .. ..$ : num [1:10] 0.00139 0.00664 -0.00115 0.00924 0.01146 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00171 38.5 0.00453 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6772 4302 0 1051 0 ... ## .. ..$ : num [1:10] 469 242 56 151 74 77 151 35 227 469 ## .. ..$ : num [1:10] 0.000271 0.003951 -0.00171 0.007221 0.00453 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 28.5 -0.00174 39.5 0.00709 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4184 2238 0 529 0 ... ## .. ..$ : num [1:10] 469 231 84 118 45 73 118 29 238 469 ## .. ..$ : num [1:10] -0.000693 0.002339 -0.001738 0.004398 0.007094 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 2 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00262 0.5 0.00277 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3121 1286 0 695 0 ... ## .. ..$ : num [1:10] 469 241 56 153 100 52 1 32 228 469 ## .. ..$ : num [1:10] -0.00122 0.00124 -0.00262 0.00277 0.00277 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00279 26.5 0.01398 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3222 1607 0 2974 0 ... ## .. ..$ : num [1:10] 469 219 46 149 23 126 149 24 250 469 ## .. ..$ : num [1:10] -0.00111 0.0017 -0.00279 0.00352 0.01398 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00194 27.5 0.02064 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 8382 4599 0 3920 0 ... ## .. ..$ : num [1:10] 469 232 54 153 22 131 153 25 237 469 ## .. ..$ : num [1:10] 0.000875 0.005148 -0.001937 0.008287 0.020639 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.000762 46.5 0.006156 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6943 1982 0 672 0 ... ## .. ..$ : num [1:10] 469 237 51 166 118 48 166 20 232 469 ## .. ..$ : num [1:10] 0.000279 0.004086 -0.000762 0.004873 0.006156 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00184 25.5 0.01085 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2753 1208 0 1409 0 ... ## .. ..$ : num [1:10] 469 242 60 156 21 135 156 26 227 469 ## .. ..$ : num [1:10] -0.000741 0.001605 -0.001844 0.003229 0.01085 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.0013 29.5 0.0162 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5927 2328 0 3352 0 ... ## .. ..$ : num [1:10] 469 238 64 144 26 118 144 30 231 469 ## .. ..$ : num [1:10] 0.000301 0.003804 -0.001303 0.005915 0.016193 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00183 0.5 0.00948 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6121 2674 0 1992 0 ... ## .. ..$ : num [1:10] 469 249 55 167 74 92 1 27 220 469 ## .. ..$ : num [1:10] 0.000837 0.004251 -0.00183 0.0057 0.009478 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 23.5 -0.00168 49.5 0.00946 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6900 4415 0 1804 0 ... ## .. ..$ : num [1:10] 469 231 64 151 116 35 151 16 238 469 ## .. ..$ : num [1:10] 0.000697 0.004809 -0.001679 0.007559 0.009458 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00157 49.5 0.0114 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 9300 4591 0 3335 0 ... ## .. ..$ : num [1:10] 469 240 63 144 108 36 144 33 229 469 ## .. ..$ : num [1:10] 0.00134 0.00568 -0.00157 0.00862 0.0114 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00182 45.5 0.00567 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 8558 4067 0 1561 0 ... ## .. ..$ : num [1:10] 469 231 59 143 95 48 143 29 238 469 ## .. ..$ : num [1:10] 0.000917 0.005253 -0.001824 0.008022 0.005673 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 44.5 0.00122 50.5 0.02602 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5505 4003 0 7407 0 ... ## .. ..$ : num [1:10] 469 240 175 46 20 26 46 19 229 469 ## .. ..$ : num [1:10] -0.000079 0.003367 0.001216 0.011548 0.026016 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 45.5 0.00159 50.5 0.02638 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7504 4850 0 6132 0 ... ## .. ..$ : num [1:10] 469 230 157 50 20 30 50 23 239 469 ## .. ..$ : num [1:10] 0.000405 0.004482 0.001587 0.012813 0.026376 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 44.5 0.00146 50.5 0.01977 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5981 2849 0 3758 0 ... ## .. ..$ : num [1:10] 469 221 152 44 21 23 44 25 248 469 ## .. ..$ : num [1:10] 3.83e-05 3.82e-03 1.46e-03 1.01e-02 1.98e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 23.5 -0.00212 29.5 0.01625 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6405 3273 0 2848 0 ... ## .. ..$ : num [1:10] 469 238 66 144 24 120 144 28 231 469 ## .. ..$ : num [1:10] 0.000197 0.003838 -0.002121 0.006307 0.01625 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00197 49.5 0.00906 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 8136 3737 0 1609 0 ... ## .. ..$ : num [1:10] 469 250 56 166 131 35 166 28 219 469 ## .. ..$ : num [1:10] 0.00129 0.00518 -0.00197 0.00745 0.00906 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 19.5 -0.00199 0.5 0.00699 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4726 1601 0 1119 0 ... ## .. ..$ : num [1:10] 469 242 54 157 74 83 157 31 227 469 ## .. ..$ : num [1:10] -0.000267 0.002807 -0.00199 0.004164 0.006992 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00158 26.5 0.0197 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5529 1767 0 5991 0 ... ## .. ..$ : num [1:10] 469 238 44 164 24 140 164 30 231 469 ## .. ..$ : num [1:10] -5.26e-05 3.33e-03 -1.58e-03 5.11e-03 1.97e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00199 49.5 0.00951 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 8382 4196 0 1925 0 ... ## .. ..$ : num [1:10] 469 245 49 169 132 37 169 27 224 469 ## .. ..$ : num [1:10] 0.000944 0.004986 -0.001988 0.007725 0.009512 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.000801 27.5 0.01522 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5188 2594 0 3272 0 ... ## .. ..$ : num [1:10] 469 232 53 150 32 118 150 29 237 469 ## .. ..$ : num [1:10] 0.000417 0.003779 -0.000801 0.006251 0.01522 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00174 0.5 0.00621 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5098 1840 0 581 0 ... ## .. ..$ : num [1:10] 469 244 51 161 78 82 1 32 225 469 ## .. ..$ : num [1:10] 0.000221 0.003403 -0.001735 0.004363 0.006206 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 1 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 0.5 20.5 -0.000393 0.011328 ... ## .. ..$ : int [1:10] 1 2 3 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 6 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 5 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6347 1967 3348 0 0 ... ## .. ..$ : num [1:10] 469 230 107 27 67 13 118 5 239 469 ## .. ..$ : num [1:10] 0.0004 0.004429 0.007961 -0.000393 0.011328 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 2 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 0.5 39.5 0.005 -0.00034 ... ## .. ..$ : int [1:10] 1 2 3 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 6 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 5 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 1927 720 903 0 0 ... ## .. ..$ : num [1:10] 469 240 121 45 64 12 117 2 229 469 ## .. ..$ : num [1:10] -0.001538 0.000364 0.001864 0.004999 -0.00034 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 45.5 0.0019 52.5 0.023 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6371 2295 0 6939 0 ... ## .. ..$ : num [1:10] 469 238 166 48 21 27 48 24 231 469 ## .. ..$ : num [1:10] 0.000272 0.003903 0.001904 0.009354 0.022987 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5.00e-01 3.85e+01 7.21e-04 4.95e+01 1.64e-02 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7752 4706 0 3177 0 ... ## .. ..$ : num [1:10] 469 233 128 80 42 38 80 25 236 469 ## .. ..$ : num [1:10] 0.000551 0.004643 0.000721 0.010425 0.016419 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 2 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.000873 0.5 0.001113 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2671 770 0 862 0 ... ## .. ..$ : num [1:10] 469 245 53 164 103 59 2 28 224 469 ## .. ..$ : num [1:10] -0.000825 0.001416 -0.000873 0.002617 0.001113 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.000896 26.5 0.014155 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5980 1908 0 2064 0 ... ## .. ..$ : num [1:10] 469 239 57 157 24 133 157 25 230 469 ## .. ..$ : num [1:10] 0.000126 0.003628 -0.000896 0.005619 0.014155 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.00112 0.5 0.00568 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3806 1804 0 667 0 ... ## .. ..$ : num [1:10] 469 235 76 135 62 73 135 24 234 469 ## .. ..$ : num [1:10] -0.000509 0.002334 -0.001122 0.003266 0.005678 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00142 29.5 0.01399 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4471 1815 0 2557 0 ... ## .. ..$ : num [1:10] 469 238 68 139 23 116 139 31 231 469 ## .. ..$ : num [1:10] -0.000158 0.002884 -0.001423 0.004354 0.013985 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5.00e-01 3.55e+01 5.24e-04 4.95e+01 1.32e-02 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5840 4095 0 3328 0 ... ## .. ..$ : num [1:10] 469 232 111 90 62 28 90 31 237 469 ## .. ..$ : num [1:10] 0.000298 0.003865 0.000524 0.009142 0.013228 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00228 0.5 0.00852 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4674 2474 0 1427 0 ... ## .. ..$ : num [1:10] 469 235 50 152 69 81 2 33 234 469 ## .. ..$ : num [1:10] -0.000267 0.002914 -0.002284 0.005304 0.008521 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00187 26.5 0.01551 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 7871 3472 0 2850 0 ... ## .. ..$ : num [1:10] 469 239 57 157 29 128 157 25 230 469 ## .. ..$ : num [1:10] 0.000786 0.004805 -0.001875 0.006556 0.015507 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5.00e-01 4.45e+01 3.92e-04 4.95e+01 2.05e-02 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5388 4875 0 3937 0 ... ## .. ..$ : num [1:10] 469 238 157 51 24 27 51 30 231 469 ## .. ..$ : num [1:10] 0.000172 0.003512 0.000392 0.011231 0.02055 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 41.5 -0.000539 50.5 0.009554 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3475 2528 0 1065 0 ... ## .. ..$ : num [1:10] 469 227 138 60 30 30 60 29 242 469 ## .. ..$ : num [1:10] -0.000732 0.002079 -0.000539 0.005341 0.009554 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.00148 44.5 0.00499 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6017 4135 0 1416 0 ... ## .. ..$ : num [1:10] 469 228 76 128 86 42 128 24 241 469 ## .. ..$ : num [1:10] -0.000125 0.003557 -0.00148 0.007314 0.004989 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 28.5 -0.000812 39.5 0.006457 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2485 1281 0 554 0 ... ## .. ..$ : num [1:10] 469 225 85 112 48 64 112 28 244 469 ## .. ..$ : num [1:10] -0.000904 0.001493 -0.000812 0.003889 0.006457 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 1 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 0.5 -0.000366 45.5 0.001928 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4469 1922 0 3291 0 ... ## .. ..$ : num [1:10] 469 244 113 129 90 21 18 2 225 469 ## .. ..$ : num [1:10] -0.00065 0.002072 -0.000366 0.004207 0.001928 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.002 26.5 0.0189 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5853 3523 0 3943 0 ... ## .. ..$ : num [1:10] 469 229 53 148 23 125 148 28 240 469 ## .. ..$ : num [1:10] 0.000382 0.003999 -0.002004 0.006863 0.018897 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00252 26.5 0.01704 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5228 2836 0 4811 0 ... ## .. ..$ : num [1:10] 469 231 50 158 26 132 158 23 238 469 ## .. ..$ : num [1:10] 0.000166 0.003555 -0.002517 0.004608 0.017041 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00177 50.5 0.00627 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3484 2429 0 692 0 ... ## .. ..$ : num [1:10] 469 233 68 133 109 24 133 32 236 469 ## .. ..$ : num [1:10] -0.000312 0.002431 -0.001767 0.005197 0.006268 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00138 27.5 0.02008 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6832 4003 0 4887 0 ... ## .. ..$ : num [1:10] 469 233 53 153 26 127 153 27 236 469 ## .. ..$ : num [1:10] 0.000753 0.004594 -0.001382 0.007587 0.020079 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00219 25.5 0.01141 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3364 1359 0 1700 0 ... ## .. ..$ : num [1:10] 469 238 55 161 23 138 161 22 231 469 ## .. ..$ : num [1:10] -0.00077 0.00187 -0.00219 0.00345 0.01141 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00112 0.5 0.00963 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4814 2767 0 2209 0 ... ## .. ..$ : num [1:10] 469 236 50 158 73 84 1 28 233 469 ## .. ..$ : num [1:10] 7.27e-05 3.28e-03 -1.12e-03 5.69e-03 9.63e-03 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.00121 49.5 0.01287 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 11851 5654 0 3121 0 ... ## .. ..$ : num [1:10] 469 226 68 134 97 37 134 24 243 469 ## .. ..$ : num [1:10] 0.00117 0.00638 -0.00121 0.00989 0.01287 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 2 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 26.5 -0.001349 0.5 0.000432 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2667 1337 0 832 0 ... ## .. ..$ : num [1:10] 469 229 71 129 85 44 129 29 240 469 ## .. ..$ : num [1:10] -0.000778 0.001663 -0.001349 0.002259 0.000432 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 1 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 0.5 27.5 0.01095 0.00458 ... ## .. ..$ : int [1:10] 1 2 3 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 6 4 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 5 -1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4014 1634 2372 0 0 ... ## .. ..$ : num [1:10] 469 249 117 38 62 17 127 5 220 469 ## .. ..$ : num [1:10] 0.000493 0.003592 0.007004 0.010951 0.004585 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.00161 29.5 0.01189 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4077 2064 0 1530 0 ... ## .. ..$ : num [1:10] 469 243 73 143 24 119 143 27 226 469 ## .. ..$ : num [1:10] -0.00002 0.00282 -0.00161 0.0046 0.01189 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00184 48.5 0.00592 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5126 2071 0 623 0 ... ## .. ..$ : num [1:10] 469 231 51 154 118 36 154 26 238 469 ## .. ..$ : num [1:10] 0.000254 0.00361 -0.001838 0.004806 0.005917 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00159 26.5 0.01423 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4014 1539 0 3002 0 ... ## .. ..$ : num [1:10] 469 231 54 150 25 125 150 27 238 469 ## .. ..$ : num [1:10] 5.09e-05 3.02e-03 -1.59e-03 4.23e-03 1.42e-02 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 44.5 0.00211 49.5 0.0208 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 6951 3086 0 3960 0 ... ## .. ..$ : num [1:10] 469 231 147 52 23 29 52 32 238 469 ## .. ..$ : num [1:10] 0.000714 0.004621 0.002111 0.010999 0.020798 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 19.5 -0.00081 39.5 0.00481 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3887 767 0 677 0 ... ## .. ..$ : num [1:10] 469 243 47 164 82 82 164 32 226 469 ## .. ..$ : num [1:10] -0.000365 0.002411 -0.00081 0.002781 0.004812 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 24.5 -0.000711 48.5 0.008142 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4873 2528 0 1678 0 ... ## .. ..$ : num [1:10] 469 236 69 138 102 36 138 29 233 469 ## .. ..$ : num [1:10] 0.000112 0.003315 -0.000711 0.006071 0.008142 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00194 27.5 0.01144 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5845 2240 0 1166 0 ... ## .. ..$ : num [1:10] 469 234 53 149 24 125 149 32 235 469 ## .. ..$ : num [1:10] 0.000152 0.00369 -0.00194 0.005052 0.011436 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00181 0.5 0.00623 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4477 1884 0 736 0 ... ## .. ..$ : num [1:10] 469 232 57 152 74 78 152 23 237 469 ## .. ..$ : num [1:10] -0.000241 0.002882 -0.001807 0.00397 0.006229 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.0018 26.5 0.0141 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4589 1916 0 2345 0 ... ## .. ..$ : num [1:10] 469 219 46 144 24 120 144 29 250 469 ## .. ..$ : num [1:10] -0.000332 0.00301 -0.001795 0.005103 0.014126 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.0015 39.5 0.00756 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4207 2205 0 1284 0 ... ## .. ..$ : num [1:10] 469 234 74 132 64 68 132 28 235 469 ## .. ..$ : num [1:10] -0.00017 0.00283 -0.0015 0.00434 0.00756 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00207 26.5 0.01923 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3765 1796 0 5841 0 ... ## .. ..$ : num [1:10] 469 240 52 162 22 140 162 26 229 469 ## .. ..$ : num [1:10] -0.000577 0.002191 -0.002068 0.00408 0.019227 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 45.5 0.00215 51.5 0.0245 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 8359 4833 0 5478 0 ... ## .. ..$ : num [1:10] 469 225 153 50 23 27 50 22 244 469 ## .. ..$ : num [1:10] 0.000826 0.005222 0.002152 0.013157 0.024498 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 36.5 -0.000845 40.5 0.009234 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 2374 1487 0 1600 0 ... ## .. ..$ : num [1:10] 469 230 119 86 24 62 86 25 239 469 ## .. ..$ : num [1:10] -0.001093 0.001201 -0.000845 0.002302 0.009234 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00203 46.5 0.00808 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 4934 3277 0 1289 0 ... ## .. ..$ : num [1:10] 469 237 59 150 100 50 150 28 232 469 ## .. ..$ : num [1:10] -2.05e-05 3.19e-03 -2.03e-03 6.01e-03 8.08e-03 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 20.5 -0.00171 26.5 0.01493 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3748 2231 0 3030 0 ... ## .. ..$ : num [1:10] 469 239 63 144 25 119 144 32 230 469 ## .. ..$ : num [1:10] -0.000313 0.002461 -0.00171 0.004922 0.01493 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 45.5 0.00106 50.5 0.02232 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 5609 3575 0 5289 0 ... ## .. ..$ : num [1:10] 469 237 159 49 21 28 49 29 232 469 ## .. ..$ : num [1:10] 0.000287 0.003708 0.001064 0.010325 0.022321 ... ## ..$ :List of 8 ## .. ..$ : int [1:10] 0 4 -1 1 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 0.5 25.5 -0.00171 0.5 0.00663 ... ## .. ..$ : int [1:10] 1 2 -1 4 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 8 3 -1 5 -1 -1 -1 -1 -1 -1 ## .. ..$ : int [1:10] 9 7 -1 6 -1 -1 -1 -1 -1 -1 ## .. ..$ : num [1:10] 3512 1862 0 915 0 ... ## .. ..$ : num [1:10] 469 237 72 133 68 65 133 32 232 469 ## .. ..$ : num [1:10] -0.000227 0.00248 -0.001714 0.004061 0.006625 ... ## .. [list output truncated] ## $ c.splits : list() ## $ bag.fraction : num 0.5 ## $ distribution :List of 1 ## ..$ name: chr &quot;gaussian&quot; ## $ interaction.depth: num 3 ## $ n.minobsinnode : num 20 ## $ num.classes : num 1 ## $ n.trees : num 5000 ## $ nTrain : num 938 ## $ train.fraction : num 1 ## $ response.name : chr &quot;LOSS&quot; ## $ shrinkage : num 0.001 ## $ var.levels :List of 5 ## ..$ : chr [1:2] &quot;1&quot; &quot;2&quot; ## ..$ : chr [1:2] &quot;1&quot; &quot;2&quot; ## ..$ : chr [1:4] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ## ..$ : chr [1:2] &quot;1&quot; &quot;2&quot; ## ..$ : Named num [1:11] 0 13 18 21.9 27 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;0%&quot; &quot;10%&quot; &quot;20%&quot; &quot;30%&quot; ... ## $ var.monotone : num [1:5] 0 0 0 0 0 ## $ var.names : chr [1:5] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## $ var.type : num [1:5] 0 0 0 0 0 ## $ verbose : logi FALSE ## $ data :List of 6 ## ..$ y : Named num [1:938] 34.94 10.892 0.33 11.037 0.138 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:938] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## ..$ x : num [1:4690] 0 1 1 0 1 0 0 1 1 0 ... ## ..$ x.order: num [1:938, 1:5] 0 3 5 6 9 11 16 17 18 22 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr [1:5] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## ..$ offset : logi NA ## ..$ Misc : logi NA ## ..$ w : num [1:938] 1 1 1 1 1 1 1 1 1 1 ... ## $ Terms :Classes &#39;terms&#39;, &#39;formula&#39; language LOSS ~ ATTORNEY + CLMSEX + MARITAL + CLMINSUR + CLMAGE ## .. ..- attr(*, &quot;variables&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, CLMAGE) ## .. ..- attr(*, &quot;factors&quot;)= int [1:6, 1:5] 0 1 0 0 0 0 0 0 1 0 ... ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:6] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## .. .. .. ..$ : chr [1:5] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;term.labels&quot;)= chr [1:5] &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; &quot;CLMINSUR&quot; ... ## .. ..- attr(*, &quot;order&quot;)= int [1:5] 1 1 1 1 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(LOSS, ATTORNEY, CLMSEX, MARITAL, CLMINSUR, CLMAGE) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:6] &quot;numeric&quot; &quot;ordered&quot; &quot;ordered&quot; &quot;ordered&quot; ... ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:6] &quot;LOSS&quot; &quot;ATTORNEY&quot; &quot;CLMSEX&quot; &quot;MARITAL&quot; ... ## $ cv.folds : num 0 ## $ call : language gbm(formula = fmla.gbm2, distribution = &quot;gaussian&quot;, data = dt_train, n.trees = 5000, interaction.depth = 3, | __truncated__ ## $ m : language model.frame(formula = fmla.gbm2, data = dt_train, drop.unused.levels = TRUE, na.action = function (object, ...) ... ## - attr(*, &quot;class&quot;)= chr &quot;gbm&quot; Como valor estimado se obtiene la esperanza condicional de la pérdida: \\(E(LOSS|X_1=ATTORNEY,...,X_6=SEATBELT)\\) Miramos el resultado en el test: gbm2.prediction &lt;- as.data.frame(predict.gbm(gbm2, newdata = dt_test , n.trees = 5000 , type=&quot;response&quot;)) dt_test$pred_gbm2 &lt;- gbm2.prediction[[1]] head(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 6 1 2 1 2 1 35 0.309 0 0.248381186 ## 12 1 1 1 2 1 42 29.620 1 0.220724924 ## 18 1 1 1 2 1 58 0.758 0 0.199511204 ## 21 1 1 2 &lt;NA&gt; 1 37 3.200 0 NA ## 22 2 2 1 2 1 39 0.230 0 0.008032649 ## 34 1 2 2 2 1 35 2.673 0 0.303488003 ## pred_rf2 pred_gbm1 pred_gbm2 ## 6 7.914495 0.25987576 7.028186 ## 12 8.488978 0.20385256 11.097263 ## 18 9.846624 0.20979586 9.715652 ## 21 NA 0.28165589 10.629112 ## 22 2.412385 0.04259158 2.166960 ## 34 8.022277 0.32816568 6.946712 tail(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE LOSS Y pred_rf1 ## 1326 1 2 2 2 1 19 3.269 0 0.001133968 ## 1328 1 2 3 2 1 71 0.505 0 0.625923580 ## 1330 2 2 2 2 1 33 1.535 0 0.001283937 ## 1336 2 1 2 2 1 NA 0.576 0 NA ## 1337 1 2 1 2 1 46 3.705 0 0.431751239 ## 1339 1 2 2 1 1 18 3.277 0 0.003433201 ## pred_rf2 pred_gbm1 pred_gbm2 ## 1326 4.269137 0.05474639 3.380333 ## 1328 10.602377 0.34634974 6.020655 ## 1330 2.182710 0.04427271 1.397027 ## 1336 NA 0.01755464 1.350616 ## 1337 36.665696 0.33197590 21.693446 ## 1339 3.978978 0.06891223 2.555850 summary(dt_test) ## ATTORNEY CLMSEX MARITAL CLMINSUR SEATBELT CLMAGE ## 1:214 1 :180 1 :185 1 : 43 1 :385 Min. : 0.00 ## 2:188 2 :219 2 :195 2 :346 2 : 5 1st Qu.:19.00 ## NA&#39;s: 3 3 : 5 NA&#39;s: 13 NA&#39;s: 12 Median :29.00 ## 4 : 10 Mean :31.31 ## NA&#39;s: 7 3rd Qu.:42.00 ## Max. :78.00 ## NA&#39;s :55 ## LOSS Y pred_rf1 pred_rf2 ## Min. : 0.0050 Min. :0.0000 Min. :0.00007 Min. : 0.3916 ## 1st Qu.: 0.5175 1st Qu.:0.0000 1st Qu.:0.00615 1st Qu.: 2.0644 ## Median : 2.1645 Median :0.0000 Median :0.03819 Median : 3.4303 ## Mean : 7.0917 Mean :0.1144 Mean :0.12815 Mean : 6.3906 ## 3rd Qu.: 3.7782 3rd Qu.:0.0000 3rd Qu.:0.22274 3rd Qu.: 7.8241 ## Max. :1067.6970 Max. :1.0000 Max. :0.78703 Max. :57.5121 ## NA&#39;s :70 NA&#39;s :70 ## pred_gbm1 pred_gbm2 ## Min. :0.01755 Min. : 0.5787 ## 1st Qu.:0.03389 1st Qu.: 1.8938 ## Median :0.05442 Median : 3.4468 ## Mean :0.10986 Mean : 5.5137 ## 3rd Qu.:0.18907 3rd Qu.: 8.6580 ## Max. :0.44740 Max. :21.6934 ## Graficamos la distribución de los valores estimados en el train plot(density(dt_test$pred_gbm2[!is.na(dt_test$pred_gbm2) &amp; dt_test$pred_gbm2 &lt; 30]), ylim= c(0,.25) , xlab=&quot;Predicted&quot;, col=&quot;red&quot; , main=&quot;&quot;) lines(density(dt_test$LOSS[dt_test$LOSS&lt;30]),col=&quot;blue&quot;,lty=1) lines(density(dt_test$pred_rf2[!is.na(dt_test$pred_rf2) &amp; dt_test$pred_rf2 &lt; 30]),col=&quot;darkgreen&quot;,lty=1) modelchecktest2 &lt;- as.data.frame( cbind(real=dt_test$LOSS , predicted=dt_test$pred_gbm2) ) modelchecktest2[is.na(modelchecktest2)] &lt;- 0 summary(modelchecktest2) ## real predicted ## Min. : 0.0050 Min. : 0.5787 ## 1st Qu.: 0.5175 1st Qu.: 1.8938 ## Median : 2.1645 Median : 3.4468 ## Mean : 7.0917 Mean : 5.5137 ## 3rd Qu.: 3.7782 3rd Qu.: 8.6580 ## Max. :1067.6970 Max. :21.6934 Error de ajuste del modelo plot(modelchecktest2, xlim=c(0,100) , ylim=c(0,100) , pch=&quot;.&quot; , cex=1.5) segments( 0, 0 , 100, 100 , col=&quot;red&quot;) modelMetrics(real=modelchecktest2$real, pred=modelchecktest2$predicted ) ## ------------------------------ ## Accuracy metrics (global): ## ------------------------------ ## MAE(ref) = 8.9208 ## MAE = 7.6492 ## RMSE = 53.8215 ## MAPE = 134.19 ## MAPE(sim) = 70.74 ## WMAPE = 107.86 ## ## ## Comentario: Al igual que en el caso del modelo de regresión RF2, el error de ajuste del modelo GBM2 demasiado alto: \\(RMSE= 53.82k\\) y el \\(MAPE=134.19%\\). Con estos errores, es preferible ir a un modelo de clasificación en lugar de un modelo de regresión. "],
["support-vector-machines.html", "Capítulo 11 Support Vector Machines ", " Capítulo 11 Support Vector Machines "],
["introduccion.html", "11.1 Introducción", " 11.1 Introducción Tienen su origen en los trabajos sobre teoría de aprendizaje estadístico realizados por Vapnik en los años 90. Son algoritmos utilizados para tanto para problemas de clasificación como de regresión. Se han utilizado con éxito en campos como: reconocimiento de imágenes, clasificación de textos, clasificación de proteínas, etc. Los algoritmos SVM se encuentran dentro de la familia de clasificadores lineales. Han ganando gran reconocimiento debido a sus solidos fundamentos teóricos. "],
["descripcion.html", "11.2 Descripción", " 11.2 Descripción Dado un conjunto separable \\[S=\\{ (\\overrightarrow{x_1},y_1), ((\\overrightarrow{x_2},y_2 ), \\ldots,((\\overrightarrow{x_l},y_l ) \\}\\] se define hiperplano de separación como una función lineal capaz de separar dicho conjunto sin error "],
["svm-clasificacion-ejemplo.html", "11.3 SVM-clasificación: ejemplo", " 11.3 SVM-clasificación: ejemplo if (!require(e1071)) install.packages(&#39;e1071&#39;) ## Loading required package: e1071 library(e1071) librería alternativa que también es muy utilizada if (!require(kernlab)) install.packages(&#39;kernlab&#39;) ## Loading required package: kernlab ## ## Attaching package: &#39;kernlab&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## alpha library(kernlab) Creamos la relación (fórmula) entre las variables fmla.svm &lt;- as.formula(paste0(targets[2],&quot;~&quot;,paste0( c(xVars,&quot;SEATBELT&quot;),collapse = &quot;+&quot;),collapse = &quot;&quot;)) Modelo exploratorio (sin ajustar parámetros): svm0 &lt;- svm( fmla.svm , data=dt_train , type=&quot;C-classification&quot;, cost=10, na.action = na.omit) Utilizamos la función na.index para recuperar las posiciones de todos los registros donde hay missings (NA’s, NULL’s, blanks) #ids_NAs &lt;- na.index(dt_test) Es necesario eliminar los valores missings (NA) de la variable a modelizar (target). Las posiciones están almacenadas en la variable ‘ids_NAs’ #real_target &lt;- data.frame( real = dt_test[ -ids_NAs , &#39;Y&#39;]) #predicted_target &lt;- data.frame(predicted = predict(svm0, dt_test)) #pred.svm0 &lt;- cbind( real_target , predicted_target ) #metricBinaryClass( fitted.model = NULL , dataset= pred.svm0 , cutpoint= NULL , roc.graph=FALSE) Este modelo ofrece un pobrísimo poder de clasificación. Hay que buscar un mejor modelo vía ‘tuning’ de los parámetros. A continuación vemos cómo realizar esto: Comparamos dos funciones kernel: ‘Base radial’ vs ‘sigmoide’ (no debemos utilizar el kernel ‘lineal’) t.ini &lt;- Sys.time() tuneSVMclass &lt;- tune(svm, fmla.svm, data = dt_train, ranges = list( kernel=&#39;sigmoid&#39;, gamma= seq(1,3,by=.5) , cost = seq(5,100,by=5)) , tune.control = tune.control( random = TRUE, sampling = &quot;bootstrap&quot;, sampling.aggregate = mean, nboot = 10, boot.size = 0.90, best.model = TRUE, performances = TRUE, error.fun = &#39;auc&#39;)) t.end &lt;- Sys.time() print(t.end-t.ini) ## Time difference of 2.58892 mins print(tuneSVMclass) ## ## Parameter tuning of &#39;svm&#39;: ## ## - sampling method: 10-fold cross validation ## ## - best parameters: ## kernel gamma cost ## sigmoid 1 5 ## ## - best performance: 11062.07 El mejor modelo de clasificación vía SVM tunedSVM1 &lt;- svm( fmla.svm , data=dt_train, type=&quot;C-classification&quot;, kernel=&#39;sigmoid&#39; , probability = TRUE , gamma= 1, cost =10 , na.action = na.omit) El mejor SVM se obtiene con un kernel de base radial predicted_target &lt;- as.data.frame(predict( tunedSVM1 , dt_test)) #pred.svm1 &lt;- as.data.frame(cbind( real_target , predicted_target )) #colnames(pred.svm1) &lt;- c(&#39;actual&#39;,&#39;predicted&#39;) #table( pred.svm1 ) Curva ROC SVM #metricBinaryClass( fitted.model = NULL , dataset= pred.svm1 , cutpoint= NULL , roc.graph=TRUE) #metricBinaryClass( fitted.model = tunedSVM1 , dataset= dt_test , cutpoint= NULL , roc.graph=TRUE) Evaluamos el poder de clasificación con la función ‘metricBinaryClass’: #metricBinaryClass( fitted.model = NULL , dataset= pred.svm.model , cutpoint= NULL , roc.graph=FALSE) Error tipo I (\\(\\alpha\\)) : 79.07% nos dice el error que se comete clasificando una pérdida ‘severa’ como ‘no severa’ Error tipo II (\\(\\beta\\)) : 10.73% nos dice el error que se comete clasificando una p?rdida ‘no severa’ como ‘severa’ % de mala clasificación : 19.58% nos da el % de veces que el modelo clasifica incorrectamente las pérdidas Accuracy = \\(100 -%mc\\) : 80.42% Area bajo la curva ROC, \\(AUC\\) : 0.55102 Finalmente calculamos la curva ROC junto con la métrica AUC "],
["f-entrenamiento-del-modelo-svm-regresion.html", "11.4 F. Entrenamiento del modelo SVM-regresión", " 11.4 F. Entrenamiento del modelo SVM-regresión Para entrenar el SVM - regresión vamos directamente a buscar el mojor modelo vía ‘tuning’ de los parámetros: Usando una función Kernel de base radial #t.ini &lt;- Sys.time() #tuneSVMreg &lt;- tune(svm, fmla.svm, data = dt_train, ranges = list(epsilon = seq(0,1,by=0.1), gamma= seq(0.1,3,by=0.1) , cost = seq(5,100, by=5) ), tune.control= tune.control(random = TRUE, nrepeat = 10, repeat.aggregate = mean, sampling = &quot;bootstrap&quot;, sampling.aggregate = mean, samling.dispersion = sd, cross = 10, fix = 2/3, nboot = 10, boot.size = 0.90, best.model = TRUE, performances = TRUE, error.fun = &#39;mse&#39;)) #t.end &lt;- Sys.time() #print(t.end-t.ini) El mejor modelo SVM "],
["incompleto.html", "Capítulo 12 Incompleto…", " Capítulo 12 Incompleto… 12.0.1 G. comparativa de modelos de clasificaci?n Realizamos una breve comparativa de los distintos m?todos de clasificaci?n de la p?rdidas: Error tipo I (alpha) : 79.07% nos dice el error que se comete clasificando una p?rdida ‘severa’ como ‘no severa’ Error tipo II (beta) : 10.73% nos dice el error que se comete clasificando una p?rdida ‘no severa’ como ‘severa’ % de mala clasificaci?n : 19.58% nos da el % de veces que el modelo clasifica incorrectamente las p?rdidas Accuracy = 100 -%mc : 80.42% Area bajo la curva ROC auc : 0.55102 Finalmente calculamos la curva ROC junto con la m?trica AUC 12.0.2 Curvas ROC #win.graph() plot( gbm1.perf , col=&#39;red&#39; , lwd=2, type=&quot;l&quot; , main=&quot;Curva ROC modelo GBM&quot;,xlab=&quot;Tasa de falsos positivos&quot;, ylab=&quot;Tasa de verdaderos positivos&quot;) abline( 0 , 1 , col=&quot;blue&quot; , lwd=2, lty=2) abline( 0 , 0 , 1 , col=&quot;gray40&quot; , lty=3) legend( 0.4 , 0.2 , c(paste0(&quot;AUC (Gradient Boosting)=&quot;,round(gbm1.auc,4)),&quot;AUC (Coin toss)=0.50&quot;) ,lty=c(1,2), lwd=c(2,2) ,col=c(&quot;red&quot;,&quot;blue&quot;), bty=&quot;n&quot;) 12.0.3 falta - Incompleto "],
["boosting.html", "Capítulo 13 Boosting ", " Capítulo 13 Boosting "],
["que-es-boosting.html", "13.1 ¿Qué es boosting?", " 13.1 ¿Qué es boosting? Es una familia de algoritmos de machine learning cuya idea es la de utilizar métodos de aprendizaje débiles (weak learners) para crear un método de aprendizaje fuerte con alto poder predictivo. Es uno de los algoritmos de aprendizaje que mayor impacto han tenido en los últimos 20 años. Robert E. Schapire y Yoav Freund recibieron el premio Gödel en 2003 por su trabajo sobre boosting. La mayoría de los ganadores recientes en Kaggle, utilizan boosting. Buscadores como Yahoo utilizan versiones propias de algoritmos de boosting. "],
["modelos-ensamblados.html", "13.2 Modelos ensamblados", " 13.2 Modelos ensamblados Los métodos de ensamblado de modelos usan múltiples algoritmos de aprendizaje para obtener un mejor poder predictivo del que se podría obtener con cada uno de los modelos por separado. Los más habituales: Bagging (Bootstrap Aggregating) Random Forest Boosting "],
["adaboost.html", "13.3 AdaBoost", " 13.3 AdaBoost 13.3.1 Idea intuitiva 13.3.2 Nomenclatura Sean \\(n\\) observaciones \\((x_1, y_1), ... , (x_n, y_n)\\) donde \\(x_i \\in \\mathcal{X}^p\\) , \\(y_i \\in \\{-1,+1\\}\\). Sea \\(h_t\\) un clasificador binario de forma que \\[h_t:\\mathcal{X}^p\\rightarrow \\{-1,+1\\}\\] Definimos las funciones \\[I(y_i \\ne h_t(x_i)) = \\begin{cases} 1, &amp; \\mbox{si } y_i \\neq h_t(x_i) \\\\ 0, &amp; \\mbox{si } y_i = h_t(x_i) \\end{cases}\\] \\[H_t(x_i) = sign\\left(\\sum_{t=1}^T \\alpha_t h_t(x_i)\\right) = \\begin{cases} 1, &amp; \\mbox{si } \\sum_{t=1}^T \\alpha_t h_t(x_i) &gt; 0 \\\\ -1, &amp; \\mbox{si } \\sum_{t=1}^T \\alpha_t h_t(x_i) &lt; 0 \\end{cases}\\] 13.3.3 AdaBoost. Algoritmo Inicializar: \\(\\omega_1^{(i)}=\\frac{1}{n} \\text{ con } i = 1, \\ldots , n\\) Repetir \\(t = 1, \\ldots, T\\): Seleccionar un clasificador \\(h_t(x_i)\\) para los datos de entrenamiento usando \\(\\omega_t^{(i)}\\) Calcular \\(\\alpha_t\\) Calcular \\(\\omega_{t+1}^{(i)} \\text{ para } i = 1, \\ldots, n\\) Modelo final: \\[H(x) = sign\\left(\\sum_{t=1}^T\\alpha_th_t(x)\\right)\\] "],
["funciones-de-perdida.html", "13.4 Funciones de pérdida", " 13.4 Funciones de pérdida Los algoritmos de aprendizaje persiguen minimizar una función de pérdida (loss function) cumpliendo unas hipótesis de partida. Como ejemplo, una regresión lineal simple busca la recta que mejor se ajuste a una nube de puntos. ¿En qué sentido? 13.4.1 Funciones de pérdida: Regresión lineal Una opción es utilizar el valor absoluto: \\[L(y,f(x)) = |y - f(x)| \\] Incrementa el error de forma lineal. No es derivable en todo punto Least Absolute Deviations Tradicionalmente se elige una pérdida cuadrática: \\[L(y,f(x)) = (y - f(x))^2 \\] Incrementa el error de forma cuadrática. Observaciones atípicas (outliers) contribuyen mucho al error. Es derivable en todo punto. 13.4.2 Funciones de pérdida: Clasificación. Clasificación errónea: \\(L(y, f(x)) = I(-yf(x) &gt; 0)\\) 13.4.3 Funciones de pérdida para clasificación. Clasificación errónea: \\(L(y, f(x)) = I(-yf(x) &gt; 0)\\) Pérdida exponencial: \\(L(y, f(x)) = exp\\{-y\\cdot f(x) \\}\\) 13.4.4 Pérdida exponencial Sea \\[E = \\sum_{i=1}^n exp\\{ -y_iH_t(x_i) \\}\\] Tal y como hemos construido el algoritmo, se tiene que \\[H_t(x_i)=\\sum_{j=1}^t\\alpha_jh_j(x_i)\\] \\[= \\alpha_th_t(x_i) + \\sum_{j=1}^{t-1}\\alpha_jh_j(x_i) \\] \\[= \\alpha_th_t(x_i) + H_{t-1}(x_i)\\] \\[H_t(x_i)= \\alpha_th_t(x_i) + H_{t-1}(x_i)\\] luego \\[E = \\sum_{i=1}^n exp\\{ -y_iH_t(x_i) \\} \\] \\[=\\sum_{i=1}^n exp\\{- y_i H_{t-1}(x_i) - y_i\\alpha_th_t(x_i) \\} \\] \\[= \\sum_{i=1}^n \\omega_t^{(i)} exp\\{ - y_i\\alpha_th_t(x_i) \\}\\] siendo \\(\\omega_t^{(i)} = exp\\{- y_i H_{t-1}(x_i) \\}\\) \\[E = \\sum_{i=1}^n \\omega_t^{(i)} exp\\{ - y_i\\alpha_th_t(x_i) \\}\\] Sean: \\(\\mathcal{B}_n\\) el conjunto de puntos bien clasificados. \\(\\mathcal{M}_n\\) el conjunto de puntos mal clasificados. podemos escribir \\[E = e^{-\\alpha_t}\\sum_{i\\in\\mathcal{B}_n} \\omega_t^{(i)} + e^{\\alpha_t} \\sum_{i\\in\\mathcal{M}_n} \\omega_t^{(i)}\\] \\[= (e^{\\alpha_t}-e^{-\\alpha_t})\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i) + e^{-\\alpha_t}\\sum_{i= 1}^n\\omega_t^{(i)}\\] \\[E = (e^{\\alpha_t}-e^{-\\alpha_t})\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i) + e^{-\\alpha_t}\\sum_{i= 1}^n\\omega_t^{(i)}\\] Si minimizamos respecto a \\(h_t(x_i)\\), el sumando de la derecha es constante, con lo que es equivalente a \\[\\hat{h}_t = \\underset{h_t}{\\arg\\min} \\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i)\\] \\[E = (e^{\\alpha_t}-e^{-\\alpha_t})\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i) + e^{-\\alpha_t}\\sum_{i= 1}^n\\omega_t^{(i)}\\] Minimizando respecto a \\(\\alpha_t\\): \\[\\frac{\\partial E}{\\partial \\alpha_t} = (e^{\\alpha_t} + e^{-\\alpha_t})\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i) - e^{-\\alpha_t}\\sum_{i= 1}^n\\omega_t^{(i)} = 0 \\] \\[\\Leftrightarrow \\frac{e^{\\alpha_t} + e^{-\\alpha_t}}{e^{-\\alpha_t}} = \\frac{\\sum_{i= 1}^n\\omega_t^{(i)}}{\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i)}\\] \\[\\Leftrightarrow 1 + e^{2\\alpha_t} = \\frac{\\sum_{i= 1}^n\\omega_t^{(i)}}{\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i)}\\] \\[\\Rightarrow 1 + e^{2\\alpha_t} = \\frac{\\sum_{i= 1}^n\\omega_t^{(i)}}{\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i)}\\] Por comodidad, llamemos \\(err_t = \\frac{\\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i)}{\\sum_{i= 1}^n\\omega_t^{(i)}}\\). Tenemos que \\[e^{2\\alpha_t} = \\frac{1-err_t}{err_t}\\] \\[\\alpha_t = \\frac{1}{2}\\ln \\left(\\frac{1-err_t}{err_t}\\right)\\] Ya tenemos dos de los elementos del algoritmo: \\[\\hat{h}_t(x_i) = \\underset{h_t(x_i)}{\\arg\\min} \\sum_{i= 1}^n\\omega_t^{(i)}I(h_t(x_i) \\neq y_i)\\] \\[\\alpha_t = \\frac{1}{2}\\ln \\left(\\frac{1-err_t}{err_t}\\right)\\] Nos falta deducir cómo se actualizan los pesos \\(\\omega_t^{(i)}\\) en cada iteración \\(t\\). Hace un momento hemos llegado a que \\[ \\omega_t^{(i)} = exp\\{- y_i H_{t-1}(x_i) \\}\\] Podemos escribir \\[ \\omega_{\\bf{t+1}}^{(i)} = exp\\{- y_i H_{t}(x_i) \\} = exp\\{- y_i (H_{t-1}(x_i) + \\alpha_t h_t) \\} \\] \\[= exp\\{- y_i (H_{t-1}(x_i))\\} exp\\{-y_i\\alpha_t h_t \\} \\] \\[\\omega_{\\bf{t+1}}^{(i)} = \\omega_t^{(i)} e^{-y_i\\alpha_t h_t }\\] "],
["algoritmo-adaboost-revisitado.html", "13.5 Algoritmo AdaBoost Revisitado", " 13.5 Algoritmo AdaBoost Revisitado Ya somos capaces de escribir el algoritmo AdaBoost al completo Inicializar: \\(\\omega_1^{(i)}=\\frac{1}{m} \\text{ con } i = 1, \\ldots , m\\) Repetir \\(t = 1, \\ldots, T\\): Seleccionar \\(h_t\\) tal que minimice el error: \\[err_t = \\frac{\\sum_{i=1}^n [\\omega_t^{(i)} \\cdot I(y_i \\neq h_t(x_i))]}{\\sum_{i=1}^n \\omega_t^{(i)}}\\] Calcular \\[\\alpha_t = \\frac{1}{2}\\ln \\left(\\frac{1-err_t}{err_t}\\right)\\] Actualizar los pesos, \\[\\omega_{\\bf{t+1}}^{(i)} = \\omega_t^{(i)} e^{-y_i\\alpha_t h_t }\\] Modelo final: \\[H(x) = sign\\left(\\sum_{t=1}^T\\alpha_th_t(x)\\right)\\] 13.5.1 AdaBoost en acción 13.5.2 AdaBoost. Propiedades El error de entrenamiento se reduce hasta 0. El error de generalización (error en test) continúa reduciéndose incluso después de que el error en entrenamiento es 0. (No sobreajusta). "],
["gradient-boosting.html", "13.6 Gradient boosting", " 13.6 Gradient boosting El algoritmo AdaBoost se ha desarrollado para problemas de clasificación binaria utilizando la función de pérdida exponencial. Para poder aplicar la idea de boosting a otro tipo de problemas, surge el algoritmo de gradient boosting. 13.6.1 Algoritmo En resumen Inicializar: \\(H_0 \\equiv 0\\) Repetir \\(t = 1, \\ldots, T\\): Seleccionar \\(h_t\\) y \\(\\alpha_t\\) tal que \\[(h_t, \\alpha_t) = \\underset{(h_t(x_i), \\alpha_t)}{\\arg\\min} \\sum_{i= 1}^n L(y_i, f(x_i))\\] Actualizar \\[H_t = H_{t-1} + \\alpha_t h_t\\] Modelo final: \\[H(x) = sign\\left(\\sum_{t=1}^T\\alpha_th_t(x)\\right)\\] "],
["optimizacion-numerica.html", "13.7 Optimización numérica", " 13.7 Optimización numérica Sea una función \\[L(H) = \\sum_{i=1}^nL(y_i, H(x_i))\\] El objetivo es minimizar \\(L(H)\\) con respecto a \\(H\\). Esto puede verse como un problema de optimización numérica \\[\\hat{H} = \\underset{H}{\\arg\\min}L(H)\\] Los métodos de optimización numérica tratan de resolver el problema como una suma de componentes \\[H_M = \\sum_{m=0}^M h_m,\\mbox{ }h_m\\in\\mathbb{R}^n\\] donde \\(H_0\\) es un punto arbitrario inicial. Los distintos métodos difieren en cómo calcular cada incremento \\(h_m\\). 13.7.1 Descenso del gradiente (gradient descent) Uno de los métodos de optimización numérica más utilizados es el descenso del gradiente (gradient descent). Dado un valor inicial \\(x_0\\), podemos cambiar su valor en muchas direcciones. Para averiguar cuál es la mejor dirección para minimizar \\(L\\), podemos escoger el gradiente \\(\\nabla L\\). Intuitivamente, el gradiente da la pendiente de la curva en \\(x\\) y su dirección indicará hacia donde crece la función. Por tanto, cambiamos \\(x\\) en la dirección opuesta del gradiente \\[x_{k+1} = x_k - \\lambda \\nabla L(x_k)\\] Visualmente El algoritmo gradient boosting queda de la siguiente forma Inicializar: \\(H_0 \\equiv 0\\) Repetir para \\(t = 1, \\ldots, T\\): Calcular para \\(i = 1, \\ldots, n\\) \\[r_{it}=-\\left[ \\frac{\\partial L(y_i, H(x_i))}{\\partial H(x_i)}\\right]_{H=H_{t-1}}\\] Ajustar \\(h_t\\) a \\(r_{it}\\) Elegir \\(\\alpha_t &gt;0\\) tal que \\[\\alpha_t = \\underset{\\alpha_t}{\\arg\\min} \\sum_{i= 1}^n L(x_i, H_{t-1}(x_i)+\\alpha_th_t(x_i))\\] 13.7.2 ¡A jugar! Tenemos los puntos \\((x_1, y_1), \\ldots , (x_n, y_n)\\) y nuestro objetivo es ajustar un modelo \\(H(x)\\) para minimizar la pérdida cuadrática. Suponemos que nos dan un modelo \\(H\\) que ya se ha ajustado a los datos. Comprobamos el modelo y vemos que es un modelo bueno pero no perfecto. Hay algunos errores: \\(H(x_1) = 0.8\\) mientras que \\(y_1 = 0.9\\) y \\(H(x_1) = 1.4\\) mientras que \\(y_1 = 1.3\\). ¿Cómo podemos mejorar este modelo? Reglas del juego: No podemos tocar nada del modelo \\(H\\). Podemos añadir un modelo adicional \\(h\\) a \\(H\\) de forma que la nueva predicción sea \\(H(x) + h(x)\\). Queremos mejorar el modelo de forma que \\[H(x_1) + h(x_1) = y_1\\] \\[H(x_2) + h(x_2) = y_2\\] \\[\\ldots\\] \\[H(x_n) + h(x_n) = y_n\\] O, equivalentemente, \\[h(x_1) = y_1 - H(x_1)\\] \\[h(x_2) = y_2 - H(x_2)\\] \\[\\ldots\\] \\[h(x_n) = y_n - H(x_n)\\] ¿Podemos ajustar esto? De forma perfecta, no. Pero podemos encontrar un modelo que lo ajuste de forma aproximada. ¿Cómo? Ajustando un modelo sobre los puntos \\[(x_1, y_1 - H(x_1))\\] \\[(x_2, y_2 - H(x_2))\\] \\[\\ldots\\] \\[(x_n, y_n - H(x_n))\\] Solemos referirnos a \\(y_i - H(x_i)\\) como los residuos. Son partes que el modelo existente \\(H\\) no puede ajustar bien. Si el nuevo modelo \\(H + h\\) no es suficientemente bueno, podemos repetir el mismo razonamiento. ¿En qué se parece esto al descenso del gradiente? Si utilizamos la función de pérdida cuadrática \\(L(y, H(x)) = (y-H(x))^2/2\\), tenemos que \\[\\frac{\\partial J}{\\partial H(x_i)} = \\frac{\\partial \\sum_i L(y_i, H(x_i))}{\\partial H(x_i)}\\] \\[= \\frac{\\partial L(y_i, H(x_i))}{\\partial H(x_i)} = H(x_i) - y_i\\] Por lo que podemos interpretar los residuos como gradientes negativos \\[y_i - H(x_i) = -\\frac{\\partial J}{\\partial H(x_i)}\\] "],
["funciones-de-perdida-mas-habituales.html", "13.8 Funciones de pérdida más habituales", " 13.8 Funciones de pérdida más habituales "],
["parametro-de-shrinkage.html", "13.9 Parámetro de shrinkage", " 13.9 Parámetro de shrinkage En el algoritmo de Gradient Boosting podemos añadir una tasa de aprendizaje (shrinkage) \\(\\nu\\in (0,1)\\) de forma que \\[H_t = H_{t-1}(x_i)+\\nu \\alpha_th_t(x_i)\\] Empíricamente se ha visto que menores valores de \\(\\nu\\) obtienen un mejor error en test pero requieren un mayor número de iteraciones \\(T\\). La mejor estrategia suele ser la de elegir una tasa de apredizaje pequeña \\(\\nu &lt; 0.1\\) y seleccionar \\(T\\) por parada temprana (early stopping). "],
["otros-metodos.html", "13.10 Otros métodos", " 13.10 Otros métodos Se pueden incorporar ideas de otros métodos: Stochastic gradient boosting aplica la idea de los modelos de tipo bagging. Random forest. Los algoritmos de boosting suelen considerarse algoritmos caja negra (black box) que, aunque tienen un alto poder predictivo, son de difícil interpretación. Han surgido formas de interpretación de las variables relevantes en el modelo. "],
["sobre-in-training.html", "A Sobre in-training", " A Sobre in-training in-training es una iniciativa del Aula Innova. Es la respuesta de Innova-tsn a la necesidad actual de formación especializada y personalizada de nuestros clientes ante un entorno en continua evolución y unos cambios tecnológicos vertiginosos. El conocimiento y especialización que Innova-tsn ha adquirido a lo largo de los años, su continua apuesta por la innovación y la cualificación e inquietud académica de sus profesionales, permiten crear una oferta formativa flexible y totalmente personalizada que aúna conocimientos teóricos y experiencia práctica. De este modo, se pretende alcanzar eficientemente el principal objetivo de Aula Innova: Dotar a los clientes de Innova-tsn de los conocimientos y competencias necesarias para afrontar eficiente y autónomamente sus propios retos de negocio. "],
["colaboradores.html", "B Colaboradores", " B Colaboradores Alicia Morales alicia.morales@innova-tsn.com Alicia Muñoz alicia.munoz@innova-tsn.com Alvaro Díaz alvaro.munoz@innova-tsn.com Andrés Devia andres.devia@innova-tsn.com Daniel Vélez daniel.velez@innova-tsn.com Diego Fernández diego.fernandez@innova-tsn.com Jaume Puigbó jaume.puigbo@innova-tsn.com Pablo Hidalgo pablo.hidalgo@innova-tsn.com Romy Rodríguez romy.rodríguez@innova-tsn.com "],
["references.html", "References", " References "]
]
